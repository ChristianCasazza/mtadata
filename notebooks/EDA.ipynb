{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "class DuckDBWrapper:\n",
    "    def __init__(self, duckdb_path=None):\n",
    "        \"\"\"\n",
    "        Initialize a DuckDB connection.\n",
    "        If duckdb_path is provided, a persistent DuckDB database will be used.\n",
    "        Otherwise, it will create an in-memory database.\n",
    "        \"\"\"\n",
    "        if duckdb_path:\n",
    "            self.con = duckdb.connect(str(duckdb_path), read_only=False)\n",
    "        else:\n",
    "            self.con = duckdb.connect(database=':memory:', read_only=False)\n",
    "        self.registered_tables = []\n",
    "        \n",
    "        # Enable httpfs for potential remote paths if needed (though we focus on local here)\n",
    "        self.con.execute(\"INSTALL httpfs;\")\n",
    "        self.con.execute(\"LOAD httpfs;\")\n",
    "\n",
    "    def register_data(self, paths, table_names):\n",
    "        \"\"\"\n",
    "        Registers local data files (Parquet, CSV, JSON) in DuckDB by creating views.\n",
    "        Automatically detects the file type based on the file extension.\n",
    "\n",
    "        Args:\n",
    "            paths (list): List of paths to data files.\n",
    "            table_names (list): List of table names corresponding to the paths.\n",
    "        \"\"\"\n",
    "        if len(paths) != len(table_names):\n",
    "            raise ValueError(\"The number of paths must match the number of table names.\")\n",
    "\n",
    "        for path, table_name in zip(paths, table_names):\n",
    "            path_str = str(path)\n",
    "            file_extension = Path(path_str).suffix.lower()\n",
    "\n",
    "            if file_extension == \".parquet\":\n",
    "                query = f\"CREATE VIEW {table_name} AS SELECT * FROM read_parquet('{path_str}')\"\n",
    "            elif file_extension == \".csv\":\n",
    "                query = f\"CREATE VIEW {table_name} AS SELECT * FROM read_csv_auto('{path_str}')\"\n",
    "            elif file_extension == \".json\":\n",
    "                query = f\"CREATE VIEW {table_name} AS SELECT * FROM read_json_auto('{path_str}')\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file type '{file_extension}' for file: {path_str}\")\n",
    "\n",
    "            self.con.execute(query)\n",
    "            self.registered_tables.append(table_name)\n",
    "\n",
    "    def run_query(self, sql_query):\n",
    "        \"\"\"\n",
    "        Runs a SQL query on the registered tables in DuckDB.\n",
    "        \n",
    "        Args:\n",
    "            sql_query (str): The SQL query string to execute.\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Query result as a pandas DataFrame.\n",
    "        \"\"\"\n",
    "        return self.con.execute(sql_query).fetchdf()\n",
    "\n",
    "    def _construct_path(self, path, base_path, file_name, extension):\n",
    "        \"\"\"\n",
    "        Constructs the full file path based on input parameters.\n",
    "        \"\"\"\n",
    "        if path:\n",
    "            return Path(path)\n",
    "        elif base_path and file_name:\n",
    "            return Path(base_path) / f\"{file_name}.{extension}\"\n",
    "        else:\n",
    "            # Default file path: \"output.<extension>\" in the current directory\n",
    "            return Path(f\"output.{extension}\")\n",
    "\n",
    "    def export(self, result, file_type, path=None, base_path=None, file_name=None, with_header=True):\n",
    "        \"\"\"\n",
    "        Exports a query result to the specified file type.\n",
    "        Handles Arrow Tables, Pandas DataFrames, and DuckDB query results.\n",
    "\n",
    "        Args:\n",
    "            result (any): Query result to export (e.g., DuckDB query result, Pandas DataFrame, or Arrow Table).\n",
    "            file_type (str): Type of file to export ('parquet', 'csv', 'json').\n",
    "            path (str): Full path to the file (optional).\n",
    "            base_path (str): Directory path (optional).\n",
    "            file_name (str): Name of the file (without extension) (optional).\n",
    "            with_header (bool): Include header row for CSV files (default: True).\n",
    "        \"\"\"\n",
    "        file_type = file_type.lower()\n",
    "        if file_type not in [\"parquet\", \"csv\", \"json\"]:\n",
    "            raise ValueError(\"file_type must be one of 'parquet', 'csv', or 'json'.\")\n",
    "\n",
    "        full_path = self._construct_path(path, base_path, file_name, file_type)\n",
    "        full_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Convert result to a Pandas DataFrame if needed\n",
    "        if isinstance(result, pa.Table):\n",
    "            # Arrow Table to Pandas DataFrame\n",
    "            dataframe = result.to_pandas()\n",
    "        elif hasattr(result, \"to_pandas\"):\n",
    "            # DuckDB result to Pandas DataFrame\n",
    "            dataframe = result.to_pandas()\n",
    "        elif isinstance(result, pd.DataFrame):\n",
    "            # Already a Pandas DataFrame\n",
    "            dataframe = result\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported result type. Must be a Pandas DataFrame, Arrow Table, or DuckDB query result.\")\n",
    "\n",
    "        # Export based on file type\n",
    "        if file_type == \"parquet\":\n",
    "            dataframe.to_parquet(full_path, index=False)\n",
    "        elif file_type == \"csv\":\n",
    "            dataframe.to_csv(full_path, index=False, header=with_header)\n",
    "        elif file_type == \"json\":\n",
    "            dataframe.to_json(full_path, orient='records', lines=True)\n",
    "\n",
    "        print(f\"File written to: {full_path}\")\n",
    "\n",
    "\n",
    "    def show_tables(self):\n",
    "        \"\"\"\n",
    "        Displays the table names and types currently registered in the catalog.\n",
    "        \"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, table_type\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema='main'\n",
    "        \"\"\"\n",
    "        result_df = self.run_query(query)\n",
    "        print(result_df)\n",
    "\n",
    "    def show_schema(self, table_name):\n",
    "        \"\"\"\n",
    "        Displays the schema of the specified table.\n",
    "        \n",
    "        Args:\n",
    "            table_name (str): Name of the table whose schema is to be displayed.\n",
    "        \"\"\"\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            table_name, \n",
    "            column_name, \n",
    "            data_type\n",
    "        FROM \n",
    "            information_schema.columns \n",
    "        WHERE \n",
    "            table_name = '{table_name}'\n",
    "        \"\"\"\n",
    "        result_df = self.run_query(query)\n",
    "        print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DuckDBWrapper (in-memory DuckDB instance)\n",
    "con = DuckDBWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path.cwd().resolve().parents[0]  # Adjust to locate the repo root\n",
    "\n",
    "# Define relative paths from the repo root and corresponding table names\n",
    "paths = [\n",
    "    repo_root / \"data/opendata/nyc/mta/mta_operations_statement/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/mta_hourly_subway_socrata/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/mta_daily_ridership/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/mta_bus_wait_time/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/daily_weather_asset/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/hourly_weather_asset/*.parquet\",\n",
    "    repo_root / \"data/opendata/nyc/mta/mta_bus_speeds/*.parquet\",\n",
    "]\n",
    "table_names = [\n",
    "    \"mta_operations_statement\",\n",
    "    \"mta_hourly_subway_socrata\",\n",
    "    \"mta_daily_ridership\",\n",
    "    \"mta_bus_wait_time\",\n",
    "    \"daily_weather_asset\",\n",
    "    \"hourly_weather_asset\",\n",
    "    \"mta_bus_speeds\",\n",
    "]\n",
    "\n",
    "\n",
    "# Register all datasets as views in DuckDB\n",
    "con.register_data(paths, table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  table_name table_type\n",
      "0        daily_weather_asset       VIEW\n",
      "1       hourly_weather_asset       VIEW\n",
      "2             mta_bus_speeds       VIEW\n",
      "3          mta_bus_wait_time       VIEW\n",
      "4        mta_daily_ridership       VIEW\n",
      "5  mta_hourly_subway_socrata       VIEW\n",
      "6   mta_operations_statement       VIEW\n"
     ]
    }
   ],
   "source": [
    "# Show the tables registered\n",
    "con.show_tables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             table_name                             column_name data_type\n",
      "0   mta_daily_ridership                                    date      DATE\n",
      "1   mta_daily_ridership                 subways_total_ridership    DOUBLE\n",
      "2   mta_daily_ridership                subways_pct_pre_pandemic    DOUBLE\n",
      "3   mta_daily_ridership                   buses_total_ridership    DOUBLE\n",
      "4   mta_daily_ridership                  buses_pct_pre_pandemic    DOUBLE\n",
      "5   mta_daily_ridership                    lirr_total_ridership    DOUBLE\n",
      "6   mta_daily_ridership                   lirr_pct_pre_pandemic    DOUBLE\n",
      "7   mta_daily_ridership             metro_north_total_ridership    DOUBLE\n",
      "8   mta_daily_ridership            metro_north_pct_pre_pandemic    DOUBLE\n",
      "9   mta_daily_ridership               access_a_ride_total_trips    DOUBLE\n",
      "10  mta_daily_ridership          access_a_ride_pct_pre_pandemic    DOUBLE\n",
      "11  mta_daily_ridership           bridges_tunnels_total_traffic    DOUBLE\n",
      "12  mta_daily_ridership        bridges_tunnels_pct_pre_pandemic    DOUBLE\n",
      "13  mta_daily_ridership   staten_island_railway_total_ridership    DOUBLE\n",
      "14  mta_daily_ridership  staten_island_railway_pct_pre_pandemic    DOUBLE\n"
     ]
    }
   ],
   "source": [
    "# Show the schema of a specific table\n",
    "con.show_schema(\"mta_daily_ridership\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count_star()\n",
      "0      67763465\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "\n",
    "SELECT count(*) from mta_hourly_subway_socrata\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = con.run_query(query)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File written to: /home/christianocean/mta/data/exports/row_count.json\n"
     ]
    }
   ],
   "source": [
    "repo_root = Path.cwd().resolve().parents[0]  # Adjust to locate the repo root\n",
    "base_path = repo_root / \"data/exports\"\n",
    "file_name = \"row_count\"\n",
    "file_type= \"csv\"\n",
    "# Export the query result to CSV\n",
    "con.export(result, file_type=file_type, base_path=base_path, file_name=file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
