[0m13:57:24.213102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08f24f400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08d9999f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08d999a20>]}


============================== 13:57:24.216920 | 134466d0-a9a9-41ce-86c9-280e89a09cca ==============================
[0m13:57:24.216920 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:57:24.217328 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:57:24.609037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08f319150>]}
[0m13:57:24.665261 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08e556800>]}
[0m13:57:24.669623 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m13:57:24.680224 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:57:24.680882 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m13:57:24.681256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08d855e70>]}
[0m13:57:25.531935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0805d44f0>]}
[0m13:57:25.639956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08041c580>]}
[0m13:57:25.640410 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m13:57:25.642002 [info ] [MainThread]: 
[0m13:57:25.642503 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:57:25.646193 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_nfl_database'
[0m13:57:25.709814 [debug] [ThreadPool]: Using duckdb connection "list_nfl_database"
[0m13:57:25.710292 [debug] [ThreadPool]: On list_nfl_database: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_nfl_database"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"nfl_database"'
    
  
  
[0m13:57:25.710630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:57:25.756050 [debug] [ThreadPool]: SQL status: OK in 0.045 seconds
[0m13:57:25.757596 [debug] [ThreadPool]: On list_nfl_database: Close
[0m13:57:25.760137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_nfl_database, now create_nfl_database_main)
[0m13:57:25.760855 [debug] [ThreadPool]: Creating schema "database: "nfl_database"
schema: "main"
"
[0m13:57:25.765572 [debug] [ThreadPool]: Using duckdb connection "create_nfl_database_main"
[0m13:57:25.765901 [debug] [ThreadPool]: On create_nfl_database_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_nfl_database_main"} */

    
        select type from duckdb_databases()
        where database_name='nfl_database'
        and type='sqlite'
    
  
[0m13:57:25.766207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:57:25.773880 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m13:57:25.775325 [debug] [ThreadPool]: Using duckdb connection "create_nfl_database_main"
[0m13:57:25.775676 [debug] [ThreadPool]: On create_nfl_database_main: BEGIN
[0m13:57:25.776207 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:57:25.776493 [debug] [ThreadPool]: Using duckdb connection "create_nfl_database_main"
[0m13:57:25.776737 [debug] [ThreadPool]: On create_nfl_database_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_nfl_database_main"} */

    
    
        create schema if not exists "nfl_database"."main"
    
[0m13:57:25.779841 [debug] [ThreadPool]: SQL status: OK in 0.003 seconds
[0m13:57:25.780873 [debug] [ThreadPool]: On create_nfl_database_main: COMMIT
[0m13:57:25.781205 [debug] [ThreadPool]: Using duckdb connection "create_nfl_database_main"
[0m13:57:25.781478 [debug] [ThreadPool]: On create_nfl_database_main: COMMIT
[0m13:57:25.782067 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:57:25.782357 [debug] [ThreadPool]: On create_nfl_database_main: Close
[0m13:57:25.785683 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_nfl_database_main, now list_nfl_database_main)
[0m13:57:25.789897 [debug] [ThreadPool]: Using duckdb connection "list_nfl_database_main"
[0m13:57:25.790459 [debug] [ThreadPool]: On list_nfl_database_main: BEGIN
[0m13:57:25.790819 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:57:25.796078 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m13:57:25.796476 [debug] [ThreadPool]: Using duckdb connection "list_nfl_database_main"
[0m13:57:25.796762 [debug] [ThreadPool]: On list_nfl_database_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_nfl_database_main"} */
select
      'nfl_database' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'nfl_database'
  
[0m13:57:25.829116 [debug] [ThreadPool]: SQL status: OK in 0.032 seconds
[0m13:57:25.830342 [debug] [ThreadPool]: On list_nfl_database_main: ROLLBACK
[0m13:57:25.832005 [debug] [ThreadPool]: Failed to rollback 'list_nfl_database_main'
[0m13:57:25.832301 [debug] [ThreadPool]: On list_nfl_database_main: Close
[0m13:57:25.836522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08f53ecb0>]}
[0m13:57:25.837078 [debug] [MainThread]: Using duckdb connection "master"
[0m13:57:25.837386 [debug] [MainThread]: On master: BEGIN
[0m13:57:25.837634 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:57:25.843025 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m13:57:25.843435 [debug] [MainThread]: On master: COMMIT
[0m13:57:25.843740 [debug] [MainThread]: Using duckdb connection "master"
[0m13:57:25.844025 [debug] [MainThread]: On master: COMMIT
[0m13:57:25.844586 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:57:25.844872 [debug] [MainThread]: On master: Close
[0m13:57:25.846494 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m13:57:25.846855 [info ] [MainThread]: 
[0m13:57:25.854136 [debug] [Thread-1 (]: Began running node model.nfl.avg_riders_per_day
[0m13:57:25.855299 [debug] [Thread-2 (]: Began running node model.nfl.busiest_specific_times
[0m13:57:25.854903 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m13:57:25.856042 [debug] [Thread-3 (]: Began running node model.nfl.fare_class_boro
[0m13:57:25.856827 [debug] [Thread-4 (]: Began running node model.nfl.hourly_riders
[0m13:57:25.856460 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m13:57:25.857460 [debug] [Thread-5 (]: Began running node model.nfl.omny_adoption_by_station
[0m13:57:25.858532 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.nfl.avg_riders_per_day'
[0m13:57:25.858960 [debug] [Thread-6 (]: Began running node model.nfl.omny_adoption_increase
[0m13:57:25.859412 [debug] [Thread-7 (]: Began running node model.nfl.total_riders_per_station
[0m13:57:25.859923 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m13:57:25.860494 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m13:57:25.861084 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.nfl.busiest_specific_times'
[0m13:57:25.861544 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m13:57:25.862055 [debug] [Thread-1 (]: Began compiling node model.nfl.avg_riders_per_day
[0m13:57:25.862518 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m13:57:25.863058 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m13:57:25.863829 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.nfl.fare_class_boro'
[0m13:57:25.864450 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.nfl.hourly_riders'
[0m13:57:25.864865 [debug] [Thread-2 (]: Began compiling node model.nfl.busiest_specific_times
[0m13:57:25.865285 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_nfl_database_main, now model.nfl.omny_adoption_by_station)
[0m13:57:25.872361 [debug] [Thread-1 (]: Writing injected SQL for node "model.nfl.avg_riders_per_day"
[0m13:57:25.873813 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.nfl.omny_adoption_increase'
[0m13:57:25.875611 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.nfl.total_riders_per_station'
[0m13:57:25.876220 [debug] [Thread-3 (]: Began compiling node model.nfl.fare_class_boro
[0m13:57:25.876735 [debug] [Thread-4 (]: Began compiling node model.nfl.hourly_riders
[0m13:57:25.879349 [debug] [Thread-2 (]: Writing injected SQL for node "model.nfl.busiest_specific_times"
[0m13:57:25.879817 [debug] [Thread-5 (]: Began compiling node model.nfl.omny_adoption_by_station
[0m13:57:25.880382 [debug] [Thread-6 (]: Began compiling node model.nfl.omny_adoption_increase
[0m13:57:25.880793 [debug] [Thread-7 (]: Began compiling node model.nfl.total_riders_per_station
[0m13:57:25.883417 [debug] [Thread-3 (]: Writing injected SQL for node "model.nfl.fare_class_boro"
[0m13:57:25.884193 [debug] [Thread-1 (]: Began executing node model.nfl.avg_riders_per_day
[0m13:57:25.887598 [debug] [Thread-4 (]: Writing injected SQL for node "model.nfl.hourly_riders"
[0m13:57:25.893603 [debug] [Thread-5 (]: Writing injected SQL for node "model.nfl.omny_adoption_by_station"
[0m13:57:25.896396 [debug] [Thread-6 (]: Writing injected SQL for node "model.nfl.omny_adoption_increase"
[0m13:57:25.896855 [debug] [Thread-2 (]: Began executing node model.nfl.busiest_specific_times
[0m13:57:25.898990 [debug] [Thread-7 (]: Writing injected SQL for node "model.nfl.total_riders_per_station"
[0m13:57:25.911224 [debug] [Thread-3 (]: Began executing node model.nfl.fare_class_boro
[0m13:57:25.912067 [debug] [Thread-4 (]: Began executing node model.nfl.hourly_riders
[0m13:57:25.912718 [debug] [Thread-5 (]: Began executing node model.nfl.omny_adoption_by_station
[0m13:57:25.925538 [debug] [Thread-1 (]: Writing runtime sql for node "model.nfl.avg_riders_per_day"
[0m13:57:25.926212 [debug] [Thread-6 (]: Began executing node model.nfl.omny_adoption_increase
[0m13:57:25.928621 [debug] [Thread-2 (]: Writing runtime sql for node "model.nfl.busiest_specific_times"
[0m13:57:25.929104 [debug] [Thread-7 (]: Began executing node model.nfl.total_riders_per_station
[0m13:57:25.931245 [debug] [Thread-3 (]: Writing runtime sql for node "model.nfl.fare_class_boro"
[0m13:57:25.934480 [debug] [Thread-4 (]: Writing runtime sql for node "model.nfl.hourly_riders"
[0m13:57:25.937160 [debug] [Thread-5 (]: Writing runtime sql for node "model.nfl.omny_adoption_by_station"
[0m13:57:25.939558 [debug] [Thread-6 (]: Writing runtime sql for node "model.nfl.omny_adoption_increase"
[0m13:57:25.941933 [debug] [Thread-7 (]: Writing runtime sql for node "model.nfl.total_riders_per_station"
[0m13:57:25.942774 [debug] [Thread-1 (]: Using duckdb connection "model.nfl.avg_riders_per_day"
[0m13:57:25.943384 [debug] [Thread-3 (]: Using duckdb connection "model.nfl.fare_class_boro"
[0m13:57:25.943831 [debug] [Thread-2 (]: Using duckdb connection "model.nfl.busiest_specific_times"
[0m13:57:25.944486 [debug] [Thread-4 (]: Using duckdb connection "model.nfl.hourly_riders"
[0m13:57:25.945499 [debug] [Thread-7 (]: Using duckdb connection "model.nfl.total_riders_per_station"
[0m13:57:25.945971 [debug] [Thread-1 (]: On model.nfl.avg_riders_per_day: BEGIN
[0m13:57:25.946440 [debug] [Thread-5 (]: Using duckdb connection "model.nfl.omny_adoption_by_station"
[0m13:57:25.946896 [debug] [Thread-6 (]: Using duckdb connection "model.nfl.omny_adoption_increase"
[0m13:57:25.947344 [debug] [Thread-3 (]: On model.nfl.fare_class_boro: BEGIN
[0m13:57:25.947779 [debug] [Thread-2 (]: On model.nfl.busiest_specific_times: BEGIN
[0m13:57:25.948128 [debug] [Thread-4 (]: On model.nfl.hourly_riders: BEGIN
[0m13:57:25.948465 [debug] [Thread-7 (]: On model.nfl.total_riders_per_station: BEGIN
[0m13:57:25.948790 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:57:25.949123 [debug] [Thread-5 (]: On model.nfl.omny_adoption_by_station: BEGIN
[0m13:57:25.949494 [debug] [Thread-6 (]: On model.nfl.omny_adoption_increase: BEGIN
[0m13:57:25.949980 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:57:25.950427 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:57:25.951087 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:57:25.951458 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:57:25.957551 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m13:57:25.958312 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:57:25.960238 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m13:57:25.960602 [debug] [Thread-1 (]: Using duckdb connection "model.nfl.avg_riders_per_day"
[0m13:57:25.960933 [debug] [Thread-1 (]: On model.nfl.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.avg_riders_per_day"} */

  
    
    

    create  table
      "nfl_database"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC;
    );
  
  
[0m13:57:25.979680 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.avg_riders_per_day"} */

  
    
    

    create  table
      "nfl_database"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC;
    );
  
  
[0m13:57:25.980230 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:25.980722 [debug] [Thread-1 (]: On model.nfl.avg_riders_per_day: ROLLBACK
[0m13:57:25.983523 [debug] [Thread-3 (]: SQL status: OK in 0.033 seconds
[0m13:57:25.985787 [debug] [Thread-3 (]: Using duckdb connection "model.nfl.fare_class_boro"
[0m13:57:25.986543 [debug] [Thread-3 (]: On model.nfl.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.fare_class_boro"} */

  
    
    

    create  table
      "nfl_database"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC;
    );
  
  
[0m13:57:25.988261 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.fare_class_boro"} */

  
    
    

    create  table
      "nfl_database"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC;
    );
  
  
[0m13:57:25.989211 [debug] [Thread-2 (]: SQL status: OK in 0.039 seconds
[0m13:57:25.989642 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:25.990060 [debug] [Thread-2 (]: Using duckdb connection "model.nfl.busiest_specific_times"
[0m13:57:25.991020 [debug] [Thread-3 (]: On model.nfl.fare_class_boro: ROLLBACK
[0m13:57:25.991624 [debug] [Thread-2 (]: On model.nfl.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.busiest_specific_times"} */

  
    
    

    create  table
      "nfl_database"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC;
    );
  
  
[0m13:57:25.993485 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.busiest_specific_times"} */

  
    
    

    create  table
      "nfl_database"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC;
    );
  
  
[0m13:57:25.995206 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:25.995894 [debug] [Thread-2 (]: On model.nfl.busiest_specific_times: ROLLBACK
[0m13:57:25.996295 [debug] [Thread-4 (]: SQL status: OK in 0.045 seconds
[0m13:57:25.997844 [debug] [Thread-4 (]: Using duckdb connection "model.nfl.hourly_riders"
[0m13:57:25.998953 [debug] [Thread-4 (]: On model.nfl.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.hourly_riders"} */

  
    
    

    create  table
      "nfl_database"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC;
    );
  
  
[0m13:57:25.999803 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.hourly_riders"} */

  
    
    

    create  table
      "nfl_database"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC;
    );
  
  
[0m13:57:26.000613 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:26.001006 [debug] [Thread-7 (]: SQL status: OK in 0.050 seconds
[0m13:57:26.002620 [debug] [Thread-4 (]: On model.nfl.hourly_riders: ROLLBACK
[0m13:57:26.004011 [debug] [Thread-7 (]: Using duckdb connection "model.nfl.total_riders_per_station"
[0m13:57:26.004977 [debug] [Thread-7 (]: On model.nfl.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.total_riders_per_station"} */

  
    
    

    create  table
      "nfl_database"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC;
    );
  
  
[0m13:57:26.005928 [debug] [Thread-7 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.total_riders_per_station"} */

  
    
    

    create  table
      "nfl_database"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "nfl_database"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC;
    );
  
  
[0m13:57:26.006573 [debug] [Thread-1 (]: Failed to rollback 'model.nfl.avg_riders_per_day'
[0m13:57:26.007459 [debug] [Thread-2 (]: Failed to rollback 'model.nfl.busiest_specific_times'
[0m13:57:26.007979 [debug] [Thread-3 (]: Failed to rollback 'model.nfl.fare_class_boro'
[0m13:57:26.008743 [debug] [Thread-7 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:26.009686 [debug] [Thread-4 (]: Failed to rollback 'model.nfl.hourly_riders'
[0m13:57:26.010189 [debug] [Thread-1 (]: On model.nfl.avg_riders_per_day: Close
[0m13:57:26.010531 [debug] [Thread-5 (]: SQL status: OK in 0.053 seconds
[0m13:57:26.010965 [debug] [Thread-2 (]: On model.nfl.busiest_specific_times: Close
[0m13:57:26.011367 [debug] [Thread-6 (]: SQL status: OK in 0.053 seconds
[0m13:57:26.011679 [debug] [Thread-3 (]: On model.nfl.fare_class_boro: Close
[0m13:57:26.012127 [debug] [Thread-7 (]: On model.nfl.total_riders_per_station: ROLLBACK
[0m13:57:26.012521 [debug] [Thread-4 (]: On model.nfl.hourly_riders: Close
[0m13:57:26.013251 [debug] [Thread-5 (]: Using duckdb connection "model.nfl.omny_adoption_by_station"
[0m13:57:26.013820 [debug] [Thread-1 (]: Runtime Error in model avg_riders_per_day (models/avg_riders_per_day.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.014591 [debug] [Thread-6 (]: Using duckdb connection "model.nfl.omny_adoption_increase"
[0m13:57:26.015202 [debug] [Thread-2 (]: Runtime Error in model busiest_specific_times (models/busiest_specific_times.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.016559 [debug] [Thread-7 (]: Failed to rollback 'model.nfl.total_riders_per_station'
[0m13:57:26.017206 [debug] [Thread-3 (]: Runtime Error in model fare_class_boro (models/fare_class_boro.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.018323 [debug] [Thread-5 (]: On model.nfl.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.omny_adoption_by_station"} */

  
    
    

    create  table
      "nfl_database"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC;
    );
  
  
[0m13:57:26.019109 [debug] [Thread-4 (]: Runtime Error in model hourly_riders (models/hourly_riders.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.020569 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08e58a830>]}
[0m13:57:26.021051 [debug] [Thread-6 (]: On model.nfl.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.omny_adoption_increase"} */

  
    
    

    create  table
      "nfl_database"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m13:57:26.021595 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b321ff0>]}
[0m13:57:26.022007 [debug] [Thread-7 (]: On model.nfl.total_riders_per_station: Close
[0m13:57:26.022415 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b4d6bf0>]}
[0m13:57:26.023721 [debug] [Thread-5 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.omny_adoption_by_station"} */

  
    
    

    create  table
      "nfl_database"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC;
    );
  
  
[0m13:57:26.024249 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b587100>]}
[0m13:57:26.024887 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model main.avg_riders_per_day .................. [[31mERROR[0m in 0.16s]
[0m13:57:26.026130 [error] [Thread-2 (]: 2 of 7 ERROR creating sql table model main.busiest_specific_times .............. [[31mERROR[0m in 0.16s]
[0m13:57:26.028125 [error] [Thread-3 (]: 3 of 7 ERROR creating sql table model main.fare_class_boro ..................... [[31mERROR[0m in 0.16s]
[0m13:57:26.029004 [debug] [Thread-5 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:26.029693 [debug] [Thread-7 (]: Runtime Error in model total_riders_per_station (models/total_riders_per_station.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.030461 [error] [Thread-4 (]: 4 of 7 ERROR creating sql table model main.hourly_riders ....................... [[31mERROR[0m in 0.16s]
[0m13:57:26.031245 [debug] [Thread-1 (]: Finished running node model.nfl.avg_riders_per_day
[0m13:57:26.031996 [debug] [Thread-2 (]: Finished running node model.nfl.busiest_specific_times
[0m13:57:26.032744 [debug] [Thread-3 (]: Finished running node model.nfl.fare_class_boro
[0m13:57:26.033965 [debug] [Thread-5 (]: On model.nfl.omny_adoption_by_station: ROLLBACK
[0m13:57:26.034731 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b31b820>]}
[0m13:57:26.035423 [debug] [Thread-4 (]: Finished running node model.nfl.hourly_riders
[0m13:57:26.037440 [error] [Thread-7 (]: 7 of 7 ERROR creating sql table model main.total_riders_per_station ............ [[31mERROR[0m in 0.16s]
[0m13:57:26.038716 [debug] [Thread-5 (]: Failed to rollback 'model.nfl.omny_adoption_by_station'
[0m13:57:26.039297 [debug] [Thread-7 (]: Finished running node model.nfl.total_riders_per_station
[0m13:57:26.039701 [debug] [Thread-5 (]: On model.nfl.omny_adoption_by_station: Close
[0m13:57:26.041108 [debug] [Thread-5 (]: Runtime Error in model omny_adoption_by_station (models/omny_adoption_by_station.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.041536 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b452bf0>]}
[0m13:57:26.042076 [error] [Thread-5 (]: 5 of 7 ERROR creating sql table model main.omny_adoption_by_station ............ [[31mERROR[0m in 0.18s]
[0m13:57:26.042564 [debug] [Thread-5 (]: Finished running node model.nfl.omny_adoption_by_station
[0m13:57:26.055236 [debug] [Thread-6 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.nfl.omny_adoption_increase"} */

  
    
    

    create  table
      "nfl_database"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "nfl_database"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m13:57:26.056277 [debug] [Thread-6 (]: DuckDB adapter: Rolling back transaction.
[0m13:57:26.057755 [debug] [Thread-6 (]: On model.nfl.omny_adoption_increase: ROLLBACK
[0m13:57:26.059061 [debug] [Thread-6 (]: Failed to rollback 'model.nfl.omny_adoption_increase'
[0m13:57:26.059498 [debug] [Thread-6 (]: On model.nfl.omny_adoption_increase: Close
[0m13:57:26.062741 [debug] [Thread-6 (]: Runtime Error in model omny_adoption_increase (models/omny_adoption_increase.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "temp.information_schema.schemata"?
  LINE 22:         "nfl_database"."main"."mta_hourly_subway_socrata"
      WHERE 
          EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_percentage_by_station AS (
      -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
      SELECT 
          station_complex_id, 
          station_complex, 
          latitude, 
          longitude, 
          year, 
          (omny_ridership / total_ridership) AS omny_percentage
      FROM 
          omny_ridership_by_station_year
  )
  SELECT 
      s2023.station_complex_id AS station_id, 
      s2023.station_complex AS station_name,
      s2023.latitude,
      s2023.longitude,
      s2023.omny_percentage AS omny_percentage_2023,
      s2024.omny_percentage AS omny_percentage_2024,
      (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
  FROM 
      omny_percentage_by_station s2023
  JOIN 
      omny_percentage_by_station s2024 
      ON s2023.station_complex_id = s2024.station_complex_id
      AND s2023.latitude = s2024.latitude
      AND s2023.longitude = s2024.longitude
      AND s2023.year = 2023
      AND s2024.year = 2024
  WHERE 
      s2024.omny_percentage > s2023.omny_percentage
  ORDER BY 
      omny_percentage_increase DESC
      );
    
    ...
                   ^
[0m13:57:26.063284 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '134466d0-a9a9-41ce-86c9-280e89a09cca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b4513f0>]}
[0m13:57:26.063879 [error] [Thread-6 (]: 6 of 7 ERROR creating sql table model main.omny_adoption_increase .............. [[31mERROR[0m in 0.19s]
[0m13:57:26.064514 [debug] [Thread-6 (]: Finished running node model.nfl.omny_adoption_increase
[0m13:57:26.067871 [debug] [MainThread]: Using duckdb connection "master"
[0m13:57:26.068644 [debug] [MainThread]: On master: BEGIN
[0m13:57:26.069105 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:57:26.076913 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m13:57:26.077409 [debug] [MainThread]: On master: COMMIT
[0m13:57:26.077722 [debug] [MainThread]: Using duckdb connection "master"
[0m13:57:26.077977 [debug] [MainThread]: On master: COMMIT
[0m13:57:26.078492 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:57:26.078809 [debug] [MainThread]: On master: Close
[0m13:57:26.080951 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:57:26.081314 [debug] [MainThread]: Connection 'model.nfl.omny_adoption_by_station' was properly closed.
[0m13:57:26.081564 [debug] [MainThread]: Connection 'model.nfl.avg_riders_per_day' was properly closed.
[0m13:57:26.081782 [debug] [MainThread]: Connection 'model.nfl.busiest_specific_times' was properly closed.
[0m13:57:26.081987 [debug] [MainThread]: Connection 'model.nfl.fare_class_boro' was properly closed.
[0m13:57:26.082187 [debug] [MainThread]: Connection 'model.nfl.hourly_riders' was properly closed.
[0m13:57:26.082394 [debug] [MainThread]: Connection 'model.nfl.omny_adoption_increase' was properly closed.
[0m13:57:26.082603 [debug] [MainThread]: Connection 'model.nfl.total_riders_per_station' was properly closed.
[0m13:57:26.083072 [info ] [MainThread]: 
[0m13:57:26.083517 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m13:57:26.085177 [debug] [MainThread]: Command end result
[0m13:57:26.174707 [info ] [MainThread]: 
[0m13:57:26.175211 [info ] [MainThread]: [31mCompleted with 7 errors and 0 warnings:[0m
[0m13:57:26.175518 [info ] [MainThread]: 
[0m13:57:26.175862 [error] [MainThread]:   Runtime Error in model avg_riders_per_day (models/avg_riders_per_day.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.176126 [info ] [MainThread]: 
[0m13:57:26.176426 [error] [MainThread]:   Runtime Error in model busiest_specific_times (models/busiest_specific_times.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.176671 [info ] [MainThread]: 
[0m13:57:26.176955 [error] [MainThread]:   Runtime Error in model fare_class_boro (models/fare_class_boro.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.177192 [info ] [MainThread]: 
[0m13:57:26.177466 [error] [MainThread]:   Runtime Error in model hourly_riders (models/hourly_riders.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.177699 [info ] [MainThread]: 
[0m13:57:26.177973 [error] [MainThread]:   Runtime Error in model total_riders_per_station (models/total_riders_per_station.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.178206 [info ] [MainThread]: 
[0m13:57:26.178488 [error] [MainThread]:   Runtime Error in model omny_adoption_by_station (models/omny_adoption_by_station.sql)
  Parser Error: syntax error at or near ";"
[0m13:57:26.178721 [info ] [MainThread]: 
[0m13:57:26.179028 [error] [MainThread]:   Runtime Error in model omny_adoption_increase (models/omny_adoption_increase.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "temp.information_schema.schemata"?
  LINE 22:         "nfl_database"."main"."mta_hourly_subway_socrata"
      WHERE 
          EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_percentage_by_station AS (
      -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
      SELECT 
          station_complex_id, 
          station_complex, 
          latitude, 
          longitude, 
          year, 
          (omny_ridership / total_ridership) AS omny_percentage
      FROM 
          omny_ridership_by_station_year
  )
  SELECT 
      s2023.station_complex_id AS station_id, 
      s2023.station_complex AS station_name,
      s2023.latitude,
      s2023.longitude,
      s2023.omny_percentage AS omny_percentage_2023,
      s2024.omny_percentage AS omny_percentage_2024,
      (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
  FROM 
      omny_percentage_by_station s2023
  JOIN 
      omny_percentage_by_station s2024 
      ON s2023.station_complex_id = s2024.station_complex_id
      AND s2023.latitude = s2024.latitude
      AND s2023.longitude = s2024.longitude
      AND s2023.year = 2023
      AND s2024.year = 2024
  WHERE 
      s2024.omny_percentage > s2023.omny_percentage
  ORDER BY 
      omny_percentage_increase DESC
      );
    
    ...
                   ^
[0m13:57:26.179417 [info ] [MainThread]: 
[0m13:57:26.179702 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=7 SKIP=0 TOTAL=7
[0m13:57:26.182772 [debug] [MainThread]: Resource report: {"command_name": "build", "command_wall_clock_time": 2.0096865, "process_user_time": 2.654633, "process_kernel_time": 0.435835, "process_mem_max_rss": "206684", "process_in_blocks": "42648", "process_out_blocks": "2864", "command_success": false}
[0m13:57:26.183823 [debug] [MainThread]: Command `dbt build` failed at 13:57:26.183606 after 2.01 seconds
[0m13:57:26.184353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff08f24f400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0805d65f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff07b4e3820>]}
[0m13:57:26.184769 [debug] [MainThread]: Flushing usage events
[0m13:59:29.322568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd275cdb430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd27441d9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd27441da20>]}


============================== 13:59:29.324833 | 5e5d64e5-4300-46ff-96f8-e12648004637 ==============================
[0m13:59:29.324833 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:59:29.325331 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:59:29.497115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd269113580>]}
[0m13:59:29.545501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2743d6380>]}
[0m13:59:29.547939 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m13:59:29.557987 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:59:29.632113 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m13:59:29.632674 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m13:59:29.633017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2750150c0>]}
[0m13:59:30.488820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262b71b70>]}
[0m13:59:30.553395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262b4aa70>]}
[0m13:59:30.553891 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m13:59:30.555486 [info ] [MainThread]: 
[0m13:59:30.556022 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:59:30.559822 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m13:59:30.582291 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m13:59:30.582823 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m13:59:30.583133 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:30.601153 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m13:59:30.602326 [debug] [ThreadPool]: On list_lake: Close
[0m13:59:30.605396 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m13:59:30.605858 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m13:59:30.610760 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:30.611215 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m13:59:30.611510 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:30.618383 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:59:30.619654 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:30.620022 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m13:59:30.620637 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:30.620893 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:30.621124 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m13:59:30.621555 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:30.622158 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m13:59:30.622429 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:30.622642 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m13:59:30.623107 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:30.623337 [debug] [ThreadPool]: On create_lake_main: Close
[0m13:59:30.626764 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m13:59:30.631244 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m13:59:30.631833 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m13:59:30.632163 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:30.637589 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m13:59:30.638037 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m13:59:30.638338 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m13:59:30.655038 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m13:59:30.657576 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m13:59:30.658066 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m13:59:30.658325 [debug] [ThreadPool]: On list_lake_main: Close
[0m13:59:30.661279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd262a054b0>]}
[0m13:59:30.661672 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:30.661907 [debug] [MainThread]: On master: BEGIN
[0m13:59:30.662138 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:59:30.667322 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m13:59:30.667650 [debug] [MainThread]: On master: COMMIT
[0m13:59:30.667921 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:30.668163 [debug] [MainThread]: On master: COMMIT
[0m13:59:30.668561 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:59:30.668806 [debug] [MainThread]: On master: Close
[0m13:59:30.670591 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m13:59:30.670954 [info ] [MainThread]: 
[0m13:59:30.677425 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m13:59:30.677928 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m13:59:30.678446 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m13:59:30.679491 [debug] [Thread-4 (]: Began running node model.mta.hourly_riders
[0m13:59:30.679916 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_by_station
[0m13:59:30.680380 [debug] [Thread-6 (]: Began running node model.mta.omny_adoption_increase
[0m13:59:30.679115 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m13:59:30.680983 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m13:59:30.681441 [debug] [Thread-7 (]: Began running node model.mta.total_riders_per_station
[0m13:59:30.682192 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m13:59:30.682743 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m13:59:30.683302 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m13:59:30.683871 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m13:59:30.684582 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m13:59:30.685297 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m13:59:30.685912 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m13:59:30.686634 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m13:59:30.687194 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.hourly_riders'
[0m13:59:30.688616 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_by_station)
[0m13:59:30.689723 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m13:59:30.690455 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m13:59:30.691074 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m13:59:30.691810 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m13:59:30.692515 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m13:59:30.693334 [debug] [Thread-4 (]: Began compiling node model.mta.hourly_riders
[0m13:59:30.694040 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_by_station
[0m13:59:30.694512 [debug] [Thread-6 (]: Began compiling node model.mta.omny_adoption_increase
[0m13:59:30.702645 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m13:59:30.707230 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m13:59:30.707819 [debug] [Thread-7 (]: Began compiling node model.mta.total_riders_per_station
[0m13:59:30.710554 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m13:59:30.713398 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.hourly_riders"
[0m13:59:30.716318 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m13:59:30.719883 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m13:59:30.722791 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m13:59:30.723723 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m13:59:30.725095 [debug] [Thread-4 (]: Began executing node model.mta.hourly_riders
[0m13:59:30.725541 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m13:59:30.726140 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m13:59:30.726902 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_by_station
[0m13:59:30.727837 [debug] [Thread-6 (]: Began executing node model.mta.omny_adoption_increase
[0m13:59:30.733950 [debug] [Thread-7 (]: Began executing node model.mta.total_riders_per_station
[0m13:59:30.817254 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.hourly_riders"
[0m13:59:30.818802 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m13:59:30.821645 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m13:59:30.824212 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m13:59:30.826808 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m13:59:30.829513 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m13:59:30.832096 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m13:59:30.834374 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:30.834875 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:30.835304 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:30.835637 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:30.836236 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:30.836727 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:30.837139 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m13:59:30.837476 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:30.837827 [debug] [Thread-4 (]: On model.mta.hourly_riders: BEGIN
[0m13:59:30.838163 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m13:59:30.838488 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m13:59:30.838838 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m13:59:30.839207 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: BEGIN
[0m13:59:30.839565 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:59:30.839909 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: BEGIN
[0m13:59:30.840247 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:59:30.840572 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:59:30.840901 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:59:30.841247 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m13:59:30.841587 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:59:30.848448 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:59:30.849969 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m13:59:30.850517 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:30.850880 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m13:59:30.852669 [debug] [Thread-4 (]: SQL status: OK in 0.012 seconds
[0m13:59:30.853048 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:30.853379 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m13:59:30.854192 [debug] [Thread-3 (]: SQL status: OK in 0.014 seconds
[0m13:59:30.854634 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:30.854991 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m13:59:30.857042 [debug] [Thread-2 (]: SQL status: OK in 0.016 seconds
[0m13:59:30.857532 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:30.858001 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m13:59:30.859516 [debug] [Thread-5 (]: SQL status: OK in 0.018 seconds
[0m13:59:30.860004 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:30.860482 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m13:59:30.861629 [debug] [Thread-6 (]: SQL status: OK in 0.020 seconds
[0m13:59:30.862078 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:30.862480 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m13:59:30.863855 [debug] [Thread-7 (]: SQL status: OK in 0.015 seconds
[0m13:59:30.864275 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:30.864656 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m13:59:32.915943 [debug] [Thread-2 (]: SQL status: OK in 2.057 seconds
[0m13:59:32.968653 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:32.969839 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m13:59:32.981220 [debug] [Thread-2 (]: SQL status: OK in 0.010 seconds
[0m13:59:33.088698 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m13:59:33.089747 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:33.090515 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m13:59:33.153432 [debug] [Thread-2 (]: SQL status: OK in 0.061 seconds
[0m13:59:33.165484 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:33.166521 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m13:59:33.178428 [debug] [Thread-2 (]: SQL status: OK in 0.011 seconds
[0m13:59:33.187307 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m13:59:33.190819 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd275d67550>]}
[0m13:59:33.206005 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 2.50s]
[0m13:59:33.210020 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m13:59:37.400402 [debug] [Thread-7 (]: SQL status: OK in 6.535 seconds
[0m13:59:37.408754 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:37.402442 [debug] [Thread-1 (]: SQL status: OK in 6.551 seconds
[0m13:59:37.409706 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m13:59:37.433411 [debug] [Thread-7 (]: SQL status: OK in 0.004 seconds
[0m13:59:37.436681 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m13:59:37.445026 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:37.445885 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m13:59:37.444137 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:37.447915 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m13:59:37.449396 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:59:37.452695 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m13:59:37.453525 [debug] [Thread-7 (]: SQL status: OK in 0.007 seconds
[0m13:59:37.454402 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:37.459442 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:37.484799 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m13:59:37.487107 [debug] [Thread-7 (]: SQL status: OK in 0.000 seconds
[0m13:59:37.490172 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: Close
[0m13:59:37.491942 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2690e9ab0>]}
[0m13:59:37.493401 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 6.80s]
[0m13:59:37.483707 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m13:59:37.495462 [debug] [Thread-7 (]: Finished running node model.mta.total_riders_per_station
[0m13:59:37.506675 [debug] [Thread-1 (]: SQL status: OK in 0.010 seconds
[0m13:59:37.515752 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:37.516778 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m13:59:37.518435 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:59:37.521428 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m13:59:37.523972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd268e661d0>]}
[0m13:59:37.526347 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 6.84s]
[0m13:59:37.531449 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m13:59:37.768773 [debug] [Thread-4 (]: SQL status: OK in 6.915 seconds
[0m13:59:37.775019 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:37.776154 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
alter table "lake"."main"."hourly_riders__dbt_tmp" rename to "hourly_riders"
[0m13:59:37.789814 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:59:37.793156 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m13:59:37.794101 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:37.794822 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m13:59:37.864914 [debug] [Thread-4 (]: SQL status: OK in 0.069 seconds
[0m13:59:37.873563 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:37.874499 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
drop table if exists "lake"."main"."hourly_riders__dbt_backup" cascade
[0m13:59:37.878787 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m13:59:37.883418 [debug] [Thread-4 (]: On model.mta.hourly_riders: Close
[0m13:59:37.884659 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd261b777f0>]}
[0m13:59:37.885937 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.hourly_riders ........................... [[32mOK[0m in 7.20s]
[0m13:59:37.887318 [debug] [Thread-4 (]: Finished running node model.mta.hourly_riders
[0m13:59:39.606536 [debug] [Thread-3 (]: SQL status: OK in 8.751 seconds
[0m13:59:39.614533 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:39.616002 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m13:59:39.620002 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:59:39.626212 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m13:59:39.644817 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:39.649256 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m13:59:39.667337 [debug] [Thread-3 (]: SQL status: OK in 0.014 seconds
[0m13:59:39.706926 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:39.708317 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m13:59:39.709924 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:59:39.713316 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m13:59:39.718629 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd261b40d90>]}
[0m13:59:39.720810 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 9.03s]
[0m13:59:39.723088 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m13:59:40.540510 [debug] [Thread-6 (]: SQL status: OK in 9.677 seconds
[0m13:59:40.544578 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:40.545137 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m13:59:40.546101 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m13:59:40.547690 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m13:59:40.548091 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:40.548456 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m13:59:40.552503 [debug] [Thread-6 (]: SQL status: OK in 0.004 seconds
[0m13:59:40.555252 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:40.555741 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m13:59:40.556641 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m13:59:40.558051 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: Close
[0m13:59:40.558778 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2680fef50>]}
[0m13:59:40.559455 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 9.87s]
[0m13:59:40.560457 [debug] [Thread-6 (]: Finished running node model.mta.omny_adoption_increase
[0m13:59:40.563904 [debug] [Thread-5 (]: SQL status: OK in 9.703 seconds
[0m13:59:40.567118 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:40.567641 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m13:59:40.568983 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m13:59:40.570581 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m13:59:40.570975 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:40.571291 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m13:59:40.576416 [debug] [Thread-5 (]: SQL status: OK in 0.005 seconds
[0m13:59:40.581270 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:40.581840 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m13:59:40.583884 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m13:59:40.586024 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: Close
[0m13:59:40.667678 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5e5d64e5-4300-46ff-96f8-e12648004637', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd268f39d80>]}
[0m13:59:40.668494 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 9.98s]
[0m13:59:40.669115 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_by_station
[0m13:59:40.672006 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:40.672372 [debug] [MainThread]: On master: BEGIN
[0m13:59:40.672641 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:59:40.685126 [debug] [MainThread]: SQL status: OK in 0.012 seconds
[0m13:59:40.685720 [debug] [MainThread]: On master: COMMIT
[0m13:59:40.686305 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:40.686692 [debug] [MainThread]: On master: COMMIT
[0m13:59:40.687817 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m13:59:40.688206 [debug] [MainThread]: On master: Close
[0m13:59:40.690577 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:59:40.690907 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m13:59:40.691155 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m13:59:40.691375 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m13:59:40.691607 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m13:59:40.691859 [debug] [MainThread]: Connection 'model.mta.hourly_riders' was properly closed.
[0m13:59:40.692119 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m13:59:40.692388 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m13:59:40.692921 [info ] [MainThread]: 
[0m13:59:40.693352 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 10.14 seconds (10.14s).
[0m13:59:40.694787 [debug] [MainThread]: Command end result
[0m13:59:40.721908 [info ] [MainThread]: 
[0m13:59:40.722460 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:59:40.722822 [info ] [MainThread]: 
[0m13:59:40.723142 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m13:59:40.723957 [debug] [MainThread]: Resource report: {"command_name": "build", "command_success": true, "command_wall_clock_time": 11.445572, "process_user_time": 114.76515, "process_kernel_time": 11.114711, "process_mem_max_rss": "455404", "process_in_blocks": "1051680", "process_out_blocks": "13088"}
[0m13:59:40.724677 [debug] [MainThread]: Command `dbt build` succeeded at 13:59:40.724565 after 11.45 seconds
[0m13:59:40.725058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd275cdb430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2749fc1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2743f82b0>]}
[0m13:59:40.725396 [debug] [MainThread]: Flushing usage events
[0m13:59:47.069309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9f57400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9b2c3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce8601ea0>]}


============================== 13:59:47.071238 | 10933252-4b8d-453d-9424-60060e9d47d7 ==============================
[0m13:59:47.071238 [info ] [MainThread]: Running with dbt=1.8.7
[0m13:59:47.071728 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:59:47.241594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce85a60e0>]}
[0m13:59:47.296891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9262800>]}
[0m13:59:47.299404 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m13:59:47.306719 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m13:59:47.384899 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:59:47.385345 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:59:47.412358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdd1398d0>]}
[0m13:59:47.475656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdd2cdde0>]}
[0m13:59:47.476267 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m13:59:47.476679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdd2cec80>]}
[0m13:59:47.478263 [info ] [MainThread]: 
[0m13:59:47.478855 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m13:59:47.483074 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m13:59:47.509664 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m13:59:47.511625 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m13:59:47.512149 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:59:47.521672 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m13:59:47.522948 [debug] [ThreadPool]: On list_lake: Close
[0m13:59:47.527149 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m13:59:47.528730 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m13:59:47.534289 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:47.534801 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m13:59:47.535083 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:47.542662 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:59:47.544144 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:47.544668 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m13:59:47.545271 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:47.545510 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:47.545728 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m13:59:47.546243 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:47.546851 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m13:59:47.547077 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m13:59:47.547268 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m13:59:47.547669 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:59:47.547905 [debug] [ThreadPool]: On create_lake_main: Close
[0m13:59:47.551376 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m13:59:47.556076 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m13:59:47.556560 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m13:59:47.556854 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m13:59:47.563701 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m13:59:47.564226 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m13:59:47.564820 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m13:59:47.581708 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m13:59:47.586965 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m13:59:47.587581 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m13:59:47.587915 [debug] [ThreadPool]: On list_lake_main: Close
[0m13:59:47.591814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce8706d40>]}
[0m13:59:47.592207 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:47.592475 [debug] [MainThread]: On master: BEGIN
[0m13:59:47.592701 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:59:47.597864 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m13:59:47.598141 [debug] [MainThread]: On master: COMMIT
[0m13:59:47.598358 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:47.598561 [debug] [MainThread]: On master: COMMIT
[0m13:59:47.598897 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:59:47.599121 [debug] [MainThread]: On master: Close
[0m13:59:47.600452 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m13:59:47.600767 [info ] [MainThread]: 
[0m13:59:47.610707 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m13:59:47.611376 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m13:59:47.611934 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m13:59:47.613299 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m13:59:47.613823 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m13:59:47.614382 [debug] [Thread-4 (]: Began running node model.mta.hourly_riders
[0m13:59:47.615283 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_by_station
[0m13:59:47.614918 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m13:59:47.615875 [debug] [Thread-6 (]: Began running node model.mta.omny_adoption_increase
[0m13:59:47.616322 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m13:59:47.617235 [debug] [Thread-7 (]: Began running node model.mta.total_riders_per_station
[0m13:59:47.616818 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m13:59:47.618920 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m13:59:47.620867 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m13:59:47.621721 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m13:59:47.622414 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m13:59:47.629633 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m13:59:47.630523 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m13:59:47.631715 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m13:59:47.632587 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.hourly_riders'
[0m13:59:47.633180 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_by_station)
[0m13:59:47.633699 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m13:59:47.634275 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m13:59:47.635801 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m13:59:47.636870 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m13:59:47.637943 [debug] [Thread-4 (]: Began compiling node model.mta.hourly_riders
[0m13:59:47.638623 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m13:59:47.639094 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_by_station
[0m13:59:47.642685 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m13:59:47.643338 [debug] [Thread-6 (]: Began compiling node model.mta.omny_adoption_increase
[0m13:59:47.644094 [debug] [Thread-7 (]: Began compiling node model.mta.total_riders_per_station
[0m13:59:47.647334 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m13:59:47.649933 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.hourly_riders"
[0m13:59:47.674722 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m13:59:47.684309 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m13:59:47.685087 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m13:59:47.738184 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m13:59:47.740254 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m13:59:47.741066 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m13:59:47.741789 [debug] [Thread-4 (]: Began executing node model.mta.hourly_riders
[0m13:59:47.742361 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_by_station
[0m13:59:47.745931 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m13:59:47.746480 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:47.750420 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m13:59:47.750937 [debug] [Thread-7 (]: Began executing node model.mta.total_riders_per_station
[0m13:59:47.754444 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.hourly_riders"
[0m13:59:47.754996 [debug] [Thread-6 (]: Began executing node model.mta.omny_adoption_increase
[0m13:59:47.758285 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m13:59:47.759192 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m13:59:47.763555 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m13:59:47.764854 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:47.765533 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:47.766273 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:47.770358 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m13:59:47.771376 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:59:47.772219 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m13:59:47.773049 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:47.773460 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m13:59:47.773813 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:47.774366 [debug] [Thread-4 (]: On model.mta.hourly_riders: BEGIN
[0m13:59:47.780379 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:59:47.781189 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:47.781644 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m13:59:47.782242 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m13:59:47.782633 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m13:59:47.783064 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: BEGIN
[0m13:59:47.783459 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m13:59:47.784012 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: BEGIN
[0m13:59:47.784426 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m13:59:47.785014 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:47.785418 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m13:59:47.786245 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:59:47.787803 [debug] [Thread-3 (]: SQL status: OK in 0.007 seconds
[0m13:59:47.788208 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m13:59:47.788927 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:47.789861 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m13:59:47.790667 [debug] [Thread-2 (]: SQL status: OK in 0.008 seconds
[0m13:59:47.791468 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:47.792018 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m13:59:47.793291 [debug] [Thread-4 (]: SQL status: OK in 0.010 seconds
[0m13:59:47.793706 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:47.794954 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m13:59:47.796487 [debug] [Thread-5 (]: SQL status: OK in 0.012 seconds
[0m13:59:47.796877 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:47.797278 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m13:59:47.798387 [debug] [Thread-7 (]: SQL status: OK in 0.013 seconds
[0m13:59:47.798938 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:47.799346 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m13:59:47.803512 [debug] [Thread-6 (]: SQL status: OK in 0.017 seconds
[0m13:59:47.803996 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:47.804494 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m13:59:49.555606 [debug] [Thread-1 (]: SQL status: OK in 1.766 seconds
[0m13:59:49.610117 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:49.633952 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day" rename to "avg_riders_per_day__dbt_backup"
[0m13:59:49.635806 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:59:49.646322 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:49.648991 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m13:59:49.650297 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m13:59:49.754294 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m13:59:49.755433 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:49.756551 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m13:59:49.790245 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m13:59:49.819211 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m13:59:49.820080 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m13:59:49.832828 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m13:59:49.837330 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m13:59:49.840076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdc525600>]}
[0m13:59:49.841522 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 2.23s]
[0m13:59:49.842666 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m13:59:51.265619 [debug] [Thread-2 (]: SQL status: OK in 3.473 seconds
[0m13:59:51.271799 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:51.272895 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times" rename to "busiest_specific_times__dbt_backup"
[0m13:59:51.296555 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:59:51.306082 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:51.308130 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m13:59:51.311415 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m13:59:51.317483 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m13:59:51.334977 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:51.335784 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m13:59:51.343279 [debug] [Thread-2 (]: SQL status: OK in 0.006 seconds
[0m13:59:51.348453 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m13:59:51.349224 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m13:59:51.356125 [debug] [Thread-2 (]: SQL status: OK in 0.006 seconds
[0m13:59:51.359755 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m13:59:51.361136 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce8529e40>]}
[0m13:59:51.362310 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 3.74s]
[0m13:59:51.363320 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m13:59:53.766020 [debug] [Thread-6 (]: SQL status: OK in 5.961 seconds
[0m13:59:53.771415 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:53.785004 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase" rename to "omny_adoption_increase__dbt_backup"
[0m13:59:53.786502 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m13:59:53.792002 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:53.792917 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m13:59:53.819155 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m13:59:53.823087 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m13:59:53.823845 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:53.824853 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m13:59:53.843063 [debug] [Thread-6 (]: SQL status: OK in 0.017 seconds
[0m13:59:53.847716 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m13:59:53.848516 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m13:59:53.854802 [debug] [Thread-6 (]: SQL status: OK in 0.005 seconds
[0m13:59:53.857752 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: Close
[0m13:59:53.859111 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdc5ae050>]}
[0m13:59:53.860261 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 6.22s]
[0m13:59:53.861354 [debug] [Thread-6 (]: Finished running node model.mta.omny_adoption_increase
[0m13:59:54.025953 [debug] [Thread-7 (]: SQL status: OK in 6.226 seconds
[0m13:59:54.045722 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:54.046862 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station" rename to "total_riders_per_station__dbt_backup"
[0m13:59:54.048450 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m13:59:54.054874 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:54.055769 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m13:59:54.057076 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m13:59:54.060362 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m13:59:54.075023 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:54.075813 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m13:59:54.082290 [debug] [Thread-5 (]: SQL status: OK in 6.284 seconds
[0m13:59:54.088969 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:54.089832 [debug] [Thread-7 (]: SQL status: OK in 0.013 seconds
[0m13:59:54.104916 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station" rename to "omny_adoption_by_station__dbt_backup"
[0m13:59:54.112222 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m13:59:54.113114 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m13:59:54.114226 [debug] [Thread-5 (]: SQL status: OK in 0.003 seconds
[0m13:59:54.119619 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:54.121087 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m13:59:54.124474 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m13:59:54.128860 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m13:59:54.137555 [debug] [Thread-7 (]: SQL status: OK in 0.024 seconds
[0m13:59:54.138452 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:54.143288 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: Close
[0m13:59:54.145241 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9d72140>]}
[0m13:59:54.146592 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 6.51s]
[0m13:59:54.147957 [debug] [Thread-7 (]: Finished running node model.mta.total_riders_per_station
[0m13:59:54.144178 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m13:59:54.164621 [debug] [Thread-5 (]: SQL status: OK in 0.015 seconds
[0m13:59:54.170224 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m13:59:54.172952 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m13:59:54.196244 [debug] [Thread-5 (]: SQL status: OK in 0.021 seconds
[0m13:59:54.200169 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: Close
[0m13:59:54.201473 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdc5ad4e0>]}
[0m13:59:54.202617 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 6.57s]
[0m13:59:54.203525 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_by_station
[0m13:59:55.138166 [debug] [Thread-4 (]: SQL status: OK in 7.342 seconds
[0m13:59:55.143497 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:55.144451 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
alter table "lake"."main"."hourly_riders" rename to "hourly_riders__dbt_backup"
[0m13:59:55.145766 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m13:59:55.150274 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:55.151007 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
alter table "lake"."main"."hourly_riders__dbt_tmp" rename to "hourly_riders"
[0m13:59:55.152067 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m13:59:55.154729 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m13:59:55.155412 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:55.156107 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m13:59:55.187306 [debug] [Thread-4 (]: SQL status: OK in 0.030 seconds
[0m13:59:55.192186 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m13:59:55.193034 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
drop table if exists "lake"."main"."hourly_riders__dbt_backup" cascade
[0m13:59:55.200632 [debug] [Thread-4 (]: SQL status: OK in 0.007 seconds
[0m13:59:55.203008 [debug] [Thread-4 (]: On model.mta.hourly_riders: Close
[0m13:59:55.203911 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdd143df0>]}
[0m13:59:55.204943 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.hourly_riders ........................... [[32mOK[0m in 7.57s]
[0m13:59:55.205910 [debug] [Thread-4 (]: Finished running node model.mta.hourly_riders
[0m13:59:55.246514 [debug] [Thread-3 (]: SQL status: OK in 7.456 seconds
[0m13:59:55.250029 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:55.250535 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro" rename to "fare_class_boro__dbt_backup"
[0m13:59:55.251494 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m13:59:55.253969 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:55.254325 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m13:59:55.255140 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m13:59:55.256729 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m13:59:55.257084 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:55.257392 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m13:59:55.261171 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m13:59:55.264672 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m13:59:55.265032 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m13:59:55.267931 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m13:59:55.269122 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m13:59:55.335891 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '10933252-4b8d-453d-9424-60060e9d47d7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3cdc39c9a0>]}
[0m13:59:55.336697 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 7.70s]
[0m13:59:55.337262 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m13:59:55.340187 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:55.340518 [debug] [MainThread]: On master: BEGIN
[0m13:59:55.340785 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m13:59:55.347133 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m13:59:55.347633 [debug] [MainThread]: On master: COMMIT
[0m13:59:55.347960 [debug] [MainThread]: Using duckdb connection "master"
[0m13:59:55.348237 [debug] [MainThread]: On master: COMMIT
[0m13:59:55.348802 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m13:59:55.349110 [debug] [MainThread]: On master: Close
[0m13:59:55.351482 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:59:55.352163 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m13:59:55.352435 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m13:59:55.352647 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m13:59:55.352825 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m13:59:55.353010 [debug] [MainThread]: Connection 'model.mta.hourly_riders' was properly closed.
[0m13:59:55.353181 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m13:59:55.353374 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m13:59:55.353770 [info ] [MainThread]: 
[0m13:59:55.354153 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 7.87 seconds (7.87s).
[0m13:59:55.355575 [debug] [MainThread]: Command end result
[0m13:59:55.383951 [info ] [MainThread]: 
[0m13:59:55.384692 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:59:55.385110 [info ] [MainThread]: 
[0m13:59:55.385506 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m13:59:55.386470 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.360214, "process_user_time": 111.31652, "process_kernel_time": 3.601798, "process_mem_max_rss": "465472", "process_in_blocks": "8464", "process_out_blocks": "12304"}
[0m13:59:55.387958 [debug] [MainThread]: Command `dbt run` succeeded at 13:59:55.387706 after 8.36 seconds
[0m13:59:55.388527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9f57400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9262800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ce9297790>]}
[0m13:59:55.388948 [debug] [MainThread]: Flushing usage events
[0m14:33:48.742037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91184cb490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91180765f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9116b76920>]}


============================== 14:33:48.747716 | 0a3fdf4e-a10d-4310-b8a9-752b1db1d197 ==============================
[0m14:33:48.747716 [info ] [MainThread]: Running with dbt=1.8.7
[0m14:33:48.748154 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:33:49.037534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0a3fdf4e-a10d-4310-b8a9-752b1db1d197', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9118590ac0>]}
[0m14:33:49.092287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0a3fdf4e-a10d-4310-b8a9-752b1db1d197', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9116bacfd0>]}
[0m14:33:49.097389 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m14:33:49.106872 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m14:33:49.212250 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:33:49.212616 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:33:49.236517 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0a3fdf4e-a10d-4310-b8a9-752b1db1d197', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910b63d930>]}
[0m14:33:49.305226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0a3fdf4e-a10d-4310-b8a9-752b1db1d197', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910b7d9ff0>]}
[0m14:33:49.305800 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m14:33:49.306168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0a3fdf4e-a10d-4310-b8a9-752b1db1d197', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910b7d85e0>]}
[0m14:33:49.307757 [info ] [MainThread]: 
[0m14:33:49.308280 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:33:49.312581 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m14:33:49.369043 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m14:33:49.369491 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m14:33:49.369782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:49.394903 [debug] [ThreadPool]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m14:33:49.395352 [debug] [ThreadPool]: DuckDB adapter: Rolling back transaction.
[0m14:33:49.396197 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:33:49.396498 [debug] [MainThread]: Connection 'list_lake' was properly closed.
[0m14:33:49.396762 [info ] [MainThread]: 
[0m14:33:49.397071 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.09 seconds (0.09s).
[0m14:33:49.397463 [error] [MainThread]: Encountered an error:
Runtime Error
  IO Error: Could not set lock on file "/home/christianocean/mta/lake.duckdb": Conflicting lock is held in /usr/bin/python3.10 (PID 2444975). See also https://duckdb.org/docs/connect/concurrency
[0m14:33:49.398934 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.7143306, "process_user_time": 1.4682, "process_kernel_time": 0.729106, "process_mem_max_rss": "132932", "process_in_blocks": "4152", "process_out_blocks": "904", "command_success": false}
[0m14:33:49.399390 [debug] [MainThread]: Command `dbt run` failed at 14:33:49.399305 after 0.71 seconds
[0m14:33:49.399704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91184cb490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910b7d8d60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f910b6443a0>]}
[0m14:33:49.400017 [debug] [MainThread]: Flushing usage events
[0m14:33:59.682070 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3b145b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3afcb9e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3afcb8c70>]}


============================== 14:33:59.683919 | d48633a8-45b7-44fe-8f74-8e473e0ed85a ==============================
[0m14:33:59.683919 [info ] [MainThread]: Running with dbt=1.8.7
[0m14:33:59.684391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'version_check': 'True', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m14:33:59.847569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3b1518e20>]}
[0m14:33:59.896316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3afaf8fd0>]}
[0m14:33:59.898794 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m14:33:59.906305 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m14:33:59.986408 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:33:59.986835 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:34:00.012758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a4605930>]}
[0m14:34:00.077348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a479f6a0>]}
[0m14:34:00.077840 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m14:34:00.078192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a479dc60>]}
[0m14:34:00.079588 [info ] [MainThread]: 
[0m14:34:00.080130 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:34:00.084268 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m14:34:00.109791 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m14:34:00.111166 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m14:34:00.111558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:34:00.153690 [debug] [ThreadPool]: SQL status: OK in 0.042 seconds
[0m14:34:00.157194 [debug] [ThreadPool]: On list_lake: Close
[0m14:34:00.159447 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m14:34:00.160189 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m14:34:00.164642 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:34:00.164935 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m14:34:00.165219 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:34:00.174892 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m14:34:00.176082 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:34:00.176407 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m14:34:00.177481 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m14:34:00.177755 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:34:00.177993 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m14:34:00.179075 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m14:34:00.179751 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:34:00.179992 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:34:00.180221 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:34:00.180640 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:34:00.180901 [debug] [ThreadPool]: On create_lake_main: Close
[0m14:34:00.183774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m14:34:00.187645 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:34:00.187927 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m14:34:00.188159 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:34:00.195231 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m14:34:00.195753 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:34:00.196075 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m14:34:00.234037 [debug] [ThreadPool]: SQL status: OK in 0.038 seconds
[0m14:34:00.236680 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m14:34:00.239692 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m14:34:00.240146 [debug] [ThreadPool]: On list_lake_main: Close
[0m14:34:00.245376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a460c370>]}
[0m14:34:00.245916 [debug] [MainThread]: Using duckdb connection "master"
[0m14:34:00.246299 [debug] [MainThread]: On master: BEGIN
[0m14:34:00.246550 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:34:00.252219 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m14:34:00.252523 [debug] [MainThread]: On master: COMMIT
[0m14:34:00.252801 [debug] [MainThread]: Using duckdb connection "master"
[0m14:34:00.253031 [debug] [MainThread]: On master: COMMIT
[0m14:34:00.253429 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:34:00.253667 [debug] [MainThread]: On master: Close
[0m14:34:00.255588 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m14:34:00.256058 [info ] [MainThread]: 
[0m14:34:00.264544 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m14:34:00.265207 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m14:34:00.265962 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m14:34:00.266582 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m14:34:00.267174 [debug] [Thread-4 (]: Began running node model.mta.hourly_riders
[0m14:34:00.267971 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_by_station
[0m14:34:00.267590 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m14:34:00.269569 [debug] [Thread-6 (]: Began running node model.mta.omny_adoption_increase
[0m14:34:00.270713 [debug] [Thread-7 (]: Began running node model.mta.total_riders_per_station
[0m14:34:00.270207 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m14:34:00.271939 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m14:34:00.272862 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m14:34:00.274131 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m14:34:00.276977 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m14:34:00.277973 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m14:34:00.279026 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m14:34:00.279951 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m14:34:00.281263 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m14:34:00.282512 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.hourly_riders'
[0m14:34:00.283337 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_by_station)
[0m14:34:00.284189 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m14:34:00.285529 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m14:34:00.286373 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m14:34:00.287037 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m14:34:00.293233 [debug] [Thread-4 (]: Began compiling node model.mta.hourly_riders
[0m14:34:00.295511 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m14:34:00.296310 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_by_station
[0m14:34:00.300426 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m14:34:00.302858 [debug] [Thread-6 (]: Began compiling node model.mta.omny_adoption_increase
[0m14:34:00.303675 [debug] [Thread-7 (]: Began compiling node model.mta.total_riders_per_station
[0m14:34:00.306920 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m14:34:00.309822 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.hourly_riders"
[0m14:34:00.312851 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m14:34:00.315667 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m14:34:00.316840 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m14:34:00.322175 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m14:34:00.372843 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m14:34:00.374167 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m14:34:00.375259 [debug] [Thread-4 (]: Began executing node model.mta.hourly_riders
[0m14:34:00.391185 [debug] [Thread-6 (]: Began executing node model.mta.omny_adoption_increase
[0m14:34:00.391693 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_by_station
[0m14:34:00.396865 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m14:34:00.399380 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m14:34:00.399791 [debug] [Thread-7 (]: Began executing node model.mta.total_riders_per_station
[0m14:34:00.402226 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m14:34:00.404411 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.hourly_riders"
[0m14:34:00.406727 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m14:34:00.409221 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m14:34:00.410004 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:34:00.412402 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m14:34:00.413001 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:34:00.413607 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:34:00.414342 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:34:00.415309 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:34:00.415649 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m14:34:00.416060 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:34:00.416569 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m14:34:00.416969 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m14:34:00.417498 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: BEGIN
[0m14:34:00.417958 [debug] [Thread-4 (]: On model.mta.hourly_riders: BEGIN
[0m14:34:00.418373 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:34:00.418810 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:34:00.419172 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m14:34:00.419544 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:34:00.419932 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:34:00.420353 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:34:00.420701 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:34:00.421075 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: BEGIN
[0m14:34:00.426567 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m14:34:00.428021 [debug] [Thread-2 (]: SQL status: OK in 0.009 seconds
[0m14:34:00.428670 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:34:00.429377 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:34:00.430257 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:34:00.430673 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m14:34:00.431651 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:34:00.432020 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:34:00.434091 [debug] [Thread-3 (]: SQL status: OK in 0.014 seconds
[0m14:34:00.434532 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:34:00.434894 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:34:00.436914 [debug] [Thread-6 (]: SQL status: OK in 0.017 seconds
[0m14:34:00.437361 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:34:00.437786 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m14:34:00.440155 [debug] [Thread-4 (]: SQL status: OK in 0.019 seconds
[0m14:34:00.440818 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:34:00.441238 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m14:34:00.442802 [debug] [Thread-5 (]: SQL status: OK in 0.016 seconds
[0m14:34:00.443226 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:34:00.443621 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m14:34:00.445007 [debug] [Thread-7 (]: SQL status: OK in 0.016 seconds
[0m14:34:00.445384 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:34:00.445704 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:34:04.244295 [debug] [Thread-2 (]: SQL status: OK in 3.813 seconds
[0m14:34:04.275247 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:34:04.276138 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m14:34:04.285336 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m14:34:04.397526 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m14:34:04.398480 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:34:04.399137 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m14:34:04.413261 [debug] [Thread-2 (]: SQL status: OK in 0.013 seconds
[0m14:34:04.425739 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:34:04.444738 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m14:34:04.446755 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m14:34:04.437922 [debug] [Thread-1 (]: SQL status: OK in 4.005 seconds
[0m14:34:04.458772 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:34:04.461525 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m14:34:04.463520 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:34:04.451385 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m14:34:04.501975 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m14:34:04.515126 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:34:04.515980 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m14:34:04.521701 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a5c610>]}
[0m14:34:04.523358 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 4.24s]
[0m14:34:04.524523 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m14:34:04.526307 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:34:04.530686 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:34:04.531570 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m14:34:04.532955 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m14:34:04.535901 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m14:34:04.537255 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a75360>]}
[0m14:34:04.538489 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 4.27s]
[0m14:34:04.539923 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m14:34:07.533219 [debug] [Thread-3 (]: SQL status: OK in 7.098 seconds
[0m14:34:07.547741 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:34:07.548649 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m14:34:07.565270 [debug] [Thread-3 (]: SQL status: OK in 0.016 seconds
[0m14:34:07.575984 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m14:34:07.576988 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:34:07.577613 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m14:34:07.585914 [debug] [Thread-3 (]: SQL status: OK in 0.007 seconds
[0m14:34:07.591965 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:34:07.593168 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m14:34:07.595113 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m14:34:07.597486 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m14:34:07.598394 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a76500>]}
[0m14:34:07.599378 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 7.32s]
[0m14:34:07.601140 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m14:34:08.071149 [debug] [Thread-4 (]: SQL status: OK in 7.629 seconds
[0m14:34:08.108189 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:34:08.109043 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
alter table "lake"."main"."hourly_riders__dbt_tmp" rename to "hourly_riders"
[0m14:34:08.110444 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m14:34:08.113146 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m14:34:08.114008 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:34:08.114722 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m14:34:08.209383 [debug] [Thread-4 (]: SQL status: OK in 0.094 seconds
[0m14:34:08.214688 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:34:08.215849 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
drop table if exists "lake"."main"."hourly_riders__dbt_backup" cascade
[0m14:34:08.217192 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m14:34:08.219536 [debug] [Thread-4 (]: On model.mta.hourly_riders: Close
[0m14:34:08.230850 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a74ac0>]}
[0m14:34:08.232274 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.hourly_riders ........................... [[32mOK[0m in 7.95s]
[0m14:34:08.233794 [debug] [Thread-4 (]: Finished running node model.mta.hourly_riders
[0m14:34:08.410436 [debug] [Thread-6 (]: SQL status: OK in 7.972 seconds
[0m14:34:08.417833 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:34:08.418755 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m14:34:08.420423 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m14:34:08.423949 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m14:34:08.446967 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:34:08.447738 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m14:34:08.458813 [debug] [Thread-6 (]: SQL status: OK in 0.010 seconds
[0m14:34:08.465448 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:34:08.466285 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m14:34:08.467444 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m14:34:08.470006 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: Close
[0m14:34:08.471273 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a74ca0>]}
[0m14:34:08.472440 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 8.19s]
[0m14:34:08.473722 [debug] [Thread-6 (]: Finished running node model.mta.omny_adoption_increase
[0m14:34:08.698780 [debug] [Thread-7 (]: SQL status: OK in 8.253 seconds
[0m14:34:08.705175 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:34:08.706228 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m14:34:08.707780 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m14:34:08.710749 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m14:34:08.711559 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:34:08.712188 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m14:34:08.739876 [debug] [Thread-7 (]: SQL status: OK in 0.027 seconds
[0m14:34:08.744613 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:34:08.745358 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m14:34:08.746422 [debug] [Thread-7 (]: SQL status: OK in 0.000 seconds
[0m14:34:08.748726 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: Close
[0m14:34:08.762064 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a75cf0>]}
[0m14:34:08.763284 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 8.48s]
[0m14:34:08.764248 [debug] [Thread-7 (]: Finished running node model.mta.total_riders_per_station
[0m14:34:08.882056 [debug] [Thread-5 (]: SQL status: OK in 8.438 seconds
[0m14:34:08.885962 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:34:08.886347 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m14:34:08.887056 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m14:34:08.888272 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m14:34:08.888600 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:34:08.888899 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m14:34:08.892762 [debug] [Thread-5 (]: SQL status: OK in 0.004 seconds
[0m14:34:08.895075 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:34:08.895447 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m14:34:08.896187 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m14:34:08.897309 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: Close
[0m14:34:08.970801 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd48633a8-45b7-44fe-8f74-8e473e0ed85a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a3a51c60>]}
[0m14:34:08.971599 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 8.69s]
[0m14:34:08.972166 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_by_station
[0m14:34:08.974880 [debug] [MainThread]: Using duckdb connection "master"
[0m14:34:08.975467 [debug] [MainThread]: On master: BEGIN
[0m14:34:08.975824 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:34:08.981712 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m14:34:08.982210 [debug] [MainThread]: On master: COMMIT
[0m14:34:08.982522 [debug] [MainThread]: Using duckdb connection "master"
[0m14:34:08.982794 [debug] [MainThread]: On master: COMMIT
[0m14:34:08.983294 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:34:08.983618 [debug] [MainThread]: On master: Close
[0m14:34:08.985526 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:34:08.985928 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m14:34:08.986186 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m14:34:08.986405 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m14:34:08.986611 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m14:34:08.986811 [debug] [MainThread]: Connection 'model.mta.hourly_riders' was properly closed.
[0m14:34:08.987012 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m14:34:08.987216 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m14:34:08.987566 [info ] [MainThread]: 
[0m14:34:08.987915 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 8.91 seconds (8.91s).
[0m14:34:08.989069 [debug] [MainThread]: Command end result
[0m14:34:09.018060 [info ] [MainThread]: 
[0m14:34:09.018573 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:34:09.018907 [info ] [MainThread]: 
[0m14:34:09.019200 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:34:09.019893 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.381788, "process_user_time": 111.56231, "process_kernel_time": 17.613008, "process_mem_max_rss": "481448", "process_in_blocks": "2784", "process_out_blocks": "12240"}
[0m14:34:09.020390 [debug] [MainThread]: Command `dbt run` succeeded at 14:34:09.020302 after 9.38 seconds
[0m14:34:09.020736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3b145b460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3ac8fe4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3a4821db0>]}
[0m14:34:09.021079 [debug] [MainThread]: Flushing usage events
[0m14:45:49.474515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050e047430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c6f1c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c6f35b0>]}


============================== 14:45:49.478625 | 18c0b9bd-2b41-4d6e-abd0-7abb284dd787 ==============================
[0m14:45:49.478625 [info ] [MainThread]: Running with dbt=1.8.7
[0m14:45:49.479043 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:45:49.652601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050e104e20>]}
[0m14:45:49.703648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050d39c6a0>]}
[0m14:45:49.707552 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m14:45:49.717443 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m14:45:49.818522 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:45:49.818868 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:45:49.843218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050123d900>]}
[0m14:45:49.919912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05013dbe80>]}
[0m14:45:49.920510 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m14:45:49.920874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05013d9ff0>]}
[0m14:45:49.922561 [info ] [MainThread]: 
[0m14:45:49.923091 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:45:49.927709 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m14:45:50.059999 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m14:45:50.060471 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m14:45:50.060743 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:45:50.087040 [debug] [ThreadPool]: SQL status: OK in 0.026 seconds
[0m14:45:50.088268 [debug] [ThreadPool]: On list_lake: Close
[0m14:45:50.090410 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m14:45:50.091128 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m14:45:50.096012 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:45:50.096325 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m14:45:50.096571 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:50.102541 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m14:45:50.103973 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:45:50.104304 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m14:45:50.104857 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:50.105155 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:45:50.105408 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m14:45:50.107201 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m14:45:50.107880 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:45:50.108166 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:45:50.108405 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:45:50.108797 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:45:50.109066 [debug] [ThreadPool]: On create_lake_main: Close
[0m14:45:50.111676 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m14:45:50.115815 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:45:50.116117 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m14:45:50.116359 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:45:50.121420 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m14:45:50.121743 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:45:50.122013 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m14:45:50.140212 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m14:45:50.141391 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m14:45:50.142697 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m14:45:50.142966 [debug] [ThreadPool]: On list_lake_main: Close
[0m14:45:50.145680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c7f7700>]}
[0m14:45:50.146040 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:50.146315 [debug] [MainThread]: On master: BEGIN
[0m14:45:50.146572 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:45:50.152441 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m14:45:50.152813 [debug] [MainThread]: On master: COMMIT
[0m14:45:50.153093 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:50.153335 [debug] [MainThread]: On master: COMMIT
[0m14:45:50.153765 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:45:50.154016 [debug] [MainThread]: On master: Close
[0m14:45:50.155506 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m14:45:50.155876 [info ] [MainThread]: 
[0m14:45:50.161274 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m14:45:50.161758 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m14:45:50.162229 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m14:45:50.162809 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m14:45:50.163505 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m14:45:50.164627 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m14:45:50.165327 [debug] [Thread-4 (]: Began running node model.mta.hourly_riders
[0m14:45:50.166720 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_by_station
[0m14:45:50.167285 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m14:45:50.167834 [debug] [Thread-6 (]: Began running node model.mta.omny_adoption_increase
[0m14:45:50.168359 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m14:45:50.168794 [debug] [Thread-7 (]: Began running node model.mta.total_riders_per_station
[0m14:45:50.169328 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m14:45:50.169892 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m14:45:50.170877 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m14:45:50.172133 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m14:45:50.173089 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m14:45:50.173662 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m14:45:50.174255 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m14:45:50.182849 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m14:45:50.183757 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.hourly_riders'
[0m14:45:50.184449 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_by_station)
[0m14:45:50.184925 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m14:45:50.185446 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m14:45:50.188125 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m14:45:50.188874 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m14:45:50.189704 [debug] [Thread-4 (]: Began compiling node model.mta.hourly_riders
[0m14:45:50.190286 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_by_station
[0m14:45:50.190684 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m14:45:50.195121 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m14:45:50.195713 [debug] [Thread-6 (]: Began compiling node model.mta.omny_adoption_increase
[0m14:45:50.196352 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m14:45:50.196757 [debug] [Thread-7 (]: Began compiling node model.mta.total_riders_per_station
[0m14:45:50.199129 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.hourly_riders"
[0m14:45:50.202231 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m14:45:50.241960 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m14:45:50.286475 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m14:45:50.289304 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m14:45:50.292634 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m14:45:50.293052 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m14:45:50.294024 [debug] [Thread-4 (]: Began executing node model.mta.hourly_riders
[0m14:45:50.294766 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:45:50.295574 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_by_station
[0m14:45:50.296183 [debug] [Thread-6 (]: Began executing node model.mta.omny_adoption_increase
[0m14:45:50.296649 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:45:50.299455 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m14:45:50.302017 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.hourly_riders"
[0m14:45:50.302454 [debug] [Thread-7 (]: Began executing node model.mta.total_riders_per_station
[0m14:45:50.302807 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m14:45:50.305297 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m14:45:50.308349 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m14:45:50.308807 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m14:45:50.309353 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:45:50.313097 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m14:45:50.313916 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:45:50.314967 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:45:50.316533 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:45:50.317145 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:45:50.317866 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m14:45:50.330039 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:45:50.331252 [debug] [Thread-4 (]: On model.mta.hourly_riders: BEGIN
[0m14:45:50.332122 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:45:50.333196 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m14:45:50.335034 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:45:50.336285 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m14:45:50.337155 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: BEGIN
[0m14:45:50.337969 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:45:50.338450 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: BEGIN
[0m14:45:50.338978 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m14:45:50.339451 [debug] [Thread-2 (]: SQL status: OK in 0.022 seconds
[0m14:45:50.340053 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:45:50.340658 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:45:50.341394 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:45:50.342008 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:45:50.343074 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:45:50.343714 [debug] [Thread-3 (]: SQL status: OK in 0.009 seconds
[0m14:45:50.344902 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:45:50.345378 [debug] [Thread-4 (]: SQL status: OK in 0.007 seconds
[0m14:45:50.346183 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:45:50.347359 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:45:50.348801 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:45:50.349465 [debug] [Thread-5 (]: SQL status: OK in 0.010 seconds
[0m14:45:50.349955 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m14:45:50.350991 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:45:50.353200 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m14:45:50.354892 [debug] [Thread-7 (]: SQL status: OK in 0.014 seconds
[0m14:45:50.356097 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:45:50.356982 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:45:50.358104 [debug] [Thread-6 (]: SQL status: OK in 0.017 seconds
[0m14:45:50.358593 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:45:50.359020 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m14:45:50.376059 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:45:50.376869 [debug] [Thread-7 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:45:50.377352 [debug] [Thread-6 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m14:45:50.377838 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m14:45:50.378235 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:45:50.378662 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:45:50.379135 [debug] [Thread-5 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m14:45:50.379488 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.380171 [debug] [Thread-7 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.380543 [debug] [Thread-6 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.380985 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.381367 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.381842 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.382237 [debug] [Thread-5 (]: DuckDB adapter: Rolling back transaction.
[0m14:45:50.382732 [debug] [Thread-3 (]: On model.mta.fare_class_boro: ROLLBACK
[0m14:45:50.383219 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: ROLLBACK
[0m14:45:50.383670 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: ROLLBACK
[0m14:45:50.384114 [debug] [Thread-4 (]: On model.mta.hourly_riders: ROLLBACK
[0m14:45:50.384589 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: ROLLBACK
[0m14:45:50.385027 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: ROLLBACK
[0m14:45:50.385463 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: ROLLBACK
[0m14:45:50.407871 [debug] [Thread-7 (]: Failed to rollback 'model.mta.total_riders_per_station'
[0m14:45:50.408786 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: Close
[0m14:45:50.409566 [debug] [Thread-4 (]: Failed to rollback 'model.mta.hourly_riders'
[0m14:45:50.410151 [debug] [Thread-6 (]: Failed to rollback 'model.mta.omny_adoption_increase'
[0m14:45:50.410704 [debug] [Thread-2 (]: Failed to rollback 'model.mta.busiest_specific_times'
[0m14:45:50.411838 [debug] [Thread-1 (]: Failed to rollback 'model.mta.avg_riders_per_day'
[0m14:45:50.412393 [debug] [Thread-3 (]: Failed to rollback 'model.mta.fare_class_boro'
[0m14:45:50.413047 [debug] [Thread-4 (]: On model.mta.hourly_riders: Close
[0m14:45:50.413793 [debug] [Thread-7 (]: Runtime Error in model total_riders_per_station (models/total_riders_per_station.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 18:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, station_complex, latitude, longitude
  ORDER BY 
      total_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.414441 [debug] [Thread-5 (]: Failed to rollback 'model.mta.omny_adoption_by_station'
[0m14:45:50.414773 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: Close
[0m14:45:50.415156 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m14:45:50.415525 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m14:45:50.415882 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m14:45:50.417679 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c6962f0>]}
[0m14:45:50.418462 [debug] [Thread-4 (]: Runtime Error in model hourly_riders (models/hourly_riders.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 17:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, 
      station_complex, 
      date
  ORDER BY 
      date, total_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.418846 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: Close
[0m14:45:50.421142 [debug] [Thread-6 (]: Runtime Error in model omny_adoption_increase (models/omny_adoption_increase.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 22:         "lake"."main"."mta_hourly_subway_socrata"
      WHERE 
          EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_percentage_by_station AS (
      -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
      SELECT 
          station_complex_id, 
          station_complex, 
          latitude, 
          longitude, 
          year, 
          (omny_ridership / total_ridership) AS omny_percentage
      FROM 
          omny_ridership_by_station_year
  )
  SELECT 
      s2023.station_complex_id AS station_id, 
      s2023.station_complex AS station_name,
      s2023.latitude,
      s2023.longitude,
      s2023.omny_percentage AS omny_percentage_2023,
      s2024.omny_percentage AS omny_percentage_2024,
      (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
  FROM 
      omny_percentage_by_station s2023
  JOIN 
      omny_percentage_by_station s2024 
      ON s2023.station_complex_id = s2024.station_complex_id
      AND s2023.latitude = s2024.latitude
      AND s2023.longitude = s2024.longitude
      AND s2023.year = 2023
      AND s2024.year = 2024
  WHERE 
      s2024.omny_percentage > s2023.omny_percentage
  ORDER BY 
      omny_percentage_increase DESC
      );
    
    ...
                   ^
[0m14:45:50.422376 [debug] [Thread-2 (]: Runtime Error in model busiest_specific_times (models/busiest_specific_times.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 15:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      transit_hour
  ORDER BY 
      average_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.423312 [debug] [Thread-1 (]: Runtime Error in model avg_riders_per_day (models/avg_riders_per_day.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 19:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, 
      station_complex, 
      latitude, 
      longitude, 
      day_of_week
  ORDER BY 
      average_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.424012 [error] [Thread-7 (]: 7 of 7 ERROR creating sql table model main.total_riders_per_station ............ [[31mERROR[0m in 0.23s]
[0m14:45:50.425016 [debug] [Thread-3 (]: Runtime Error in model fare_class_boro (models/fare_class_boro.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 36:         "lake"."main"."mta_hourly_subway_socrata"
      GROUP BY 
          borough, fare_class_category, day_type
  )
  SELECT 
      r.borough, 
      r.fare_class_category, 
      r.day_type,
      r.total_ridership, 
      ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
  FROM 
      ridership_by_fare_class r
  JOIN 
      total_ridership_per_borough_daytype t
      ON r.borough = t.borough 
      AND r.day_type = t.day_type
  ORDER BY 
      total_ridership DESC
      );
    
    ...
                   ^
[0m14:45:50.425511 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050057b070>]}
[0m14:45:50.431384 [debug] [Thread-5 (]: Runtime Error in model omny_adoption_by_station (models/omny_adoption_by_station.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 21:         "lake"."main"."mta_hourly_subway_socrata"
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_ridership_by_station AS (
      -- Calculate OMNY ridership by station, year, latitude, and longitude
      SELECT 
          station_complex_id, 
          latitude, 
          longitude, 
          EXTRACT(YEAR FROM transit_timestamp) AS year, 
          SUM(ridership) AS omny_ridership
      FROM 
          "lake"."main"."mta_hourly_subway_socrata"
      WHERE 
          payment_method = 'omny'
      GROUP BY 
          station_complex_id, latitude, longitude, year
  )
  SELECT 
      t.station_complex_id AS station_id,
      t.station_complex AS station_name,
      t.latitude,
      t.longitude,
      t.year, 
      (o.omny_ridership / t.total_ridership) AS omny_percentage
  FROM 
      total_ridership_by_station t
  LEFT JOIN 
      omny_ridership_by_station o
      ON t.station_complex_id = o.station_complex_id 
      AND t.latitude = o.latitude
      AND t.longitude = o.longitude
      AND t.year = o.year
  ORDER BY 
      t.year, omny_percentage DESC
      );
    
    ...
                   ^
[0m14:45:50.432611 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050055f640>]}
[0m14:45:50.434123 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c656290>]}
[0m14:45:50.435178 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05005bd4b0>]}
[0m14:45:50.436311 [debug] [Thread-7 (]: Finished running node model.mta.total_riders_per_station
[0m14:45:50.437220 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0500694460>]}
[0m14:45:50.438347 [error] [Thread-4 (]: 4 of 7 ERROR creating sql table model main.hourly_riders ....................... [[31mERROR[0m in 0.24s]
[0m14:45:50.439525 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '18c0b9bd-2b41-4d6e-abd0-7abb284dd787', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0500591510>]}
[0m14:45:50.440621 [error] [Thread-6 (]: 6 of 7 ERROR creating sql table model main.omny_adoption_increase .............. [[31mERROR[0m in 0.25s]
[0m14:45:50.441837 [error] [Thread-2 (]: 2 of 7 ERROR creating sql table model main.busiest_specific_times .............. [[31mERROR[0m in 0.27s]
[0m14:45:50.443034 [error] [Thread-1 (]: 1 of 7 ERROR creating sql table model main.avg_riders_per_day .................. [[31mERROR[0m in 0.27s]
[0m14:45:50.447770 [error] [Thread-3 (]: 3 of 7 ERROR creating sql table model main.fare_class_boro ..................... [[31mERROR[0m in 0.27s]
[0m14:45:50.451224 [debug] [Thread-4 (]: Finished running node model.mta.hourly_riders
[0m14:45:50.453870 [debug] [Thread-6 (]: Finished running node model.mta.omny_adoption_increase
[0m14:45:50.452836 [error] [Thread-5 (]: 5 of 7 ERROR creating sql table model main.omny_adoption_by_station ............ [[31mERROR[0m in 0.26s]
[0m14:45:50.455252 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m14:45:50.456365 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m14:45:50.457733 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m14:45:50.461615 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_by_station
[0m14:45:50.466197 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:50.466733 [debug] [MainThread]: On master: BEGIN
[0m14:45:50.467086 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:45:50.480532 [debug] [MainThread]: SQL status: OK in 0.013 seconds
[0m14:45:50.483088 [debug] [MainThread]: On master: COMMIT
[0m14:45:50.483884 [debug] [MainThread]: Using duckdb connection "master"
[0m14:45:50.484320 [debug] [MainThread]: On master: COMMIT
[0m14:45:50.485690 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m14:45:50.486190 [debug] [MainThread]: On master: Close
[0m14:45:50.489721 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:45:50.491396 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m14:45:50.491856 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m14:45:50.492135 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m14:45:50.492333 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m14:45:50.492530 [debug] [MainThread]: Connection 'model.mta.hourly_riders' was properly closed.
[0m14:45:50.492746 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m14:45:50.492919 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m14:45:50.493318 [info ] [MainThread]: 
[0m14:45:50.493693 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m14:45:50.494992 [debug] [MainThread]: Command end result
[0m14:45:50.520366 [info ] [MainThread]: 
[0m14:45:50.520988 [info ] [MainThread]: [31mCompleted with 7 errors and 0 warnings:[0m
[0m14:45:50.521355 [info ] [MainThread]: 
[0m14:45:50.521786 [error] [MainThread]:   Runtime Error in model total_riders_per_station (models/total_riders_per_station.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 18:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, station_complex, latitude, longitude
  ORDER BY 
      total_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.522096 [info ] [MainThread]: 
[0m14:45:50.522434 [error] [MainThread]:   Runtime Error in model hourly_riders (models/hourly_riders.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 17:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, 
      station_complex, 
      date
  ORDER BY 
      date, total_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.522706 [info ] [MainThread]: 
[0m14:45:50.523113 [error] [MainThread]:   Runtime Error in model omny_adoption_increase (models/omny_adoption_increase.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 22:         "lake"."main"."mta_hourly_subway_socrata"
      WHERE 
          EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_percentage_by_station AS (
      -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
      SELECT 
          station_complex_id, 
          station_complex, 
          latitude, 
          longitude, 
          year, 
          (omny_ridership / total_ridership) AS omny_percentage
      FROM 
          omny_ridership_by_station_year
  )
  SELECT 
      s2023.station_complex_id AS station_id, 
      s2023.station_complex AS station_name,
      s2023.latitude,
      s2023.longitude,
      s2023.omny_percentage AS omny_percentage_2023,
      s2024.omny_percentage AS omny_percentage_2024,
      (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
  FROM 
      omny_percentage_by_station s2023
  JOIN 
      omny_percentage_by_station s2024 
      ON s2023.station_complex_id = s2024.station_complex_id
      AND s2023.latitude = s2024.latitude
      AND s2023.longitude = s2024.longitude
      AND s2023.year = 2023
      AND s2024.year = 2024
  WHERE 
      s2024.omny_percentage > s2023.omny_percentage
  ORDER BY 
      omny_percentage_increase DESC
      );
    
    ...
                   ^
[0m14:45:50.523524 [info ] [MainThread]: 
[0m14:45:50.523855 [error] [MainThread]:   Runtime Error in model busiest_specific_times (models/busiest_specific_times.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 15:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      transit_hour
  ORDER BY 
      average_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.524135 [info ] [MainThread]: 
[0m14:45:50.524516 [error] [MainThread]:   Runtime Error in model avg_riders_per_day (models/avg_riders_per_day.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 19:     "lake"."main"."mta_hourly_subway_socrata"
  GROUP BY 
      station_complex_id, 
      station_complex, 
      latitude, 
      longitude, 
      day_of_week
  ORDER BY 
      average_ridership DESC
      );
    
    ...
               ^
[0m14:45:50.524796 [info ] [MainThread]: 
[0m14:45:50.525151 [error] [MainThread]:   Runtime Error in model fare_class_boro (models/fare_class_boro.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 36:         "lake"."main"."mta_hourly_subway_socrata"
      GROUP BY 
          borough, fare_class_category, day_type
  )
  SELECT 
      r.borough, 
      r.fare_class_category, 
      r.day_type,
      r.total_ridership, 
      ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
  FROM 
      ridership_by_fare_class r
  JOIN 
      total_ridership_per_borough_daytype t
      ON r.borough = t.borough 
      AND r.day_type = t.day_type
  ORDER BY 
      total_ridership DESC
      );
    
    ...
                   ^
[0m14:45:50.525554 [info ] [MainThread]: 
[0m14:45:50.526004 [error] [MainThread]:   Runtime Error in model omny_adoption_by_station (models/omny_adoption_by_station.sql)
  Catalog Error: Table with name mta_hourly_subway_socrata does not exist!
  Did you mean "mta_daily_subway_socrata"?
  LINE 21:         "lake"."main"."mta_hourly_subway_socrata"
      GROUP BY 
          station_complex_id, station_complex, latitude, longitude, year
  ),
  omny_ridership_by_station AS (
      -- Calculate OMNY ridership by station, year, latitude, and longitude
      SELECT 
          station_complex_id, 
          latitude, 
          longitude, 
          EXTRACT(YEAR FROM transit_timestamp) AS year, 
          SUM(ridership) AS omny_ridership
      FROM 
          "lake"."main"."mta_hourly_subway_socrata"
      WHERE 
          payment_method = 'omny'
      GROUP BY 
          station_complex_id, latitude, longitude, year
  )
  SELECT 
      t.station_complex_id AS station_id,
      t.station_complex AS station_name,
      t.latitude,
      t.longitude,
      t.year, 
      (o.omny_ridership / t.total_ridership) AS omny_percentage
  FROM 
      total_ridership_by_station t
  LEFT JOIN 
      omny_ridership_by_station o
      ON t.station_complex_id = o.station_complex_id 
      AND t.latitude = o.latitude
      AND t.longitude = o.longitude
      AND t.year = o.year
  ORDER BY 
      t.year, omny_percentage DESC
      );
    
    ...
                   ^
[0m14:45:50.527253 [info ] [MainThread]: 
[0m14:45:50.527670 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=7 SKIP=0 TOTAL=7
[0m14:45:50.529759 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 1.0989745, "process_user_time": 1.770061, "process_kernel_time": 0.366219, "process_mem_max_rss": "177012", "process_in_blocks": "42216", "process_out_blocks": "2016", "command_success": false}
[0m14:45:50.530272 [debug] [MainThread]: Command `dbt run` failed at 14:45:50.530181 after 1.10 seconds
[0m14:45:50.530624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050e047430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050c633a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f050df71960>]}
[0m14:45:50.530973 [debug] [MainThread]: Flushing usage events
[0m14:48:28.872115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88410fb490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883f95bf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883f95a560>]}


============================== 14:48:28.873895 | a5c76f80-98ae-44b1-b2ab-985b5f110642 ==============================
[0m14:48:28.873895 [info ] [MainThread]: Running with dbt=1.8.7
[0m14:48:28.874353 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:48:29.035582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883c594d60>]}
[0m14:48:29.085697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883f79cfd0>]}
[0m14:48:29.088224 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m14:48:29.095463 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m14:48:29.169287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:48:29.169715 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:48:29.194353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8834205960>]}
[0m14:48:29.253104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8834398c10>]}
[0m14:48:29.253614 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m14:48:29.253959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883439a050>]}
[0m14:48:29.255422 [info ] [MainThread]: 
[0m14:48:29.255983 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m14:48:29.260123 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m14:48:29.285872 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m14:48:29.286308 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m14:48:29.286608 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:48:29.298094 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m14:48:29.299444 [debug] [ThreadPool]: On list_lake: Close
[0m14:48:29.303001 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m14:48:29.303477 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m14:48:29.308736 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:48:29.309158 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m14:48:29.309420 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:48:29.314929 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m14:48:29.315966 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:48:29.316244 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m14:48:29.317114 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m14:48:29.317361 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:48:29.317605 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m14:48:29.318066 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:48:29.318628 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:48:29.318879 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m14:48:29.319095 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m14:48:29.319539 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m14:48:29.319791 [debug] [ThreadPool]: On create_lake_main: Close
[0m14:48:29.322338 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m14:48:29.326350 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:48:29.326669 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m14:48:29.326938 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:48:29.332085 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m14:48:29.332366 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m14:48:29.332602 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m14:48:29.347574 [debug] [ThreadPool]: SQL status: OK in 0.015 seconds
[0m14:48:29.349007 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m14:48:29.349459 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m14:48:29.349696 [debug] [ThreadPool]: On list_lake_main: Close
[0m14:48:29.352507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883420d000>]}
[0m14:48:29.352885 [debug] [MainThread]: Using duckdb connection "master"
[0m14:48:29.353126 [debug] [MainThread]: On master: BEGIN
[0m14:48:29.353350 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:48:29.358262 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m14:48:29.358593 [debug] [MainThread]: On master: COMMIT
[0m14:48:29.358841 [debug] [MainThread]: Using duckdb connection "master"
[0m14:48:29.359051 [debug] [MainThread]: On master: COMMIT
[0m14:48:29.359529 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:48:29.359758 [debug] [MainThread]: On master: Close
[0m14:48:29.361286 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m14:48:29.361647 [info ] [MainThread]: 
[0m14:48:29.368245 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m14:48:29.368731 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m14:48:29.369248 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m14:48:29.370188 [debug] [Thread-4 (]: Began running node model.mta.hourly_riders
[0m14:48:29.369747 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m14:48:29.370762 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_by_station
[0m14:48:29.372062 [debug] [Thread-6 (]: Began running node model.mta.omny_adoption_increase
[0m14:48:29.372576 [debug] [Thread-7 (]: Began running node model.mta.total_riders_per_station
[0m14:48:29.373041 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m14:48:29.373698 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m14:48:29.374218 [info ] [Thread-4 (]: 4 of 7 START sql table model main.hourly_riders ................................ [RUN]
[0m14:48:29.375042 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m14:48:29.375567 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m14:48:29.376508 [info ] [Thread-6 (]: 6 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m14:48:29.377225 [info ] [Thread-7 (]: 7 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m14:48:29.378195 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m14:48:29.379832 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m14:48:29.382888 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.hourly_riders'
[0m14:48:29.383515 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m14:48:29.384226 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_by_station)
[0m14:48:29.385138 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m14:48:29.385751 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m14:48:29.386193 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m14:48:29.386605 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m14:48:29.387058 [debug] [Thread-4 (]: Began compiling node model.mta.hourly_riders
[0m14:48:29.395586 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m14:48:29.396291 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_by_station
[0m14:48:29.396843 [debug] [Thread-6 (]: Began compiling node model.mta.omny_adoption_increase
[0m14:48:29.397248 [debug] [Thread-7 (]: Began compiling node model.mta.total_riders_per_station
[0m14:48:29.399570 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m14:48:29.401803 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m14:48:29.403836 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.hourly_riders"
[0m14:48:29.406512 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m14:48:29.410175 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m14:48:29.411325 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m14:48:29.414406 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m14:48:29.415366 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m14:48:29.416666 [debug] [Thread-4 (]: Began executing node model.mta.hourly_riders
[0m14:48:29.417394 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m14:48:29.418281 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_by_station
[0m14:48:29.464224 [debug] [Thread-6 (]: Began executing node model.mta.omny_adoption_increase
[0m14:48:29.487318 [debug] [Thread-7 (]: Began executing node model.mta.total_riders_per_station
[0m14:48:29.495987 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m14:48:29.496783 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m14:48:29.499397 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.hourly_riders"
[0m14:48:29.501735 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m14:48:29.503869 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m14:48:29.506786 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m14:48:29.509036 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m14:48:29.509762 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:48:29.510778 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:48:29.511857 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:48:29.512473 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:48:29.513073 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:48:29.513628 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:48:29.514092 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m14:48:29.514485 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:48:29.514945 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m14:48:29.515328 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m14:48:29.515666 [debug] [Thread-4 (]: On model.mta.hourly_riders: BEGIN
[0m14:48:29.515998 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m14:48:29.516330 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: BEGIN
[0m14:48:29.516668 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m14:48:29.517044 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: BEGIN
[0m14:48:29.517374 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:48:29.517714 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m14:48:29.518029 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:48:29.518330 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m14:48:29.518622 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m14:48:29.523964 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:48:29.525751 [debug] [Thread-1 (]: SQL status: OK in 0.009 seconds
[0m14:48:29.526299 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:48:29.526652 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:48:29.529055 [debug] [Thread-3 (]: SQL status: OK in 0.012 seconds
[0m14:48:29.529444 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:48:29.529997 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:48:29.531643 [debug] [Thread-5 (]: SQL status: OK in 0.014 seconds
[0m14:48:29.532035 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:48:29.532421 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m14:48:29.533174 [debug] [Thread-4 (]: SQL status: OK in 0.015 seconds
[0m14:48:29.533489 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:48:29.533795 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */

  
    
    

    create  table
      "lake"."main"."hourly_riders__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m14:48:29.535853 [debug] [Thread-2 (]: SQL status: OK in 0.017 seconds
[0m14:48:29.536287 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:48:29.536700 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m14:48:29.538838 [debug] [Thread-7 (]: SQL status: OK in 0.020 seconds
[0m14:48:29.539336 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:48:29.539971 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m14:48:29.542663 [debug] [Thread-6 (]: SQL status: OK in 0.019 seconds
[0m14:48:29.543086 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:48:29.543494 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m14:48:32.278648 [debug] [Thread-1 (]: SQL status: OK in 2.751 seconds
[0m14:48:32.327689 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:48:32.336315 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m14:48:32.339877 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m14:48:32.548489 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m14:48:32.550226 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:48:32.551990 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m14:48:32.565624 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m14:48:32.595422 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m14:48:32.596726 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m14:48:32.619869 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m14:48:32.627369 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m14:48:32.641600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f883367a530>]}
[0m14:48:32.642899 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 3.26s]
[0m14:48:32.644151 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m14:48:33.373861 [debug] [Thread-2 (]: SQL status: OK in 3.836 seconds
[0m14:48:33.381562 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:48:33.382663 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m14:48:33.384893 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m14:48:33.403540 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m14:48:33.404652 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:48:33.405659 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m14:48:33.414528 [debug] [Thread-2 (]: SQL status: OK in 0.008 seconds
[0m14:48:33.473913 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m14:48:33.475479 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m14:48:33.477841 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m14:48:33.482080 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m14:48:33.483605 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8833678b80>]}
[0m14:48:33.495478 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 4.11s]
[0m14:48:33.498333 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m14:48:36.208445 [debug] [Thread-7 (]: SQL status: OK in 6.668 seconds
[0m14:48:36.218704 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:48:36.242113 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m14:48:36.243590 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m14:48:36.246345 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m14:48:36.247020 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:48:36.265587 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: COMMIT
[0m14:48:36.273913 [debug] [Thread-6 (]: SQL status: OK in 6.730 seconds
[0m14:48:36.281628 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:48:36.282647 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m14:48:36.283882 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m14:48:36.291120 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m14:48:36.293300 [debug] [Thread-7 (]: SQL status: OK in 0.025 seconds
[0m14:48:36.304926 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:48:36.309760 [debug] [Thread-7 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m14:48:36.310568 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: COMMIT
[0m14:48:36.311248 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m14:48:36.320466 [debug] [Thread-6 (]: SQL status: OK in 0.007 seconds
[0m14:48:36.327276 [debug] [Thread-7 (]: SQL status: OK in 0.014 seconds
[0m14:48:36.329909 [debug] [Thread-7 (]: On model.mta.total_riders_per_station: Close
[0m14:48:36.331074 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8833679f30>]}
[0m14:48:36.332145 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 6.95s]
[0m14:48:36.333075 [debug] [Thread-7 (]: Finished running node model.mta.total_riders_per_station
[0m14:48:36.344712 [debug] [Thread-6 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m14:48:36.345669 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m14:48:36.346860 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m14:48:36.352214 [debug] [Thread-6 (]: On model.mta.omny_adoption_increase: Close
[0m14:48:36.353413 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88336604c0>]}
[0m14:48:36.354809 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 6.97s]
[0m14:48:36.356145 [debug] [Thread-6 (]: Finished running node model.mta.omny_adoption_increase
[0m14:48:37.487602 [debug] [Thread-4 (]: SQL status: OK in 7.953 seconds
[0m14:48:37.495124 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:48:37.496099 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
alter table "lake"."main"."hourly_riders__dbt_tmp" rename to "hourly_riders"
[0m14:48:37.497533 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m14:48:37.500627 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m14:48:37.501613 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:48:37.502445 [debug] [Thread-4 (]: On model.mta.hourly_riders: COMMIT
[0m14:48:37.563755 [debug] [Thread-4 (]: SQL status: OK in 0.060 seconds
[0m14:48:37.569056 [debug] [Thread-4 (]: Using duckdb connection "model.mta.hourly_riders"
[0m14:48:37.570089 [debug] [Thread-4 (]: On model.mta.hourly_riders: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.hourly_riders"} */
drop table if exists "lake"."main"."hourly_riders__dbt_backup" cascade
[0m14:48:37.571363 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m14:48:37.573614 [debug] [Thread-4 (]: On model.mta.hourly_riders: Close
[0m14:48:37.574694 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88336798d0>]}
[0m14:48:37.575871 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.hourly_riders ........................... [[32mOK[0m in 8.19s]
[0m14:48:37.576949 [debug] [Thread-4 (]: Finished running node model.mta.hourly_riders
[0m14:48:37.734467 [debug] [Thread-5 (]: SQL status: OK in 8.201 seconds
[0m14:48:37.740684 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:48:37.741546 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m14:48:37.742711 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m14:48:37.745392 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m14:48:37.746102 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:48:37.746714 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m14:48:37.751911 [debug] [Thread-5 (]: SQL status: OK in 0.005 seconds
[0m14:48:37.757657 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m14:48:37.758766 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m14:48:37.760064 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m14:48:37.762155 [debug] [Thread-5 (]: On model.mta.omny_adoption_by_station: Close
[0m14:48:37.763094 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88336604f0>]}
[0m14:48:37.764134 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 8.38s]
[0m14:48:37.765324 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_by_station
[0m14:48:38.587913 [debug] [Thread-3 (]: SQL status: OK in 9.057 seconds
[0m14:48:38.591998 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:48:38.592426 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m14:48:38.593202 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m14:48:38.594577 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m14:48:38.594909 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:48:38.595186 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m14:48:38.599423 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m14:48:38.601402 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m14:48:38.601748 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m14:48:38.602366 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m14:48:38.603480 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m14:48:38.671131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a5c76f80-98ae-44b1-b2ab-985b5f110642', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8833679570>]}
[0m14:48:38.672037 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 9.29s]
[0m14:48:38.672633 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m14:48:38.676053 [debug] [MainThread]: Using duckdb connection "master"
[0m14:48:38.676539 [debug] [MainThread]: On master: BEGIN
[0m14:48:38.676823 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:48:38.683704 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m14:48:38.684370 [debug] [MainThread]: On master: COMMIT
[0m14:48:38.684735 [debug] [MainThread]: Using duckdb connection "master"
[0m14:48:38.684975 [debug] [MainThread]: On master: COMMIT
[0m14:48:38.685516 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m14:48:38.685882 [debug] [MainThread]: On master: Close
[0m14:48:38.688083 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:48:38.688459 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m14:48:38.688709 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m14:48:38.688928 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m14:48:38.689146 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m14:48:38.689356 [debug] [MainThread]: Connection 'model.mta.hourly_riders' was properly closed.
[0m14:48:38.689561 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m14:48:38.689768 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m14:48:38.690175 [info ] [MainThread]: 
[0m14:48:38.690558 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 9.43 seconds (9.43s).
[0m14:48:38.691857 [debug] [MainThread]: Command end result
[0m14:48:38.719232 [info ] [MainThread]: 
[0m14:48:38.719803 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:48:38.720152 [info ] [MainThread]: 
[0m14:48:38.720455 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m14:48:38.721280 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.888595, "process_user_time": 122.93175, "process_kernel_time": 7.700735, "process_mem_max_rss": "466384", "process_in_blocks": "1022664", "process_out_blocks": "12248"}
[0m14:48:38.721841 [debug] [MainThread]: Command `dbt run` succeeded at 14:48:38.721745 after 9.89 seconds
[0m14:48:38.722250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88410fb490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f88345cd840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8833651240>]}
[0m14:48:38.722604 [debug] [MainThread]: Flushing usage events
[0m15:11:22.713178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c57dd73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c56480be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c56480b50>]}


============================== 15:11:22.718107 | a2ab0461-780c-4ea4-9fbf-3b896f0ccd50 ==============================
[0m15:11:22.718107 [info ] [MainThread]: Running with dbt=1.8.7
[0m15:11:22.718563 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:11:22.934635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c563c6620>]}
[0m15:11:22.985224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c563ab520>]}
[0m15:11:22.990736 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m15:11:23.002961 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m15:11:23.127043 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m15:11:23.127660 [debug] [MainThread]: Partial parsing: added file: mta://models/weekly_riders_per_station.sql
[0m15:11:23.127959 [debug] [MainThread]: Partial parsing: deleted file: mta://models/hourly_riders.sql
[0m15:11:23.341081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c4af27550>]}
[0m15:11:23.418255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c4aed1ff0>]}
[0m15:11:23.418787 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m15:11:23.419146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c4aed20b0>]}
[0m15:11:23.420674 [info ] [MainThread]: 
[0m15:11:23.421227 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:11:23.425366 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m15:11:23.558745 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m15:11:23.559298 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m15:11:23.559622 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:23.577684 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:11:23.579298 [debug] [ThreadPool]: On list_lake: Close
[0m15:11:23.581595 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m15:11:23.582373 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m15:11:23.587709 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:11:23.588126 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m15:11:23.588470 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:11:23.596210 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:11:23.597509 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:11:23.597842 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m15:11:23.599315 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:11:23.599636 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:11:23.599883 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m15:11:23.601791 [debug] [ThreadPool]: SQL status: OK in 0.002 seconds
[0m15:11:23.602550 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:11:23.602895 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:11:23.603154 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:11:23.604472 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:11:23.604850 [debug] [ThreadPool]: On create_lake_main: Close
[0m15:11:23.608590 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m15:11:23.613124 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:11:23.613466 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m15:11:23.613729 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:11:23.619897 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:11:23.620281 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:11:23.620557 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m15:11:23.647180 [debug] [ThreadPool]: SQL status: OK in 0.026 seconds
[0m15:11:23.648790 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m15:11:23.650604 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m15:11:23.650935 [debug] [ThreadPool]: On list_lake_main: Close
[0m15:11:23.654094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c580c2c80>]}
[0m15:11:23.654558 [debug] [MainThread]: Using duckdb connection "master"
[0m15:11:23.654831 [debug] [MainThread]: On master: BEGIN
[0m15:11:23.655104 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:11:23.660365 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m15:11:23.660717 [debug] [MainThread]: On master: COMMIT
[0m15:11:23.660966 [debug] [MainThread]: Using duckdb connection "master"
[0m15:11:23.661186 [debug] [MainThread]: On master: COMMIT
[0m15:11:23.661723 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:11:23.662027 [debug] [MainThread]: On master: Close
[0m15:11:23.663791 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m15:11:23.664168 [info ] [MainThread]: 
[0m15:11:23.671691 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m15:11:23.672373 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m15:11:23.672983 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m15:11:23.673576 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m15:11:23.674321 [debug] [Thread-4 (]: Began running node model.mta.omny_adoption_by_station
[0m15:11:23.675434 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_increase
[0m15:11:23.675017 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m15:11:23.676017 [debug] [Thread-6 (]: Began running node model.mta.total_riders_per_station
[0m15:11:23.676946 [debug] [Thread-7 (]: Began running node model.mta.weekly_riders_per_station
[0m15:11:23.678091 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m15:11:23.680010 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m15:11:23.681917 [info ] [Thread-4 (]: 4 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m15:11:23.683010 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m15:11:23.684081 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m15:11:23.684859 [info ] [Thread-6 (]: 6 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m15:11:23.685526 [info ] [Thread-7 (]: 7 of 7 START sql table model main.weekly_riders_per_station .................... [RUN]
[0m15:11:23.686207 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m15:11:23.686667 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m15:11:23.687208 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m15:11:23.687744 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_increase)
[0m15:11:23.688141 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m15:11:23.688634 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m15:11:23.689084 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m15:11:23.689463 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m15:11:23.699095 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m15:11:23.699844 [debug] [Thread-4 (]: Began compiling node model.mta.omny_adoption_by_station
[0m15:11:23.700365 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_increase
[0m15:11:23.703549 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m15:11:23.704224 [debug] [Thread-6 (]: Began compiling node model.mta.total_riders_per_station
[0m15:11:23.704965 [debug] [Thread-7 (]: Began compiling node model.mta.weekly_riders_per_station
[0m15:11:23.707690 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m15:11:23.711266 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m15:11:23.716648 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m15:11:23.717531 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m15:11:23.720352 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m15:11:23.722485 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m15:11:23.722959 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m15:11:23.723686 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m15:11:23.743024 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_increase
[0m15:11:23.760646 [debug] [Thread-4 (]: Began executing node model.mta.omny_adoption_by_station
[0m15:11:23.761401 [debug] [Thread-6 (]: Began executing node model.mta.total_riders_per_station
[0m15:11:23.764517 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m15:11:23.765375 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m15:11:23.769597 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m15:11:23.770103 [debug] [Thread-7 (]: Began executing node model.mta.weekly_riders_per_station
[0m15:11:23.772745 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m15:11:23.775889 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m15:11:23.780541 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m15:11:23.782307 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:11:23.782759 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:11:23.786138 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m15:11:23.786580 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:11:23.787684 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:11:23.788072 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:11:23.788474 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m15:11:23.788879 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m15:11:23.789606 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:11:23.789965 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:11:23.790265 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m15:11:23.790665 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: BEGIN
[0m15:11:23.791061 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m15:11:23.791434 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:11:23.791792 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:11:23.792147 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: BEGIN
[0m15:11:23.792536 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: BEGIN
[0m15:11:23.792913 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:11:23.793274 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m15:11:23.793639 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:11:23.799905 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:11:23.800529 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m15:11:23.801569 [debug] [Thread-2 (]: SQL status: OK in 0.010 seconds
[0m15:11:23.802647 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:11:23.803131 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:11:23.803503 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m15:11:23.804153 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:11:23.804529 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:11:23.805334 [debug] [Thread-3 (]: SQL status: OK in 0.012 seconds
[0m15:11:23.805657 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:11:23.806000 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:11:23.808068 [debug] [Thread-5 (]: SQL status: OK in 0.015 seconds
[0m15:11:23.808579 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:11:23.808997 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m15:11:23.810141 [debug] [Thread-4 (]: SQL status: OK in 0.016 seconds
[0m15:11:23.810534 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:11:23.810911 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m15:11:23.812424 [debug] [Thread-7 (]: SQL status: OK in 0.013 seconds
[0m15:11:23.812833 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:11:23.813184 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    DATE_TRUNC('week', transit_timestamp) AS date, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    date
ORDER BY 
    date, total_ridership DESC
    );
  
  
[0m15:11:23.814129 [debug] [Thread-6 (]: SQL status: OK in 0.014 seconds
[0m15:11:23.814504 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:11:23.814814 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:11:25.792490 [debug] [Thread-2 (]: SQL status: OK in 1.988 seconds
[0m15:11:25.811827 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:11:25.812806 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m15:11:25.815005 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:11:25.865904 [debug] [Thread-1 (]: SQL status: OK in 2.061 seconds
[0m15:11:25.873134 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:11:25.876412 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m15:11:25.878170 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:11:25.882705 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m15:11:25.875050 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:11:25.904818 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:11:25.905887 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:11:25.906751 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m15:11:25.907519 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:11:25.935795 [debug] [Thread-1 (]: SQL status: OK in 0.011 seconds
[0m15:11:25.947078 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:11:25.948179 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m15:11:25.951602 [debug] [Thread-2 (]: SQL status: OK in 0.024 seconds
[0m15:11:25.965879 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:11:25.972843 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:11:25.977882 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m15:11:25.978821 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m15:11:25.981911 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c531c8e80>]}
[0m15:11:25.984833 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:11:25.983782 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 2.30s]
[0m15:11:25.987606 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m15:11:25.988891 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m15:11:25.991869 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c563c7550>]}
[0m15:11:25.993473 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 2.31s]
[0m15:11:25.995462 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m15:11:29.184392 [debug] [Thread-7 (]: SQL status: OK in 5.371 seconds
[0m15:11:29.190893 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:11:29.191997 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "lake"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m15:11:29.193936 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m15:11:29.197992 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m15:11:29.199059 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:11:29.199789 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m15:11:29.251546 [debug] [Thread-7 (]: SQL status: OK in 0.051 seconds
[0m15:11:29.258822 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:11:29.259852 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "lake"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m15:11:29.261017 [debug] [Thread-7 (]: SQL status: OK in 0.000 seconds
[0m15:11:29.263430 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: Close
[0m15:11:29.266699 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c531213c0>]}
[0m15:11:29.268121 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.weekly_riders_per_station ............... [[32mOK[0m in 5.58s]
[0m15:11:29.269312 [debug] [Thread-7 (]: Finished running node model.mta.weekly_riders_per_station
[0m15:11:29.509663 [debug] [Thread-6 (]: SQL status: OK in 5.694 seconds
[0m15:11:29.525281 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:11:29.526394 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m15:11:29.527893 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m15:11:29.530602 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m15:11:29.531305 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:11:29.532560 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m15:11:29.555136 [debug] [Thread-6 (]: SQL status: OK in 0.022 seconds
[0m15:11:29.561008 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:11:29.562132 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m15:11:29.563473 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m15:11:29.569819 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: Close
[0m15:11:29.575205 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c48389f90>]}
[0m15:11:29.579655 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 5.89s]
[0m15:11:29.581174 [debug] [Thread-6 (]: Finished running node model.mta.total_riders_per_station
[0m15:11:29.590126 [debug] [Thread-4 (]: SQL status: OK in 5.779 seconds
[0m15:11:29.598481 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:11:29.599449 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m15:11:29.600815 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m15:11:29.609879 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m15:11:29.612441 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:11:29.616259 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m15:11:29.630639 [debug] [Thread-4 (]: SQL status: OK in 0.013 seconds
[0m15:11:29.636319 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:11:29.640715 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m15:11:29.642290 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m15:11:29.645533 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: Close
[0m15:11:29.662877 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c53121f60>]}
[0m15:11:29.664143 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 5.98s]
[0m15:11:29.665165 [debug] [Thread-4 (]: Finished running node model.mta.omny_adoption_by_station
[0m15:11:31.668704 [debug] [Thread-3 (]: SQL status: OK in 7.862 seconds
[0m15:11:31.675516 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:11:31.676671 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m15:11:31.678732 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:11:31.681879 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m15:11:31.682770 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:11:31.683457 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m15:11:31.690027 [debug] [Thread-3 (]: SQL status: OK in 0.006 seconds
[0m15:11:31.695512 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:11:31.696525 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m15:11:31.697782 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.700340 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m15:11:31.701576 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c531c93f0>]}
[0m15:11:31.702713 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 8.02s]
[0m15:11:31.703764 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m15:11:32.048405 [debug] [Thread-5 (]: SQL status: OK in 8.239 seconds
[0m15:11:32.051325 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:11:32.051719 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m15:11:32.052666 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m15:11:32.053986 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m15:11:32.054307 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:11:32.054665 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m15:11:32.057685 [debug] [Thread-5 (]: SQL status: OK in 0.003 seconds
[0m15:11:32.060584 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:11:32.060920 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m15:11:32.061461 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.062576 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: Close
[0m15:11:32.137883 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2ab0461-780c-4ea4-9fbf-3b896f0ccd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b58fef880>]}
[0m15:11:32.138738 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 8.45s]
[0m15:11:32.139384 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_increase
[0m15:11:32.142447 [debug] [MainThread]: Using duckdb connection "master"
[0m15:11:32.142948 [debug] [MainThread]: On master: BEGIN
[0m15:11:32.143445 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:11:32.150096 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m15:11:32.150596 [debug] [MainThread]: On master: COMMIT
[0m15:11:32.150897 [debug] [MainThread]: Using duckdb connection "master"
[0m15:11:32.151149 [debug] [MainThread]: On master: COMMIT
[0m15:11:32.151677 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:11:32.151983 [debug] [MainThread]: On master: Close
[0m15:11:32.154080 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:32.154662 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m15:11:32.155069 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m15:11:32.155360 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m15:11:32.155594 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m15:11:32.155810 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m15:11:32.156057 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m15:11:32.156302 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m15:11:32.156766 [info ] [MainThread]: 
[0m15:11:32.157163 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 8.74 seconds (8.74s).
[0m15:11:32.159015 [debug] [MainThread]: Command end result
[0m15:11:32.189517 [info ] [MainThread]: 
[0m15:11:32.190119 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:11:32.190442 [info ] [MainThread]: 
[0m15:11:32.190740 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m15:11:32.192745 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.527684, "process_user_time": 121.62299, "process_kernel_time": 5.490722, "process_mem_max_rss": "493436", "process_in_blocks": "126520", "process_out_blocks": "13088"}
[0m15:11:32.193435 [debug] [MainThread]: Command `dbt run` succeeded at 15:11:32.193298 after 9.53 seconds
[0m15:11:32.193880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c57dd73d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c4af74730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6c53183190>]}
[0m15:11:32.194489 [debug] [MainThread]: Flushing usage events
[0m15:59:34.638052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effbc1af400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba860be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba860b50>]}


============================== 15:59:34.641146 | 5af32ded-bbbd-49a5-87ee-56ab2ef8fe46 ==============================
[0m15:59:34.641146 [info ] [MainThread]: Running with dbt=1.8.7
[0m15:59:34.641638 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:59:34.836909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba7a6620>]}
[0m15:59:34.891513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba78f520>]}
[0m15:59:34.894972 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m15:59:34.905613 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m15:59:34.997178 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:59:34.997699 [debug] [MainThread]: Partial parsing: updated file: mta://models/weekly_riders_per_station.sql
[0m15:59:35.204406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf2e7fa0>]}
[0m15:59:35.272095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf4e44c0>]}
[0m15:59:35.272766 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m15:59:35.273113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf4e5540>]}
[0m15:59:35.274421 [info ] [MainThread]: 
[0m15:59:35.275032 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:59:35.279389 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m15:59:35.373276 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m15:59:35.373730 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m15:59:35.374034 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:59:35.391779 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m15:59:35.393235 [debug] [ThreadPool]: On list_lake: Close
[0m15:59:35.395861 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m15:59:35.396516 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m15:59:35.400846 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:35.401144 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m15:59:35.401382 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:59:35.407103 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:59:35.408246 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:35.408584 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m15:59:35.409028 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:59:35.409285 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:35.409521 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m15:59:35.410805 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:59:35.411552 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:59:35.411826 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:35.412072 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:59:35.413261 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:59:35.413552 [debug] [ThreadPool]: On create_lake_main: Close
[0m15:59:35.416869 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m15:59:35.421098 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:59:35.421409 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m15:59:35.421663 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:59:35.427491 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:59:35.427879 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:59:35.428177 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m15:59:35.451973 [debug] [ThreadPool]: SQL status: OK in 0.023 seconds
[0m15:59:35.457959 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m15:59:35.458983 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m15:59:35.459281 [debug] [ThreadPool]: On list_lake_main: Close
[0m15:59:35.463237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf290bb0>]}
[0m15:59:35.463610 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:35.463835 [debug] [MainThread]: On master: BEGIN
[0m15:59:35.464037 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:59:35.469738 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m15:59:35.470051 [debug] [MainThread]: On master: COMMIT
[0m15:59:35.470284 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:35.470511 [debug] [MainThread]: On master: COMMIT
[0m15:59:35.470896 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:59:35.471154 [debug] [MainThread]: On master: Close
[0m15:59:35.472774 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m15:59:35.473129 [info ] [MainThread]: 
[0m15:59:35.481246 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m15:59:35.481791 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m15:59:35.482307 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m15:59:35.482726 [debug] [Thread-4 (]: Began running node model.mta.omny_adoption_by_station
[0m15:59:35.483265 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m15:59:35.483861 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_increase
[0m15:59:35.484303 [debug] [Thread-6 (]: Began running node model.mta.total_riders_per_station
[0m15:59:35.485179 [debug] [Thread-7 (]: Began running node model.mta.weekly_riders_per_station
[0m15:59:35.484836 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m15:59:35.485844 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m15:59:35.486338 [info ] [Thread-4 (]: 4 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m15:59:35.487025 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m15:59:35.487528 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m15:59:35.488077 [info ] [Thread-6 (]: 6 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m15:59:35.488820 [info ] [Thread-7 (]: 7 of 7 START sql table model main.weekly_riders_per_station .................... [RUN]
[0m15:59:35.489496 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m15:59:35.490539 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m15:59:35.492514 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m15:59:35.494307 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m15:59:35.495484 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_increase)
[0m15:59:35.497232 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m15:59:35.498248 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m15:59:35.498815 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m15:59:35.499293 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m15:59:35.499690 [debug] [Thread-4 (]: Began compiling node model.mta.omny_adoption_by_station
[0m15:59:35.506818 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m15:59:35.507387 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_increase
[0m15:59:35.507874 [debug] [Thread-6 (]: Began compiling node model.mta.total_riders_per_station
[0m15:59:35.508336 [debug] [Thread-7 (]: Began compiling node model.mta.weekly_riders_per_station
[0m15:59:35.511077 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m15:59:35.513712 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m15:59:35.516849 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m15:59:35.520765 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m15:59:35.522953 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m15:59:35.525649 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m15:59:35.527272 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m15:59:35.528142 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m15:59:35.529771 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_increase
[0m15:59:35.541991 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m15:59:35.548330 [debug] [Thread-4 (]: Began executing node model.mta.omny_adoption_by_station
[0m15:59:35.554497 [debug] [Thread-7 (]: Began executing node model.mta.weekly_riders_per_station
[0m15:59:35.554982 [debug] [Thread-6 (]: Began executing node model.mta.total_riders_per_station
[0m15:59:35.562960 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m15:59:35.565921 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m15:59:35.567470 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m15:59:35.569915 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m15:59:35.572096 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m15:59:35.574954 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m15:59:35.577471 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m15:59:35.579725 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:35.580600 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:35.581243 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:35.581798 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:35.582634 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:59:35.582986 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: BEGIN
[0m15:59:35.583327 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:35.583747 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:35.584139 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m15:59:35.584544 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m15:59:35.584903 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m15:59:35.585252 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: BEGIN
[0m15:59:35.585600 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m15:59:35.585951 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m15:59:35.586293 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: BEGIN
[0m15:59:35.586632 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:59:35.586968 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:59:35.587339 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:59:35.587663 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:59:35.594130 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:59:35.594830 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m15:59:35.595769 [debug] [Thread-5 (]: SQL status: OK in 0.010 seconds
[0m15:59:35.597225 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:35.597738 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m15:59:35.598992 [debug] [Thread-3 (]: SQL status: OK in 0.012 seconds
[0m15:59:35.599590 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:35.600015 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:59:35.600882 [debug] [Thread-2 (]: SQL status: OK in 0.014 seconds
[0m15:59:35.601220 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:35.601526 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:59:35.603297 [debug] [Thread-1 (]: SQL status: OK in 0.016 seconds
[0m15:59:35.603691 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:35.604032 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:59:35.605616 [debug] [Thread-7 (]: SQL status: OK in 0.018 seconds
[0m15:59:35.606041 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:59:35.606402 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      WITH ridership_data AS (
    SELECT 
        station_complex_id, 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_date, 
        SUM(ridership) AS total_ridership,
        latitude,
        longitude
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, 
        station_complex, 
        week_date, 
        latitude, 
        longitude
),
weather_data AS (
    SELECT
        DATE_TRUNC('week', date) AS week_date, 
        SUM(precipitation_sum) AS total_precipitation -- Using the precipitation_sum column for total rain
    FROM 
           "lake"."main"."daily_weather_asset"
    GROUP BY 
        week_date
)
SELECT 
    r.station_complex_id,
    r.station_complex,
    r.latitude,
    r.longitude,
    r.week_date,
    r.total_ridership,
    w.total_precipitation
FROM 
    ridership_data r
LEFT JOIN 
    weather_data w
ON 
    r.week_date = w.week_date
ORDER BY 
    r.week_date, r.total_ridership DESC;
    );
  
  
[0m15:59:35.619193 [debug] [Thread-7 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      WITH ridership_data AS (
    SELECT 
        station_complex_id, 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_date, 
        SUM(ridership) AS total_ridership,
        latitude,
        longitude
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, 
        station_complex, 
        week_date, 
        latitude, 
        longitude
),
weather_data AS (
    SELECT
        DATE_TRUNC('week', date) AS week_date, 
        SUM(precipitation_sum) AS total_precipitation -- Using the precipitation_sum column for total rain
    FROM 
           "lake"."main"."daily_weather_asset"
    GROUP BY 
        week_date
)
SELECT 
    r.station_complex_id,
    r.station_complex,
    r.latitude,
    r.longitude,
    r.week_date,
    r.total_ridership,
    w.total_precipitation
FROM 
    ridership_data r
LEFT JOIN 
    weather_data w
ON 
    r.week_date = w.week_date
ORDER BY 
    r.week_date, r.total_ridership DESC;
    );
  
  
[0m15:59:35.620297 [debug] [Thread-7 (]: DuckDB adapter: Rolling back transaction.
[0m15:59:35.621260 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: ROLLBACK
[0m15:59:35.623232 [debug] [Thread-4 (]: SQL status: OK in 0.029 seconds
[0m15:59:35.623633 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:35.624044 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m15:59:35.629520 [debug] [Thread-6 (]: SQL status: OK in 0.034 seconds
[0m15:59:35.630366 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:35.631093 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:59:35.647154 [debug] [Thread-7 (]: Failed to rollback 'model.mta.weekly_riders_per_station'
[0m15:59:35.647689 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: Close
[0m15:59:35.648634 [debug] [Thread-7 (]: Runtime Error in model weekly_riders_per_station (models/weekly_riders_per_station.sql)
  Parser Error: syntax error at or near ";"
[0m15:59:35.652190 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effbb4ea830>]}
[0m15:59:35.652935 [error] [Thread-7 (]: 7 of 7 ERROR creating sql table model main.weekly_riders_per_station ........... [[31mERROR[0m in 0.15s]
[0m15:59:35.653607 [debug] [Thread-7 (]: Finished running node model.mta.weekly_riders_per_station
[0m15:59:35.930432 [debug] [Thread-2 (]: SQL status: OK in 0.328 seconds
[0m15:59:35.955935 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:35.957030 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times" rename to "busiest_specific_times__dbt_backup"
[0m15:59:35.958522 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:59:35.976154 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:35.977127 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m15:59:35.978406 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:59:36.068450 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:59:36.069429 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:36.070246 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:59:36.114416 [debug] [Thread-2 (]: SQL status: OK in 0.039 seconds
[0m15:59:36.137401 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:36.138347 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m15:59:36.239929 [debug] [Thread-2 (]: SQL status: OK in 0.101 seconds
[0m15:59:36.245328 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m15:59:36.246543 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba82c0d0>]}
[0m15:59:36.247692 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 0.76s]
[0m15:59:36.248917 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m15:59:39.407088 [debug] [Thread-3 (]: SQL status: OK in 3.806 seconds
[0m15:59:39.414307 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:39.415443 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro" rename to "fare_class_boro__dbt_backup"
[0m15:59:39.422279 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:59:39.442947 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:39.465473 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m15:59:39.467335 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:59:39.471483 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m15:59:39.472466 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:39.473249 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m15:59:39.485801 [debug] [Thread-3 (]: SQL status: OK in 0.012 seconds
[0m15:59:39.505799 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:39.506894 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m15:59:39.518748 [debug] [Thread-3 (]: SQL status: OK in 0.010 seconds
[0m15:59:39.521613 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m15:59:39.522760 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf356680>]}
[0m15:59:39.523981 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 4.03s]
[0m15:59:39.525368 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m15:59:40.437158 [debug] [Thread-4 (]: SQL status: OK in 4.812 seconds
[0m15:59:40.443080 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:40.464844 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station" rename to "omny_adoption_by_station__dbt_backup"
[0m15:59:40.466577 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m15:59:40.471742 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:40.472586 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m15:59:40.473800 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m15:59:40.478176 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m15:59:40.478909 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:40.479453 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m15:59:40.490176 [debug] [Thread-4 (]: SQL status: OK in 0.010 seconds
[0m15:59:40.495844 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:40.496650 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m15:59:40.506393 [debug] [Thread-4 (]: SQL status: OK in 0.009 seconds
[0m15:59:40.509198 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: Close
[0m15:59:40.510361 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba82dff0>]}
[0m15:59:40.511489 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 5.02s]
[0m15:59:40.512437 [debug] [Thread-4 (]: Finished running node model.mta.omny_adoption_by_station
[0m15:59:40.518270 [debug] [Thread-6 (]: SQL status: OK in 4.885 seconds
[0m15:59:40.525787 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:40.533151 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station" rename to "total_riders_per_station__dbt_backup"
[0m15:59:40.535122 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m15:59:40.548566 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:40.550548 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m15:59:40.554494 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m15:59:40.560131 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m15:59:40.561518 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:40.562790 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m15:59:40.577937 [debug] [Thread-6 (]: SQL status: OK in 0.014 seconds
[0m15:59:40.583258 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:40.584048 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m15:59:40.599071 [debug] [Thread-6 (]: SQL status: OK in 0.014 seconds
[0m15:59:40.601628 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: Close
[0m15:59:40.602700 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba82cf10>]}
[0m15:59:40.603881 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 5.11s]
[0m15:59:40.605061 [debug] [Thread-6 (]: Finished running node model.mta.total_riders_per_station
[0m15:59:41.572556 [debug] [Thread-1 (]: SQL status: OK in 5.968 seconds
[0m15:59:41.581277 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:41.582151 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day" rename to "avg_riders_per_day__dbt_backup"
[0m15:59:41.583534 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:59:41.621417 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:41.622438 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m15:59:41.623886 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:59:41.628308 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m15:59:41.629420 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:41.630249 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m15:59:41.650980 [debug] [Thread-1 (]: SQL status: OK in 0.020 seconds
[0m15:59:41.657335 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:41.658930 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m15:59:41.682543 [debug] [Thread-1 (]: SQL status: OK in 0.022 seconds
[0m15:59:41.685347 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m15:59:41.686467 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba82fa60>]}
[0m15:59:41.687611 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 6.20s]
[0m15:59:41.688802 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m15:59:42.476258 [debug] [Thread-5 (]: SQL status: OK in 6.878 seconds
[0m15:59:42.479077 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:42.479455 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase" rename to "omny_adoption_increase__dbt_backup"
[0m15:59:42.480147 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m15:59:42.482233 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:42.482550 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m15:59:42.483115 [debug] [Thread-5 (]: SQL status: OK in 0.000 seconds
[0m15:59:42.484427 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m15:59:42.484793 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:42.485082 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m15:59:42.488888 [debug] [Thread-5 (]: SQL status: OK in 0.004 seconds
[0m15:59:42.490686 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:42.491003 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m15:59:42.493784 [debug] [Thread-5 (]: SQL status: OK in 0.002 seconds
[0m15:59:42.494978 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: Close
[0m15:59:42.539078 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5af32ded-bbbd-49a5-87ee-56ab2ef8fe46', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effba82e230>]}
[0m15:59:42.539875 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 7.04s]
[0m15:59:42.540454 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_increase
[0m15:59:42.543354 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:42.543732 [debug] [MainThread]: On master: BEGIN
[0m15:59:42.544025 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:59:42.549736 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m15:59:42.550231 [debug] [MainThread]: On master: COMMIT
[0m15:59:42.550531 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:42.550779 [debug] [MainThread]: On master: COMMIT
[0m15:59:42.551283 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:59:42.551584 [debug] [MainThread]: On master: Close
[0m15:59:42.553539 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:59:42.553890 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m15:59:42.554143 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m15:59:42.554509 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m15:59:42.555026 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m15:59:42.555550 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m15:59:42.555816 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m15:59:42.556055 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m15:59:42.556529 [info ] [MainThread]: 
[0m15:59:42.556925 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 7.28 seconds (7.28s).
[0m15:59:42.558242 [debug] [MainThread]: Command end result
[0m15:59:42.583750 [info ] [MainThread]: 
[0m15:59:42.584389 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m15:59:42.584812 [info ] [MainThread]: 
[0m15:59:42.585220 [error] [MainThread]:   Runtime Error in model weekly_riders_per_station (models/weekly_riders_per_station.sql)
  Parser Error: syntax error at or near ";"
[0m15:59:42.585654 [info ] [MainThread]: 
[0m15:59:42.586231 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
[0m15:59:42.588674 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 7.993441, "process_user_time": 103.07716, "process_kernel_time": 4.627789, "process_mem_max_rss": "478596", "process_in_blocks": "4608", "process_out_blocks": "7192", "command_success": false}
[0m15:59:42.589284 [debug] [MainThread]: Command `dbt run` failed at 15:59:42.589173 after 7.99 seconds
[0m15:59:42.589681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effbc1af400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effaf5a2410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effbc17e770>]}
[0m15:59:42.590036 [debug] [MainThread]: Flushing usage events
[0m15:59:57.754628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58f60b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58f18d750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58f18cca0>]}


============================== 15:59:57.756772 | 11849352-194e-4881-a732-2f8fcb83ae32 ==============================
[0m15:59:57.756772 [info ] [MainThread]: Running with dbt=1.8.7
[0m15:59:57.757271 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m15:59:57.916093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58f6c8a30>]}
[0m15:59:57.966533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc1b6a0>]}
[0m15:59:57.969044 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m15:59:57.981798 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m15:59:58.060080 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:59:58.060863 [debug] [MainThread]: Partial parsing: updated file: mta://models/weekly_riders_per_station.sql
[0m15:59:58.263297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5827d5e40>]}
[0m15:59:58.322891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5829d2fb0>]}
[0m15:59:58.323423 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m15:59:58.323779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd5829d3ac0>]}
[0m15:59:58.325356 [info ] [MainThread]: 
[0m15:59:58.325927 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:59:58.330522 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_lake'
[0m15:59:58.409243 [debug] [ThreadPool]: Using duckdb connection "list_lake"
[0m15:59:58.409784 [debug] [ThreadPool]: On list_lake: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"lake"'
    
  
  
[0m15:59:58.410070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:59:58.420108 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:59:58.421537 [debug] [ThreadPool]: On list_lake: Close
[0m15:59:58.425298 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_lake, now create_lake_main)
[0m15:59:58.426003 [debug] [ThreadPool]: Creating schema "database: "lake"
schema: "main"
"
[0m15:59:58.431808 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:58.432312 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
        select type from duckdb_databases()
        where database_name='lake'
        and type='sqlite'
    
  
[0m15:59:58.432616 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:59:58.439919 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m15:59:58.441648 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:58.442124 [debug] [ThreadPool]: On create_lake_main: BEGIN
[0m15:59:58.442867 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:59:58.443189 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:58.443441 [debug] [ThreadPool]: On create_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_lake_main"} */

    
    
        create schema if not exists "lake"."main"
    
[0m15:59:58.444376 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:59:58.445597 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:59:58.445942 [debug] [ThreadPool]: Using duckdb connection "create_lake_main"
[0m15:59:58.446199 [debug] [ThreadPool]: On create_lake_main: COMMIT
[0m15:59:58.446980 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:59:58.447292 [debug] [ThreadPool]: On create_lake_main: Close
[0m15:59:58.450992 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_lake_main, now list_lake_main)
[0m15:59:58.455447 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:59:58.455924 [debug] [ThreadPool]: On list_lake_main: BEGIN
[0m15:59:58.456218 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:59:58.463239 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m15:59:58.463759 [debug] [ThreadPool]: Using duckdb connection "list_lake_main"
[0m15:59:58.464064 [debug] [ThreadPool]: On list_lake_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_lake_main"} */
select
      'lake' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'lake'
  
[0m15:59:58.480518 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:59:58.486248 [debug] [ThreadPool]: On list_lake_main: ROLLBACK
[0m15:59:58.486958 [debug] [ThreadPool]: Failed to rollback 'list_lake_main'
[0m15:59:58.487289 [debug] [ThreadPool]: On list_lake_main: Close
[0m15:59:58.491797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58283f100>]}
[0m15:59:58.492380 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:58.492710 [debug] [MainThread]: On master: BEGIN
[0m15:59:58.492967 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:59:58.501216 [debug] [MainThread]: SQL status: OK in 0.008 seconds
[0m15:59:58.501726 [debug] [MainThread]: On master: COMMIT
[0m15:59:58.502032 [debug] [MainThread]: Using duckdb connection "master"
[0m15:59:58.502274 [debug] [MainThread]: On master: COMMIT
[0m15:59:58.502839 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:59:58.503151 [debug] [MainThread]: On master: Close
[0m15:59:58.505892 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m15:59:58.506582 [info ] [MainThread]: 
[0m15:59:58.512373 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m15:59:58.513784 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m15:59:58.514584 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m15:59:58.513174 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m15:59:58.515765 [debug] [Thread-4 (]: Began running node model.mta.omny_adoption_by_station
[0m15:59:58.516988 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_increase
[0m15:59:58.515139 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m15:59:58.516453 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m15:59:58.517986 [debug] [Thread-6 (]: Began running node model.mta.total_riders_per_station
[0m15:59:58.518534 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m15:59:58.518913 [debug] [Thread-7 (]: Began running node model.mta.weekly_riders_per_station
[0m15:59:58.519523 [info ] [Thread-4 (]: 4 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m15:59:58.520596 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m15:59:58.521972 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m15:59:58.523300 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m15:59:58.525669 [info ] [Thread-6 (]: 6 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m15:59:58.528081 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m15:59:58.529002 [info ] [Thread-7 (]: 7 of 7 START sql table model main.weekly_riders_per_station .................... [RUN]
[0m15:59:58.530561 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m15:59:58.532542 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_lake_main, now model.mta.omny_adoption_increase)
[0m15:59:58.534161 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m15:59:58.534943 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m15:59:58.537172 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m15:59:58.545084 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m15:59:58.545928 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m15:59:58.546590 [debug] [Thread-4 (]: Began compiling node model.mta.omny_adoption_by_station
[0m15:59:58.547197 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_increase
[0m15:59:58.552303 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m15:59:58.555450 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m15:59:58.556006 [debug] [Thread-6 (]: Began compiling node model.mta.total_riders_per_station
[0m15:59:58.556660 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m15:59:58.557321 [debug] [Thread-7 (]: Began compiling node model.mta.weekly_riders_per_station
[0m15:59:58.561506 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m15:59:58.566399 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m15:59:58.569449 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m15:59:58.570590 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m15:59:58.576498 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m15:59:58.586408 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m15:59:58.604872 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m15:59:58.606065 [debug] [Thread-4 (]: Began executing node model.mta.omny_adoption_by_station
[0m15:59:58.607377 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_increase
[0m15:59:58.610845 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m15:59:58.611434 [debug] [Thread-6 (]: Began executing node model.mta.total_riders_per_station
[0m15:59:58.614872 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m15:59:58.615989 [debug] [Thread-7 (]: Began executing node model.mta.weekly_riders_per_station
[0m15:59:58.619380 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m15:59:58.622918 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m15:59:58.623681 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:58.628698 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m15:59:58.632746 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m15:59:58.633707 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:58.634422 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:58.635608 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m15:59:58.636138 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:58.636615 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:58.637189 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:58.637720 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m15:59:58.638163 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:59:58.638528 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m15:59:58.638901 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:59:58.639268 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: BEGIN
[0m15:59:58.639623 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m15:59:58.640047 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: BEGIN
[0m15:59:58.640461 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:59:58.640846 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: BEGIN
[0m15:59:58.641289 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:59:58.648829 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m15:59:58.649538 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:59:58.650193 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m15:59:58.651125 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m15:59:58.651531 [debug] [Thread-1 (]: SQL status: OK in 0.013 seconds
[0m15:59:58.653170 [debug] [Thread-2 (]: SQL status: OK in 0.013 seconds
[0m15:59:58.654160 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m15:59:58.654779 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:58.655241 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "lake"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:59:58.655729 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "lake"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m15:59:58.657509 [debug] [Thread-3 (]: SQL status: OK in 0.016 seconds
[0m15:59:58.657996 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m15:59:58.658401 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "lake"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:59:58.660871 [debug] [Thread-5 (]: SQL status: OK in 0.012 seconds
[0m15:59:58.661442 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m15:59:58.661934 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m15:59:58.664210 [debug] [Thread-4 (]: SQL status: OK in 0.015 seconds
[0m15:59:58.664740 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m15:59:58.665168 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "lake"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m15:59:58.667480 [debug] [Thread-6 (]: SQL status: OK in 0.017 seconds
[0m15:59:58.668317 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m15:59:58.669010 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "lake"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m15:59:58.670736 [debug] [Thread-7 (]: SQL status: OK in 0.019 seconds
[0m15:59:58.671492 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m15:59:58.671918 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "lake"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      WITH ridership_data AS (
    SELECT 
        station_complex_id, 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_date, 
        SUM(ridership) AS total_ridership,
        latitude,
        longitude
    FROM 
        "lake"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, 
        station_complex, 
        week_date, 
        latitude, 
        longitude
),
weather_data AS (
    SELECT
        DATE_TRUNC('week', date) AS week_date, 
        SUM(precipitation_sum) AS total_precipitation -- Using the precipitation_sum column for total rain
    FROM 
           "lake"."main"."daily_weather_asset"
    GROUP BY 
        week_date
)
SELECT 
    r.station_complex_id,
    r.station_complex,
    r.latitude,
    r.longitude,
    r.week_date,
    r.total_ridership,
    w.total_precipitation
FROM 
    ridership_data r
LEFT JOIN 
    weather_data w
ON 
    r.week_date = w.week_date
ORDER BY 
    r.week_date, r.total_ridership DESC
    );
  
  
[0m15:59:59.128263 [debug] [Thread-2 (]: SQL status: OK in 0.472 seconds
[0m15:59:59.155214 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:59.156591 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times" rename to "busiest_specific_times__dbt_backup"
[0m15:59:59.158163 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:59:59.172485 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:59.173341 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "lake"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m15:59:59.174660 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:59:59.215548 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:59:59.232251 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:59.233109 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m15:59:59.247370 [debug] [Thread-2 (]: SQL status: OK in 0.013 seconds
[0m15:59:59.259860 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m15:59:59.260878 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "lake"."main"."busiest_specific_times__dbt_backup" cascade
[0m15:59:59.273999 [debug] [Thread-2 (]: SQL status: OK in 0.012 seconds
[0m15:59:59.279921 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m15:59:59.296931 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc7c5e0>]}
[0m15:59:59.298118 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 0.77s]
[0m15:59:59.299080 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m16:00:03.772348 [debug] [Thread-5 (]: SQL status: OK in 5.110 seconds
[0m16:00:03.778653 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:00:03.795066 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase" rename to "omny_adoption_increase__dbt_backup"
[0m16:00:03.796791 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m16:00:03.802315 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:00:03.803142 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "lake"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m16:00:03.804603 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m16:00:03.807903 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m16:00:03.830516 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:00:03.831855 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m16:00:03.844937 [debug] [Thread-5 (]: SQL status: OK in 0.012 seconds
[0m16:00:03.851132 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:00:03.852170 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "lake"."main"."omny_adoption_increase__dbt_backup" cascade
[0m16:00:03.859463 [debug] [Thread-5 (]: SQL status: OK in 0.006 seconds
[0m16:00:03.862340 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: Close
[0m16:00:03.863588 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49d85d5a0>]}
[0m16:00:03.877147 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 5.33s]
[0m16:00:03.878609 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_increase
[0m16:00:04.175346 [debug] [Thread-4 (]: SQL status: OK in 5.510 seconds
[0m16:00:04.181473 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:00:04.184156 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station" rename to "omny_adoption_by_station__dbt_backup"
[0m16:00:04.186085 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m16:00:04.191633 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:00:04.209335 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "lake"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m16:00:04.210689 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m16:00:04.213863 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m16:00:04.214825 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:00:04.215571 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m16:00:04.231146 [debug] [Thread-4 (]: SQL status: OK in 0.015 seconds
[0m16:00:04.235847 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:00:04.236780 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "lake"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m16:00:04.246848 [debug] [Thread-4 (]: SQL status: OK in 0.009 seconds
[0m16:00:04.249781 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: Close
[0m16:00:04.250825 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc7d360>]}
[0m16:00:04.252055 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 5.72s]
[0m16:00:04.253149 [debug] [Thread-4 (]: Finished running node model.mta.omny_adoption_by_station
[0m16:00:04.294611 [debug] [Thread-7 (]: SQL status: OK in 5.621 seconds
[0m16:00:04.300839 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:00:04.301626 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "lake"."main"."weekly_riders_per_station" rename to "weekly_riders_per_station__dbt_backup"
[0m16:00:04.302835 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m16:00:04.314814 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:00:04.325039 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "lake"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m16:00:04.326900 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m16:00:04.330279 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m16:00:04.331009 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:00:04.331557 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m16:00:04.429921 [debug] [Thread-7 (]: SQL status: OK in 0.098 seconds
[0m16:00:04.436108 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:00:04.437152 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "lake"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m16:00:04.465668 [debug] [Thread-7 (]: SQL status: OK in 0.028 seconds
[0m16:00:04.468592 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: Close
[0m16:00:04.469615 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc7e470>]}
[0m16:00:04.471034 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.weekly_riders_per_station ............... [[32mOK[0m in 5.92s]
[0m16:00:04.472200 [debug] [Thread-7 (]: Finished running node model.mta.weekly_riders_per_station
[0m16:00:05.297725 [debug] [Thread-6 (]: SQL status: OK in 6.628 seconds
[0m16:00:05.303351 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:00:05.304274 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station" rename to "total_riders_per_station__dbt_backup"
[0m16:00:05.305682 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m16:00:05.312392 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:00:05.313333 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "lake"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m16:00:05.314745 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m16:00:05.318140 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m16:00:05.319063 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:00:05.319820 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m16:00:05.331398 [debug] [Thread-6 (]: SQL status: OK in 0.011 seconds
[0m16:00:05.336038 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:00:05.358308 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "lake"."main"."total_riders_per_station__dbt_backup" cascade
[0m16:00:05.373708 [debug] [Thread-6 (]: SQL status: OK in 0.014 seconds
[0m16:00:05.376796 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: Close
[0m16:00:05.377874 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd49d850c10>]}
[0m16:00:05.379201 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 6.84s]
[0m16:00:05.380688 [debug] [Thread-6 (]: Finished running node model.mta.total_riders_per_station
[0m16:00:05.771382 [debug] [Thread-1 (]: SQL status: OK in 7.115 seconds
[0m16:00:05.776470 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:00:05.777330 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day" rename to "avg_riders_per_day__dbt_backup"
[0m16:00:05.778635 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:00:05.782879 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:00:05.783516 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "lake"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m16:00:05.784536 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:05.787128 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m16:00:05.787754 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:00:05.788415 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m16:00:05.826365 [debug] [Thread-1 (]: SQL status: OK in 0.037 seconds
[0m16:00:05.830729 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:00:05.831470 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "lake"."main"."avg_riders_per_day__dbt_backup" cascade
[0m16:00:05.838311 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m16:00:05.842271 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m16:00:05.843243 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc7efb0>]}
[0m16:00:05.844197 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 7.32s]
[0m16:00:05.845362 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m16:00:06.336032 [debug] [Thread-3 (]: SQL status: OK in 7.677 seconds
[0m16:00:06.338984 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:00:06.339413 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro" rename to "fare_class_boro__dbt_backup"
[0m16:00:06.340365 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m16:00:06.342940 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:00:06.343303 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "lake"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m16:00:06.344017 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m16:00:06.345504 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m16:00:06.345838 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:00:06.346139 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m16:00:06.349661 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m16:00:06.351679 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:00:06.352001 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "lake"."main"."fare_class_boro__dbt_backup" cascade
[0m16:00:06.354901 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m16:00:06.356939 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m16:00:06.434269 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '11849352-194e-4881-a732-2f8fcb83ae32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58dc7c6a0>]}
[0m16:00:06.435220 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 7.91s]
[0m16:00:06.435783 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m16:00:06.439070 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:06.439464 [debug] [MainThread]: On master: BEGIN
[0m16:00:06.439780 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:00:06.446959 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m16:00:06.447643 [debug] [MainThread]: On master: COMMIT
[0m16:00:06.448045 [debug] [MainThread]: Using duckdb connection "master"
[0m16:00:06.448340 [debug] [MainThread]: On master: COMMIT
[0m16:00:06.449089 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:00:06.449444 [debug] [MainThread]: On master: Close
[0m16:00:06.452705 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:06.453651 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m16:00:06.454181 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m16:00:06.455332 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m16:00:06.455725 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m16:00:06.455984 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m16:00:06.456972 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m16:00:06.457527 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m16:00:06.458155 [info ] [MainThread]: 
[0m16:00:06.458620 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 8.13 seconds (8.13s).
[0m16:00:06.459938 [debug] [MainThread]: Command end result
[0m16:00:06.487129 [info ] [MainThread]: 
[0m16:00:06.487711 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:00:06.488051 [info ] [MainThread]: 
[0m16:00:06.488357 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m16:00:06.489100 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.776116, "process_user_time": 115.770226, "process_kernel_time": 2.935552, "process_mem_max_rss": "553472", "process_in_blocks": "240", "process_out_blocks": "18816"}
[0m16:00:06.489614 [debug] [MainThread]: Command `dbt run` succeeded at 16:00:06.489514 after 8.78 seconds
[0m16:00:06.489994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58f60b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd580606650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd58e4d3e50>]}
[0m16:00:06.490356 [debug] [MainThread]: Flushing usage events
[0m16:01:59.889783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb7d2b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb6589c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb658b5b0>]}


============================== 16:01:59.891597 | a416cc5e-e39d-471e-9e8c-c4f9f26f677b ==============================
[0m16:01:59.891597 [info ] [MainThread]: Running with dbt=1.8.7
[0m16:01:59.892058 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:02:00.059501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb7df0a30>]}
[0m16:02:00.112624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb704c6a0>]}
[0m16:02:00.114994 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m16:02:00.123899 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m16:02:00.190081 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m16:02:00.190587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb70310c0>]}
[0m16:02:00.988773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8d4d990>]}
[0m16:02:01.045474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8cfee60>]}
[0m16:02:01.045972 [info ] [MainThread]: Found 7 models, 8 sources, 416 macros
[0m16:02:01.046312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8cfecb0>]}
[0m16:02:01.047558 [info ] [MainThread]: 
[0m16:02:01.048060 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m16:02:01.051854 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_mtastats'
[0m16:02:01.079110 [debug] [ThreadPool]: Using duckdb connection "list_mtastats"
[0m16:02:01.079562 [debug] [ThreadPool]: On list_mtastats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"mtastats"'
    
  
  
[0m16:02:01.079861 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:02:01.089664 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m16:02:01.090920 [debug] [ThreadPool]: On list_mtastats: Close
[0m16:02:01.093261 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mtastats, now create_mtastats_main)
[0m16:02:01.093728 [debug] [ThreadPool]: Creating schema "database: "mtastats"
schema: "main"
"
[0m16:02:01.098459 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m16:02:01.098737 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
        select type from duckdb_databases()
        where database_name='mtastats'
        and type='sqlite'
    
  
[0m16:02:01.099016 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:02:01.105315 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m16:02:01.106503 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m16:02:01.106822 [debug] [ThreadPool]: On create_mtastats_main: BEGIN
[0m16:02:01.107730 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m16:02:01.108020 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m16:02:01.108273 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
    
        create schema if not exists "mtastats"."main"
    
[0m16:02:01.108703 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m16:02:01.109290 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m16:02:01.109536 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m16:02:01.109777 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m16:02:01.110753 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m16:02:01.111065 [debug] [ThreadPool]: On create_mtastats_main: Close
[0m16:02:01.113721 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_mtastats_main, now list_mtastats_main)
[0m16:02:01.117926 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m16:02:01.118254 [debug] [ThreadPool]: On list_mtastats_main: BEGIN
[0m16:02:01.118518 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:02:01.123934 [debug] [ThreadPool]: SQL status: OK in 0.005 seconds
[0m16:02:01.124241 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m16:02:01.124516 [debug] [ThreadPool]: On list_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats_main"} */
select
      'mtastats' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'mtastats'
  
[0m16:02:01.140640 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m16:02:01.141896 [debug] [ThreadPool]: On list_mtastats_main: ROLLBACK
[0m16:02:01.142327 [debug] [ThreadPool]: Failed to rollback 'list_mtastats_main'
[0m16:02:01.142559 [debug] [ThreadPool]: On list_mtastats_main: Close
[0m16:02:01.146133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8d801c0>]}
[0m16:02:01.146484 [debug] [MainThread]: Using duckdb connection "master"
[0m16:02:01.146717 [debug] [MainThread]: On master: BEGIN
[0m16:02:01.146928 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:02:01.151915 [debug] [MainThread]: SQL status: OK in 0.005 seconds
[0m16:02:01.152187 [debug] [MainThread]: On master: COMMIT
[0m16:02:01.152427 [debug] [MainThread]: Using duckdb connection "master"
[0m16:02:01.152646 [debug] [MainThread]: On master: COMMIT
[0m16:02:01.152994 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:02:01.153228 [debug] [MainThread]: On master: Close
[0m16:02:01.155016 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m16:02:01.155436 [info ] [MainThread]: 
[0m16:02:01.162240 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m16:02:01.163000 [info ] [Thread-1 (]: 1 of 7 START sql table model main.avg_riders_per_day ........................... [RUN]
[0m16:02:01.163666 [debug] [Thread-2 (]: Began running node model.mta.busiest_specific_times
[0m16:02:01.164565 [debug] [Thread-3 (]: Began running node model.mta.fare_class_boro
[0m16:02:01.165829 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m16:02:01.166461 [debug] [Thread-4 (]: Began running node model.mta.omny_adoption_by_station
[0m16:02:01.167179 [debug] [Thread-5 (]: Began running node model.mta.omny_adoption_increase
[0m16:02:01.168353 [debug] [Thread-6 (]: Began running node model.mta.total_riders_per_station
[0m16:02:01.167958 [info ] [Thread-2 (]: 2 of 7 START sql table model main.busiest_specific_times ....................... [RUN]
[0m16:02:01.169285 [debug] [Thread-7 (]: Began running node model.mta.weekly_riders_per_station
[0m16:02:01.170349 [info ] [Thread-3 (]: 3 of 7 START sql table model main.fare_class_boro .............................. [RUN]
[0m16:02:01.170911 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m16:02:01.171605 [info ] [Thread-4 (]: 4 of 7 START sql table model main.omny_adoption_by_station ..................... [RUN]
[0m16:02:01.172440 [info ] [Thread-5 (]: 5 of 7 START sql table model main.omny_adoption_increase ....................... [RUN]
[0m16:02:01.173250 [info ] [Thread-6 (]: 6 of 7 START sql table model main.total_riders_per_station ..................... [RUN]
[0m16:02:01.174160 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m16:02:01.175690 [info ] [Thread-7 (]: 7 of 7 START sql table model main.weekly_riders_per_station .................... [RUN]
[0m16:02:01.178541 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m16:02:01.185983 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m16:02:01.189153 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m16:02:01.189884 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_mtastats_main, now model.mta.omny_adoption_increase)
[0m16:02:01.190565 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m16:02:01.191118 [debug] [Thread-2 (]: Began compiling node model.mta.busiest_specific_times
[0m16:02:01.191696 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m16:02:01.192101 [debug] [Thread-3 (]: Began compiling node model.mta.fare_class_boro
[0m16:02:01.192456 [debug] [Thread-4 (]: Began compiling node model.mta.omny_adoption_by_station
[0m16:02:01.193026 [debug] [Thread-5 (]: Began compiling node model.mta.omny_adoption_increase
[0m16:02:01.193579 [debug] [Thread-6 (]: Began compiling node model.mta.total_riders_per_station
[0m16:02:01.195991 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m16:02:01.196420 [debug] [Thread-7 (]: Began compiling node model.mta.weekly_riders_per_station
[0m16:02:01.196781 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m16:02:01.199179 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m16:02:01.202426 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m16:02:01.206668 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m16:02:01.210013 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m16:02:01.213473 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m16:02:01.213871 [debug] [Thread-2 (]: Began executing node model.mta.busiest_specific_times
[0m16:02:01.244897 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m16:02:01.245648 [debug] [Thread-3 (]: Began executing node model.mta.fare_class_boro
[0m16:02:01.247278 [debug] [Thread-5 (]: Began executing node model.mta.omny_adoption_increase
[0m16:02:01.247723 [debug] [Thread-4 (]: Began executing node model.mta.omny_adoption_by_station
[0m16:02:01.248140 [debug] [Thread-6 (]: Began executing node model.mta.total_riders_per_station
[0m16:02:01.251481 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m16:02:01.256427 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m16:02:01.257130 [debug] [Thread-7 (]: Began executing node model.mta.weekly_riders_per_station
[0m16:02:01.259861 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m16:02:01.260291 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:02:01.263481 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m16:02:01.313633 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m16:02:01.314635 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m16:02:01.317470 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m16:02:01.318356 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:02:01.318767 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m16:02:01.319231 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:02:01.320148 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: BEGIN
[0m16:02:01.320508 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:02:01.320913 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:02:01.321383 [debug] [Thread-3 (]: On model.mta.fare_class_boro: BEGIN
[0m16:02:01.321838 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m16:02:01.322167 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:02:01.322568 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: BEGIN
[0m16:02:01.322903 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m16:02:01.323251 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m16:02:01.323599 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: BEGIN
[0m16:02:01.323936 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:02:01.330070 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: BEGIN
[0m16:02:01.330631 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m16:02:01.331273 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:02:01.331687 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m16:02:01.332561 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:02:01.333554 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m16:02:01.334469 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:02:01.334839 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m16:02:01.337787 [debug] [Thread-2 (]: SQL status: OK in 0.015 seconds
[0m16:02:01.338167 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m16:02:01.338724 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "mtastats"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m16:02:01.339485 [debug] [Thread-3 (]: SQL status: OK in 0.016 seconds
[0m16:02:01.339889 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:02:01.340276 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m16:02:01.343543 [debug] [Thread-5 (]: SQL status: OK in 0.013 seconds
[0m16:02:01.344038 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:02:01.344618 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m16:02:01.345630 [debug] [Thread-4 (]: SQL status: OK in 0.014 seconds
[0m16:02:01.345962 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:02:01.346298 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH total_ridership_by_station AS (
    -- Calculate total ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_ridership_by_station AS (
    -- Calculate OMNY ridership by station, year, latitude, and longitude
    SELECT 
        station_complex_id, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(ridership) AS omny_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        payment_method = 'omny'
    GROUP BY 
        station_complex_id, latitude, longitude, year
)
SELECT 
    t.station_complex_id AS station_id,
    t.station_complex AS station_name,
    t.latitude,
    t.longitude,
    t.year, 
    (o.omny_ridership / t.total_ridership) AS omny_percentage
FROM 
    total_ridership_by_station t
LEFT JOIN 
    omny_ridership_by_station o
    ON t.station_complex_id = o.station_complex_id 
    AND t.latitude = o.latitude
    AND t.longitude = o.longitude
    AND t.year = o.year
ORDER BY 
    t.year, omny_percentage DESC
    );
  
  
[0m16:02:01.348135 [debug] [Thread-6 (]: SQL status: OK in 0.016 seconds
[0m16:02:01.348559 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:02:01.348994 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m16:02:01.352353 [debug] [Thread-7 (]: SQL status: OK in 0.020 seconds
[0m16:02:01.352870 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:02:01.353246 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      WITH ridership_data AS (
    SELECT 
        station_complex_id, 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_date, 
        SUM(ridership) AS total_ridership,
        latitude,
        longitude
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex_id, 
        station_complex, 
        week_date, 
        latitude, 
        longitude
),
weather_data AS (
    SELECT
        DATE_TRUNC('week', date) AS week_date, 
        SUM(precipitation_sum) AS total_precipitation -- Using the precipitation_sum column for total rain
    FROM 
           "mtastats"."main"."daily_weather_asset"
    GROUP BY 
        week_date
)
SELECT 
    r.station_complex_id,
    r.station_complex,
    r.latitude,
    r.longitude,
    r.week_date,
    r.total_ridership,
    w.total_precipitation
FROM 
    ridership_data r
LEFT JOIN 
    weather_data w
ON 
    r.week_date = w.week_date
ORDER BY 
    r.week_date, r.total_ridership DESC
    );
  
  
[0m16:02:03.233276 [debug] [Thread-1 (]: SQL status: OK in 1.898 seconds
[0m16:02:03.265092 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:02:03.285412 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "mtastats"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m16:02:03.286779 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m16:02:03.335733 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m16:02:03.336730 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:02:03.337392 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m16:02:03.376069 [debug] [Thread-1 (]: SQL status: OK in 0.034 seconds
[0m16:02:03.385528 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m16:02:03.386397 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "mtastats"."main"."avg_riders_per_day__dbt_backup" cascade
[0m16:02:03.401354 [debug] [Thread-1 (]: SQL status: OK in 0.014 seconds
[0m16:02:03.406160 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m16:02:03.421154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8170d30>]}
[0m16:02:03.422760 [info ] [Thread-1 (]: 1 of 7 OK created sql table model main.avg_riders_per_day ...................... [[32mOK[0m in 2.25s]
[0m16:02:03.424434 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m16:02:04.972862 [debug] [Thread-2 (]: SQL status: OK in 3.634 seconds
[0m16:02:04.978410 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m16:02:04.979305 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "mtastats"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m16:02:04.980564 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m16:02:04.984236 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m16:02:04.985445 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m16:02:04.986191 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: COMMIT
[0m16:02:05.009755 [debug] [Thread-2 (]: SQL status: OK in 0.023 seconds
[0m16:02:05.014356 [debug] [Thread-2 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m16:02:05.015536 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "mtastats"."main"."busiest_specific_times__dbt_backup" cascade
[0m16:02:05.017272 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m16:02:05.019751 [debug] [Thread-2 (]: On model.mta.busiest_specific_times: Close
[0m16:02:05.020723 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8171c00>]}
[0m16:02:05.021804 [info ] [Thread-2 (]: 2 of 7 OK created sql table model main.busiest_specific_times .................. [[32mOK[0m in 3.85s]
[0m16:02:05.023003 [debug] [Thread-2 (]: Finished running node model.mta.busiest_specific_times
[0m16:02:07.468691 [debug] [Thread-5 (]: SQL status: OK in 6.123 seconds
[0m16:02:07.475571 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:02:07.476500 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "mtastats"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m16:02:07.477738 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m16:02:07.480623 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m16:02:07.481444 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:02:07.482077 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: COMMIT
[0m16:02:07.509402 [debug] [Thread-5 (]: SQL status: OK in 0.026 seconds
[0m16:02:07.513889 [debug] [Thread-5 (]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m16:02:07.514856 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "mtastats"."main"."omny_adoption_increase__dbt_backup" cascade
[0m16:02:07.517545 [debug] [Thread-5 (]: SQL status: OK in 0.001 seconds
[0m16:02:07.520804 [debug] [Thread-5 (]: On model.mta.omny_adoption_increase: Close
[0m16:02:07.522111 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca81728f0>]}
[0m16:02:07.530405 [info ] [Thread-5 (]: 5 of 7 OK created sql table model main.omny_adoption_increase .................. [[32mOK[0m in 6.33s]
[0m16:02:07.531633 [debug] [Thread-5 (]: Finished running node model.mta.omny_adoption_increase
[0m16:02:07.625380 [debug] [Thread-7 (]: SQL status: OK in 6.271 seconds
[0m16:02:07.631007 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:02:07.635514 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "mtastats"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m16:02:07.637178 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m16:02:07.640799 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m16:02:07.643198 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:02:07.644004 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: COMMIT
[0m16:02:07.696505 [debug] [Thread-4 (]: SQL status: OK in 6.350 seconds
[0m16:02:07.717440 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:02:07.718975 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "mtastats"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m16:02:07.719762 [debug] [Thread-7 (]: SQL status: OK in 0.045 seconds
[0m16:02:07.739580 [debug] [Thread-7 (]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m16:02:07.740924 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "mtastats"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m16:02:07.741897 [debug] [Thread-4 (]: SQL status: OK in 0.007 seconds
[0m16:02:07.744731 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m16:02:07.745611 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:02:07.746512 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m16:02:07.747462 [debug] [Thread-7 (]: SQL status: OK in 0.006 seconds
[0m16:02:07.752188 [debug] [Thread-7 (]: On model.mta.weekly_riders_per_station: Close
[0m16:02:07.753168 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca81a8b50>]}
[0m16:02:07.754181 [info ] [Thread-7 (]: 7 of 7 OK created sql table model main.weekly_riders_per_station ............... [[32mOK[0m in 6.56s]
[0m16:02:07.755379 [debug] [Thread-7 (]: Finished running node model.mta.weekly_riders_per_station
[0m16:02:07.764689 [debug] [Thread-4 (]: SQL status: OK in 0.016 seconds
[0m16:02:07.772932 [debug] [Thread-4 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m16:02:07.773686 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "mtastats"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m16:02:07.774882 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m16:02:07.777653 [debug] [Thread-4 (]: On model.mta.omny_adoption_by_station: Close
[0m16:02:07.779072 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8170520>]}
[0m16:02:07.781583 [info ] [Thread-4 (]: 4 of 7 OK created sql table model main.omny_adoption_by_station ................ [[32mOK[0m in 6.59s]
[0m16:02:07.787893 [debug] [Thread-4 (]: Finished running node model.mta.omny_adoption_by_station
[0m16:02:09.016979 [debug] [Thread-3 (]: SQL status: OK in 7.676 seconds
[0m16:02:09.022397 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:02:09.023136 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "mtastats"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m16:02:09.024256 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m16:02:09.027097 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m16:02:09.027742 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:02:09.028300 [debug] [Thread-3 (]: On model.mta.fare_class_boro: COMMIT
[0m16:02:09.049425 [debug] [Thread-3 (]: SQL status: OK in 0.020 seconds
[0m16:02:09.053945 [debug] [Thread-3 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m16:02:09.054991 [debug] [Thread-3 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "mtastats"."main"."fare_class_boro__dbt_backup" cascade
[0m16:02:09.056309 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m16:02:09.058557 [debug] [Thread-3 (]: On model.mta.fare_class_boro: Close
[0m16:02:09.059652 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ca8170310>]}
[0m16:02:09.060755 [info ] [Thread-3 (]: 3 of 7 OK created sql table model main.fare_class_boro ......................... [[32mOK[0m in 7.88s]
[0m16:02:09.062039 [debug] [Thread-3 (]: Finished running node model.mta.fare_class_boro
[0m16:02:09.119630 [debug] [Thread-6 (]: SQL status: OK in 7.770 seconds
[0m16:02:09.123920 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:02:09.124498 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "mtastats"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m16:02:09.125428 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m16:02:09.126928 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m16:02:09.127258 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:02:09.127541 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: COMMIT
[0m16:02:09.130543 [debug] [Thread-6 (]: SQL status: OK in 0.003 seconds
[0m16:02:09.132599 [debug] [Thread-6 (]: Using duckdb connection "model.mta.total_riders_per_station"
[0m16:02:09.132979 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "mtastats"."main"."total_riders_per_station__dbt_backup" cascade
[0m16:02:09.133712 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m16:02:09.135018 [debug] [Thread-6 (]: On model.mta.total_riders_per_station: Close
[0m16:02:09.209724 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a416cc5e-e39d-471e-9e8c-c4f9f26f677b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cab1193f0>]}
[0m16:02:09.210499 [info ] [Thread-6 (]: 6 of 7 OK created sql table model main.total_riders_per_station ................ [[32mOK[0m in 8.02s]
[0m16:02:09.211060 [debug] [Thread-6 (]: Finished running node model.mta.total_riders_per_station
[0m16:02:09.213736 [debug] [MainThread]: Using duckdb connection "master"
[0m16:02:09.214112 [debug] [MainThread]: On master: BEGIN
[0m16:02:09.214403 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:02:09.220326 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m16:02:09.220789 [debug] [MainThread]: On master: COMMIT
[0m16:02:09.221100 [debug] [MainThread]: Using duckdb connection "master"
[0m16:02:09.221356 [debug] [MainThread]: On master: COMMIT
[0m16:02:09.221842 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m16:02:09.222192 [debug] [MainThread]: On master: Close
[0m16:02:09.224461 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:02:09.224908 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m16:02:09.225187 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m16:02:09.225423 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m16:02:09.225652 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m16:02:09.225930 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m16:02:09.226137 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m16:02:09.226342 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m16:02:09.226703 [info ] [MainThread]: 
[0m16:02:09.227085 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 8.18 seconds (8.18s).
[0m16:02:09.228274 [debug] [MainThread]: Command end result
[0m16:02:09.253304 [info ] [MainThread]: 
[0m16:02:09.253856 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:02:09.254192 [info ] [MainThread]: 
[0m16:02:09.254545 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m16:02:09.255292 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.405769, "process_user_time": 116.8813, "process_kernel_time": 3.092097, "process_mem_max_rss": "531588", "process_out_blocks": "18232", "process_in_blocks": "0"}
[0m16:02:09.255831 [debug] [MainThread]: Command `dbt run` succeeded at 16:02:09.255732 after 9.41 seconds
[0m16:02:09.256181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb7d2b430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1cb6babe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1caaf065f0>]}
[0m16:02:09.256501 [debug] [MainThread]: Flushing usage events
[0m16:02:14.334752 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.
