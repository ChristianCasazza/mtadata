[0m02:33:17.302734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a047173a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a02dc3e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a02dc2230>]}


============================== 02:33:17.307488 | 9f511418-8fb2-4e68-9237-8a00a96a1d69 ==============================
[0m02:33:17.307488 [info ] [MainThread]: Running with dbt=1.8.7
[0m02:33:17.307945 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:33:17.313966 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'LAKE_PATH'
[0m02:33:17.315197 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.0594247, "process_user_time": 1.052545, "process_kernel_time": 0.222653, "process_mem_max_rss": "91316", "process_in_blocks": "21608", "process_out_blocks": "16", "command_success": false}
[0m02:33:17.315748 [debug] [MainThread]: Command `dbt run` failed at 02:33:17.315660 after 0.06 seconds
[0m02:33:17.316047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a047173a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a02dc0b20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a02dc3f10>]}
[0m02:33:17.316354 [debug] [MainThread]: Flushing usage events
[0m02:47:49.216352 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe032e77370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0329fabc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe031522b00>]}


============================== 02:47:49.222119 | 5fbe0b15-d8f0-429e-80c0-eef581f953b4 ==============================
[0m02:47:49.222119 [info ] [MainThread]: Running with dbt=1.8.7
[0m02:47:49.222645 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:47:49.447584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0314e39a0>]}
[0m02:47:49.504796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0314494e0>]}
[0m02:47:49.508584 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m02:47:49.516232 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m02:47:49.629226 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:47:49.629618 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:47:49.657894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0314c6110>]}
[0m02:47:49.792037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe026078f40>]}
[0m02:47:49.792870 [info ] [MainThread]: Found 13 models, 9 sources, 416 macros
[0m02:47:49.793291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe02607bd60>]}
[0m02:47:49.795069 [info ] [MainThread]: 
[0m02:47:49.795634 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m02:47:49.800687 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_mtastats'
[0m02:47:49.994908 [debug] [ThreadPool]: Using duckdb connection "list_mtastats"
[0m02:47:49.995324 [debug] [ThreadPool]: On list_mtastats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"mtastats"'
    
  
  
[0m02:47:49.995817 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:47:50.023022 [debug] [ThreadPool]: SQL status: OK in 0.027 seconds
[0m02:47:50.024117 [debug] [ThreadPool]: On list_mtastats: Close
[0m02:47:50.026522 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mtastats, now create_mtastats_main)
[0m02:47:50.027294 [debug] [ThreadPool]: Creating schema "database: "mtastats"
schema: "main"
"
[0m02:47:50.032078 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m02:47:50.032353 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
        select type from duckdb_databases()
        where database_name='mtastats'
        and type='sqlite'
    
  
[0m02:47:50.032617 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:50.041222 [debug] [ThreadPool]: SQL status: OK in 0.009 seconds
[0m02:47:50.042397 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m02:47:50.042880 [debug] [ThreadPool]: On create_mtastats_main: BEGIN
[0m02:47:50.043599 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m02:47:50.044025 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m02:47:50.044418 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
    
        create schema if not exists "mtastats"."main"
    
[0m02:47:50.045577 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m02:47:50.046340 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m02:47:50.046600 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m02:47:50.046856 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m02:47:50.047341 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m02:47:50.047681 [debug] [ThreadPool]: On create_mtastats_main: Close
[0m02:47:50.051770 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_mtastats_main, now list_mtastats_main)
[0m02:47:50.056170 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m02:47:50.056547 [debug] [ThreadPool]: On list_mtastats_main: BEGIN
[0m02:47:50.056957 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:47:50.064627 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m02:47:50.065109 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m02:47:50.065434 [debug] [ThreadPool]: On list_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats_main"} */
select
      'mtastats' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'mtastats'
  
[0m02:47:50.086612 [debug] [ThreadPool]: SQL status: OK in 0.021 seconds
[0m02:47:50.088175 [debug] [ThreadPool]: On list_mtastats_main: ROLLBACK
[0m02:47:50.091005 [debug] [ThreadPool]: Failed to rollback 'list_mtastats_main'
[0m02:47:50.091369 [debug] [ThreadPool]: On list_mtastats_main: Close
[0m02:47:50.094665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe026251f00>]}
[0m02:47:50.095089 [debug] [MainThread]: Using duckdb connection "master"
[0m02:47:50.095349 [debug] [MainThread]: On master: BEGIN
[0m02:47:50.095565 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:47:50.102295 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m02:47:50.102606 [debug] [MainThread]: On master: COMMIT
[0m02:47:50.102876 [debug] [MainThread]: Using duckdb connection "master"
[0m02:47:50.103095 [debug] [MainThread]: On master: COMMIT
[0m02:47:50.103498 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m02:47:50.103724 [debug] [MainThread]: On master: Close
[0m02:47:50.105420 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m02:47:50.105753 [info ] [MainThread]: 
[0m02:47:50.119255 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m02:47:50.121074 [debug] [Thread-2 (]: Began running node model.mta.bond_payment_info
[0m02:47:50.120391 [info ] [Thread-1 (]: 1 of 13 START sql table model main.avg_riders_per_day .......................... [RUN]
[0m02:47:50.122126 [debug] [Thread-3 (]: Began running node model.mta.busiest_specific_times
[0m02:47:50.123617 [info ] [Thread-2 (]: 2 of 13 START sql table model main.bond_payment_info ........................... [RUN]
[0m02:47:50.125126 [debug] [Thread-4 (]: Began running node model.mta.daily_ridership
[0m02:47:50.126252 [debug] [Thread-5 (]: Began running node model.mta.expense_type_per_year
[0m02:47:50.127433 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m02:47:50.127993 [debug] [Thread-6 (]: Began running node model.mta.fare_class_boro
[0m02:47:50.128619 [debug] [Thread-7 (]: Began running node model.mta.labor_expenses_per_agency
[0m02:47:50.129830 [info ] [Thread-3 (]: 3 of 13 START sql table model main.busiest_specific_times ...................... [RUN]
[0m02:47:50.130763 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.bond_payment_info'
[0m02:47:50.131452 [debug] [Thread-8 (]: Began running node model.mta.largest_expense_differences_2023
[0m02:47:50.132220 [debug] [Thread-9 (]: Began running node model.mta.omny_adoption_by_station
[0m02:47:50.132943 [info ] [Thread-4 (]: 4 of 13 START sql table model main.daily_ridership ............................. [RUN]
[0m02:47:50.134212 [debug] [Thread-10 ]: Began running node model.mta.omny_adoption_increase
[0m02:47:50.134853 [debug] [Thread-11 ]: Began running node model.mta.subway_station_stats
[0m02:47:50.137115 [debug] [Thread-12 ]: Began running node model.mta.total_riders_per_station
[0m02:47:50.139030 [debug] [Thread-13 ]: Began running node model.mta.weekly_riders_per_station
[0m02:47:50.136601 [info ] [Thread-5 (]: 5 of 13 START sql table model main.expense_type_per_year ....................... [RUN]
[0m02:47:50.140439 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m02:47:50.141269 [info ] [Thread-6 (]: 6 of 13 START sql table model main.fare_class_boro ............................. [RUN]
[0m02:47:50.142106 [info ] [Thread-7 (]: 7 of 13 START sql table model main.labor_expenses_per_agency ................... [RUN]
[0m02:47:50.143133 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m02:47:50.143776 [debug] [Thread-2 (]: Began compiling node model.mta.bond_payment_info
[0m02:47:50.144565 [info ] [Thread-8 (]: 8 of 13 START sql table model main.largest_expense_differences_2023 ............ [RUN]
[0m02:47:50.145421 [info ] [Thread-9 (]: 9 of 13 START sql table model main.omny_adoption_by_station .................... [RUN]
[0m02:47:50.146444 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.daily_ridership'
[0m02:47:50.147369 [info ] [Thread-10 ]: 10 of 13 START sql table model main.omny_adoption_increase ..................... [RUN]
[0m02:47:50.148061 [info ] [Thread-11 ]: 11 of 13 START sql table model main.subway_station_stats ....................... [RUN]
[0m02:47:50.149028 [info ] [Thread-12 ]: 12 of 13 START sql table model main.total_riders_per_station ................... [RUN]
[0m02:47:50.149610 [info ] [Thread-13 ]: 13 of 13 START sql table model main.weekly_riders_per_station .................. [RUN]
[0m02:47:50.150399 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_mtastats_main, now model.mta.expense_type_per_year)
[0m02:47:50.158548 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m02:47:50.162166 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m02:47:50.164324 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.labor_expenses_per_agency'
[0m02:47:50.165045 [debug] [Thread-3 (]: Began compiling node model.mta.busiest_specific_times
[0m02:47:50.167748 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.bond_payment_info"
[0m02:47:50.168549 [debug] [Thread-8 (]: Acquiring new duckdb connection 'model.mta.largest_expense_differences_2023'
[0m02:47:50.169188 [debug] [Thread-9 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m02:47:50.169747 [debug] [Thread-4 (]: Began compiling node model.mta.daily_ridership
[0m02:47:50.170482 [debug] [Thread-10 ]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m02:47:50.171181 [debug] [Thread-11 ]: Acquiring new duckdb connection 'model.mta.subway_station_stats'
[0m02:47:50.172222 [debug] [Thread-12 ]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m02:47:50.172901 [debug] [Thread-13 ]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m02:47:50.173391 [debug] [Thread-5 (]: Began compiling node model.mta.expense_type_per_year
[0m02:47:50.174009 [debug] [Thread-6 (]: Began compiling node model.mta.fare_class_boro
[0m02:47:50.174855 [debug] [Thread-7 (]: Began compiling node model.mta.labor_expenses_per_agency
[0m02:47:50.180737 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m02:47:50.181995 [debug] [Thread-8 (]: Began compiling node model.mta.largest_expense_differences_2023
[0m02:47:50.182907 [debug] [Thread-9 (]: Began compiling node model.mta.omny_adoption_by_station
[0m02:47:50.205290 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.daily_ridership"
[0m02:47:50.206104 [debug] [Thread-10 ]: Began compiling node model.mta.omny_adoption_increase
[0m02:47:50.206810 [debug] [Thread-11 ]: Began compiling node model.mta.subway_station_stats
[0m02:47:50.207421 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m02:47:50.207874 [debug] [Thread-12 ]: Began compiling node model.mta.total_riders_per_station
[0m02:47:50.208322 [debug] [Thread-2 (]: Began executing node model.mta.bond_payment_info
[0m02:47:50.208920 [debug] [Thread-13 ]: Began compiling node model.mta.weekly_riders_per_station
[0m02:47:50.217801 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.expense_type_per_year"
[0m02:47:50.273942 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.labor_expenses_per_agency"
[0m02:47:50.276137 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m02:47:50.281734 [debug] [Thread-8 (]: Writing injected SQL for node "model.mta.largest_expense_differences_2023"
[0m02:47:50.284377 [debug] [Thread-9 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m02:47:50.285199 [debug] [Thread-3 (]: Began executing node model.mta.busiest_specific_times
[0m02:47:50.287954 [debug] [Thread-10 ]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m02:47:50.293143 [debug] [Thread-11 ]: Writing injected SQL for node "model.mta.subway_station_stats"
[0m02:47:50.304377 [debug] [Thread-12 ]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m02:47:50.311023 [debug] [Thread-4 (]: Began executing node model.mta.daily_ridership
[0m02:47:50.330208 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m02:47:50.332799 [debug] [Thread-13 ]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m02:47:50.333441 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.bond_payment_info"
[0m02:47:50.337323 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m02:47:50.339400 [debug] [Thread-9 (]: Began executing node model.mta.omny_adoption_by_station
[0m02:47:50.340384 [debug] [Thread-5 (]: Began executing node model.mta.expense_type_per_year
[0m02:47:50.340884 [debug] [Thread-8 (]: Began executing node model.mta.largest_expense_differences_2023
[0m02:47:50.341678 [debug] [Thread-7 (]: Began executing node model.mta.labor_expenses_per_agency
[0m02:47:50.342729 [debug] [Thread-10 ]: Began executing node model.mta.omny_adoption_increase
[0m02:47:50.345601 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.daily_ridership"
[0m02:47:50.345995 [debug] [Thread-11 ]: Began executing node model.mta.subway_station_stats
[0m02:47:50.346848 [debug] [Thread-6 (]: Began executing node model.mta.fare_class_boro
[0m02:47:50.347321 [debug] [Thread-12 ]: Began executing node model.mta.total_riders_per_station
[0m02:47:50.348182 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m02:47:50.352178 [debug] [Thread-9 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m02:47:50.353768 [debug] [Thread-13 ]: Began executing node model.mta.weekly_riders_per_station
[0m02:47:50.354338 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m02:47:50.354856 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m02:47:50.358694 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.expense_type_per_year"
[0m02:47:50.362312 [debug] [Thread-8 (]: Writing runtime sql for node "model.mta.largest_expense_differences_2023"
[0m02:47:50.364718 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.labor_expenses_per_agency"
[0m02:47:50.369023 [debug] [Thread-10 ]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m02:47:50.371741 [debug] [Thread-11 ]: Writing runtime sql for node "model.mta.subway_station_stats"
[0m02:47:50.374788 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m02:47:50.377706 [debug] [Thread-12 ]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m02:47:50.378252 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m02:47:50.382954 [debug] [Thread-13 ]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m02:47:50.384207 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m02:47:50.384705 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: BEGIN
[0m02:47:50.385097 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m02:47:50.385594 [debug] [Thread-2 (]: On model.mta.bond_payment_info: BEGIN
[0m02:47:50.386596 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m02:47:50.387068 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m02:47:50.389505 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m02:47:50.390948 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m02:47:50.391675 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m02:47:50.392115 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m02:47:50.392678 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m02:47:50.393495 [debug] [Thread-4 (]: On model.mta.daily_ridership: BEGIN
[0m02:47:50.393873 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m02:47:50.394318 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m02:47:50.395005 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m02:47:50.395391 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m02:47:50.395885 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m02:47:50.396314 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: BEGIN
[0m02:47:50.396762 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: BEGIN
[0m02:47:50.397180 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: BEGIN
[0m02:47:50.397598 [debug] [Thread-11 ]: On model.mta.subway_station_stats: BEGIN
[0m02:47:50.398042 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: BEGIN
[0m02:47:50.398458 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: BEGIN
[0m02:47:50.420847 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m02:47:50.421545 [debug] [Thread-6 (]: On model.mta.fare_class_boro: BEGIN
[0m02:47:50.422572 [debug] [Thread-9 (]: Opening a new connection, currently in state init
[0m02:47:50.423753 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: BEGIN
[0m02:47:50.424192 [debug] [Thread-1 (]: SQL status: OK in 0.032 seconds
[0m02:47:50.425102 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m02:47:50.425670 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m02:47:50.426152 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m02:47:50.426652 [debug] [Thread-11 ]: Opening a new connection, currently in state init
[0m02:47:50.427254 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m02:47:50.427985 [debug] [Thread-12 ]: Opening a new connection, currently in state init
[0m02:47:50.428694 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m02:47:50.429118 [debug] [Thread-3 (]: SQL status: OK in 0.035 seconds
[0m02:47:50.430161 [debug] [Thread-13 ]: Opening a new connection, currently in state init
[0m02:47:50.430669 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m02:47:50.432826 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m02:47:50.434531 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m02:47:50.435276 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "mtastats"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m02:47:50.436291 [debug] [Thread-2 (]: SQL status: OK in 0.040 seconds
[0m02:47:50.439563 [debug] [Thread-4 (]: SQL status: OK in 0.019 seconds
[0m02:47:50.440465 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m02:47:50.441058 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m02:47:50.441628 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */

  
    
    

    create  table
      "mtastats"."main"."bond_payment_info__dbt_tmp"
  
    as (
      WITH payment_stats AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        MAX(timestamp) AS last_payment_date,
        AVG(amount) AS average_payment,
        COUNT(DISTINCT timestamp) AS total_payments,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) AS median_payment
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
first_payment AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = fp.general_ledger AND timestamp = MIN(fp.timestamp)) AS first_payment_amount
    FROM
        mta_operations_statement fp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
last_payment AS (
    SELECT
        general_ledger,
        MAX(timestamp) AS last_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = lp.general_ledger AND timestamp = MAX(lp.timestamp)) AS last_payment_amount
    FROM
        mta_operations_statement lp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
)
-- Wrapping everything inside another DISTINCT query
SELECT DISTINCT
    ps.general_ledger,
    fp.first_payment_date,
    fp.first_payment_amount,
    ps.last_payment_date,
    lp.last_payment_amount,
    ps.average_payment,
    ps.median_payment,
    ps.total_payments
FROM
    payment_stats ps
LEFT JOIN
    first_payment fp ON ps.general_ledger = fp.general_ledger
LEFT JOIN
    last_payment lp ON ps.general_ledger = lp.general_ledger
ORDER BY
    ps.general_ledger
    );
  
  
[0m02:47:50.442348 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */

  
    
    

    create  table
      "mtastats"."main"."daily_ridership__dbt_tmp"
  
    as (
      SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(subways_total_ridership) AS ridership,
    'subway' AS transport_type,
    AVG(subways_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(buses_total_ridership) AS ridership,
    'buses' AS transport_type,
    AVG(buses_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(lirr_total_ridership) AS ridership,
    'lirr' AS transport_type,
    AVG(lirr_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(metro_north_total_ridership) AS ridership,
    'metro_north' AS transport_type,
    AVG(metro_north_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(access_a_ride_total_trips) AS ridership,
    'access_a_ride' AS transport_type,
    AVG(access_a_ride_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(bridges_tunnels_total_traffic) AS ridership,
    'bridges_tunnels' AS transport_type,
    AVG(bridges_tunnels_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(staten_island_railway_total_ridership) AS ridership,
    'staten_island_railway' AS transport_type,
    AVG(staten_island_railway_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type
    );
  
  
[0m02:47:50.447892 [debug] [Thread-9 (]: SQL status: OK in 0.025 seconds
[0m02:47:50.449020 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m02:47:50.449482 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH yearly_data AS (
    SELECT 
        station_complex,
        YEAR(transit_timestamp) AS year,
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) * 1.0 / SUM(ridership) AS omny_percentage
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) IN (2022, 2023, 2024)
    GROUP BY 
        station_complex, 
        YEAR(transit_timestamp)
),
pivoted_data AS (
    SELECT 
        station_complex,
        MAX(CASE WHEN year = 2022 THEN omny_percentage ELSE NULL END) AS omny_2022,
        MAX(CASE WHEN year = 2023 THEN omny_percentage ELSE NULL END) AS omny_2023,
        MAX(CASE WHEN year = 2024 THEN omny_percentage ELSE NULL END) AS omny_2024
    FROM 
        yearly_data
    GROUP BY 
        station_complex
)
SELECT 
    station_complex,
    omny_2022,
    omny_2023,
    omny_2024,
    CASE 
        WHEN omny_2022 IS NOT NULL AND omny_2023 IS NOT NULL THEN 
            (omny_2023 - omny_2022) / omny_2022
        ELSE NULL
    END AS omny_2023_growth,
    CASE 
        WHEN omny_2023 IS NOT NULL AND omny_2024 IS NOT NULL THEN 
            (omny_2024 - omny_2023) / omny_2023
        ELSE NULL
    END AS omny_2024_growth
FROM 
    pivoted_data
ORDER BY 
    station_complex
    );
  
  
[0m02:47:50.453931 [debug] [Thread-5 (]: SQL status: OK in 0.029 seconds
[0m02:47:50.454599 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m02:47:50.455346 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */

  
    
    

    create  table
      "mtastats"."main"."expense_type_per_year__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    general_ledger,
    SUM(amount) AS total_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    scenario = 'Actual'
    AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
GROUP BY 
    agency,
    fiscal_year,
    general_ledger
ORDER BY 
    agency, fiscal_year, general_ledger
    );
  
  
[0m02:47:50.459657 [debug] [Thread-8 (]: SQL status: OK in 0.034 seconds
[0m02:47:50.460614 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m02:47:50.462275 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */

  
    
    

    create  table
      "mtastats"."main"."largest_expense_differences_2023__dbt_tmp"
  
    as (
      WITH expense_differences AS (
    SELECT
        agency,
        general_ledger,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) AS actual_expenses,
        SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS adopted_plan_expenses,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) - SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS difference
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        fiscal_year = 2023
        AND scenario IN ('Actual', 'Adopted Budget')
        AND financial_plan_year = 2023  -- Ensure we use only the 2023 Adopted Budget
        AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
        AND general_ledger != 'Reimbursable Overhead'  -- Exclude Reimbursable Overhead
    GROUP BY
        agency, general_ledger
),
ranked_expenses AS (
    SELECT
        agency,
        general_ledger,
        actual_expenses,
        adopted_plan_expenses,
        difference,
        ROW_NUMBER() OVER (PARTITION BY agency ORDER BY difference DESC) AS rank
    FROM
        expense_differences
    WHERE
        difference > 0  -- Only include cases where actual expenses are larger than the adopted budget
)
SELECT
    agency,
    general_ledger,
    actual_expenses,
    adopted_plan_expenses,
    difference
FROM
    ranked_expenses
WHERE
    rank <= 5  -- Select the top 5 items per agency
ORDER BY
    difference, rank
    );
  
  
[0m02:47:50.469227 [debug] [Thread-10 ]: SQL status: OK in 0.043 seconds
[0m02:47:50.470043 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m02:47:50.470681 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m02:47:50.473926 [debug] [Thread-11 ]: SQL status: OK in 0.047 seconds
[0m02:47:50.475019 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m02:47:50.475646 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */

  
    
    

    create  table
      "mtastats"."main"."subway_station_stats__dbt_tmp"
  
    as (
      WITH ridership_by_day AS (
    SELECT 
        station_complex,
        CAST(transit_timestamp AS DATE) AS day,
        DAYOFWEEK(transit_timestamp) AS weekday,
        SUM(ridership) AS daily_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) = 2024
    GROUP BY 
        station_complex, 
        CAST(transit_timestamp AS DATE), 
        DAYOFWEEK(transit_timestamp)
),
weekday_weekend AS (
    SELECT 
        station_complex,
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END AS day_type,
        AVG(daily_ridership) AS avg_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex, 
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END
),
single_day_stats AS (
    SELECT 
        station_complex,
        MAX(daily_ridership) AS highest_single_day_ridership,
        MIN(daily_ridership) AS lowest_single_day_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex
),
highest_single_day AS (
    SELECT 
        station_complex,
        day AS highest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MAX(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
),
lowest_single_day AS (
    SELECT 
        station_complex,
        day AS lowest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MIN(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
)
SELECT 
    rbd.station_complex,
    MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS avg_weekday_ridership,
    MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) AS avg_weekend_ridership,
    sds.highest_single_day_ridership,
    hsd.highest_single_day_ridership_day,
    sds.lowest_single_day_ridership,
    lsd.lowest_single_day_ridership_day,
    (MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) - MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END)) * 1.0 / MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS weekend_percentage_change
FROM 
    ridership_by_day rbd
JOIN 
    weekday_weekend wwd ON rbd.station_complex = wwd.station_complex
JOIN 
    single_day_stats sds ON rbd.station_complex = sds.station_complex
JOIN 
    highest_single_day hsd ON rbd.station_complex = hsd.station_complex
JOIN 
    lowest_single_day lsd ON rbd.station_complex = lsd.station_complex
GROUP BY 
    rbd.station_complex, 
    sds.highest_single_day_ridership, 
    sds.lowest_single_day_ridership, 
    hsd.highest_single_day_ridership_day, 
    lsd.lowest_single_day_ridership_day
ORDER BY 
    rbd.station_complex
    );
  
  
[0m02:47:50.479325 [debug] [Thread-7 (]: SQL status: OK in 0.052 seconds
[0m02:47:50.479971 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m02:47:50.480549 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */

  
    
    

    create  table
      "mtastats"."main"."labor_expenses_per_agency__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    expense_type,
    general_ledger,
    SUM(amount) AS total_labor_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    subtype = 'Labor Expenses' AND 
    scenario = 'Actual'
GROUP BY 
    agency,
    fiscal_year,
    expense_type,
    general_ledger
ORDER BY 
    agency, fiscal_year, expense_type, general_ledger
    );
  
  
[0m02:47:50.490070 [debug] [Thread-12 ]: SQL status: OK in 0.062 seconds
[0m02:47:50.491168 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m02:47:50.491934 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m02:47:50.499683 [debug] [Thread-6 (]: SQL status: OK in 0.071 seconds
[0m02:47:50.500462 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m02:47:50.501291 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m02:47:50.513465 [debug] [Thread-13 ]: SQL status: OK in 0.083 seconds
[0m02:47:50.514304 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m02:47:50.515059 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      with weekly_ridership AS (
    SELECT 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_start,
        SUM(ridership) AS total_weekly_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp)
)
SELECT 
    station_complex, 
    week_start, 
    total_weekly_ridership
FROM 
    weekly_ridership
ORDER BY 
    station_complex, 
    week_start
    );
  
  
[0m02:47:51.020368 [debug] [Thread-7 (]: SQL status: OK in 0.539 seconds
[0m02:47:51.039738 [debug] [Thread-5 (]: SQL status: OK in 0.581 seconds
[0m02:47:51.049240 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m02:47:51.058589 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m02:47:51.064176 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
alter table "mtastats"."main"."labor_expenses_per_agency__dbt_tmp" rename to "labor_expenses_per_agency"
[0m02:47:51.065690 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
alter table "mtastats"."main"."expense_type_per_year__dbt_tmp" rename to "expense_type_per_year"
[0m02:47:51.072472 [debug] [Thread-8 (]: SQL status: OK in 0.609 seconds
[0m02:47:51.083804 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m02:47:51.085042 [debug] [Thread-5 (]: SQL status: OK in 0.016 seconds
[0m02:47:51.085615 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
alter table "mtastats"."main"."largest_expense_differences_2023__dbt_tmp" rename to "largest_expense_differences_2023"
[0m02:47:51.086176 [debug] [Thread-7 (]: SQL status: OK in 0.018 seconds
[0m02:47:51.294114 [debug] [Thread-4 (]: SQL status: OK in 0.845 seconds
[0m02:47:51.302369 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m02:47:51.304466 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m02:47:51.308863 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m02:47:51.309468 [debug] [Thread-8 (]: SQL status: OK in 0.197 seconds
[0m02:47:51.310216 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m02:47:51.310876 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m02:47:51.311516 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
alter table "mtastats"."main"."daily_ridership__dbt_tmp" rename to "daily_ridership"
[0m02:47:51.313869 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m02:47:51.314576 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m02:47:51.315175 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m02:47:51.315966 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m02:47:51.317089 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m02:47:51.319275 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m02:47:51.321538 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m02:47:51.322124 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m02:47:51.322604 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m02:47:51.348310 [debug] [Thread-5 (]: SQL status: OK in 0.032 seconds
[0m02:47:51.360354 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m02:47:51.363786 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
drop table if exists "mtastats"."main"."expense_type_per_year__dbt_backup" cascade
[0m02:47:51.366474 [debug] [Thread-7 (]: SQL status: OK in 0.050 seconds
[0m02:47:51.369842 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m02:47:51.370294 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
drop table if exists "mtastats"."main"."labor_expenses_per_agency__dbt_backup" cascade
[0m02:47:51.376818 [debug] [Thread-8 (]: SQL status: OK in 0.059 seconds
[0m02:47:51.379359 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m02:47:51.379887 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
drop table if exists "mtastats"."main"."largest_expense_differences_2023__dbt_backup" cascade
[0m02:47:51.475200 [debug] [Thread-4 (]: SQL status: OK in 0.152 seconds
[0m02:47:51.478512 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m02:47:51.479353 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
drop table if exists "mtastats"."main"."daily_ridership__dbt_backup" cascade
[0m02:47:51.498305 [debug] [Thread-5 (]: SQL status: OK in 0.132 seconds
[0m02:47:51.502843 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: Close
[0m02:47:51.506591 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0260609a0>]}
[0m02:47:51.508325 [debug] [Thread-8 (]: SQL status: OK in 0.128 seconds
[0m02:47:51.509699 [info ] [Thread-5 (]: 5 of 13 OK created sql table model main.expense_type_per_year .................. [[32mOK[0m in 1.35s]
[0m02:47:51.510646 [debug] [Thread-7 (]: SQL status: OK in 0.135 seconds
[0m02:47:51.512539 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: Close
[0m02:47:51.513164 [debug] [Thread-4 (]: SQL status: OK in 0.033 seconds
[0m02:47:51.514401 [debug] [Thread-5 (]: Finished running node model.mta.expense_type_per_year
[0m02:47:51.516581 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: Close
[0m02:47:51.517728 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0254bab60>]}
[0m02:47:51.519901 [debug] [Thread-4 (]: On model.mta.daily_ridership: Close
[0m02:47:51.521563 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0254ba9b0>]}
[0m02:47:51.522801 [info ] [Thread-8 (]: 8 of 13 OK created sql table model main.largest_expense_differences_2023 ....... [[32mOK[0m in 1.35s]
[0m02:47:51.523996 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe026062410>]}
[0m02:47:51.525232 [info ] [Thread-7 (]: 7 of 13 OK created sql table model main.labor_expenses_per_agency .............. [[32mOK[0m in 1.36s]
[0m02:47:51.526754 [debug] [Thread-8 (]: Finished running node model.mta.largest_expense_differences_2023
[0m02:47:51.527907 [info ] [Thread-4 (]: 4 of 13 OK created sql table model main.daily_ridership ........................ [[32mOK[0m in 1.38s]
[0m02:47:51.529193 [debug] [Thread-7 (]: Finished running node model.mta.labor_expenses_per_agency
[0m02:47:51.530794 [debug] [Thread-4 (]: Finished running node model.mta.daily_ridership
[0m02:47:52.200152 [debug] [Thread-2 (]: SQL status: OK in 1.757 seconds
[0m02:47:52.216394 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m02:47:52.217257 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
alter table "mtastats"."main"."bond_payment_info__dbt_tmp" rename to "bond_payment_info"
[0m02:47:52.218484 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m02:47:52.226677 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m02:47:52.227751 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m02:47:52.228549 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m02:47:52.239242 [debug] [Thread-2 (]: SQL status: OK in 0.009 seconds
[0m02:47:52.247990 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m02:47:52.249221 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
drop table if exists "mtastats"."main"."bond_payment_info__dbt_backup" cascade
[0m02:47:52.250900 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m02:47:52.258463 [debug] [Thread-2 (]: On model.mta.bond_payment_info: Close
[0m02:47:52.260261 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0260259c0>]}
[0m02:47:52.261787 [info ] [Thread-2 (]: 2 of 13 OK created sql table model main.bond_payment_info ...................... [[32mOK[0m in 2.13s]
[0m02:47:52.264424 [debug] [Thread-2 (]: Finished running node model.mta.bond_payment_info
[0m02:47:54.811870 [debug] [Thread-3 (]: SQL status: OK in 4.371 seconds
[0m02:47:54.828186 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m02:47:54.834188 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "mtastats"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m02:47:54.840521 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m02:47:54.844564 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m02:47:54.845530 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m02:47:54.846379 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m02:47:54.858771 [debug] [Thread-3 (]: SQL status: OK in 0.011 seconds
[0m02:47:54.895232 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m02:47:54.902388 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "mtastats"."main"."busiest_specific_times__dbt_backup" cascade
[0m02:47:54.905596 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m02:47:54.908495 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: Close
[0m02:47:54.909695 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbe0b15-d8f0-429e-80c0-eef581f953b4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0261cfee0>]}
[0m02:47:54.911533 [info ] [Thread-3 (]: 3 of 13 OK created sql table model main.busiest_specific_times ................. [[32mOK[0m in 4.77s]
[0m02:47:54.913150 [debug] [Thread-3 (]: Finished running node model.mta.busiest_specific_times
[0m02:47:56.008739 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.avg_riders_per_day. Details: Connection(type='duckdb', name='model.mta.avg_riders_per_day', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe02479b4f0>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.010981 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.avg_riders_per_day
[0m02:47:56.019875 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.fare_class_boro. Details: Connection(type='duckdb', name='model.mta.fare_class_boro', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe02539b4c0>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.021070 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.fare_class_boro
[0m02:47:56.022037 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.omny_adoption_by_station. Details: Connection(type='duckdb', name='model.mta.omny_adoption_by_station', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe02472b160>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.023332 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.omny_adoption_by_station
[0m02:47:56.024759 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.omny_adoption_increase. Details: Connection(type='duckdb', name='model.mta.omny_adoption_increase', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe02538fd60>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.025666 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.omny_adoption_increase
[0m02:47:56.026439 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.subway_station_stats. Details: Connection(type='duckdb', name='model.mta.subway_station_stats', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe025399c90>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.027220 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.subway_station_stats
[0m02:47:56.028137 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.total_riders_per_station. Details: Connection(type='duckdb', name='model.mta.total_riders_per_station', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe0253757b0>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.028832 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.total_riders_per_station
[0m02:47:56.029457 [debug] [MainThread]: DuckDB adapter: cancelling query on connection model.mta.weekly_riders_per_station. Details: Connection(type='duckdb', name='model.mta.weekly_riders_per_station', state=<ConnectionState.OPEN: 'open'>, transaction_open=True, _handle=<dbt.adapters.duckdb.environments.local.DuckDBConnectionWrapper object at 0x7fe025374790>, _credentials=DuckDBCredentials(database='mtastats', schema='main', path='/home/christianocean/mta/mta/mtastats/sources/mta/mtastats.duckdb', config_options=None, extensions=None, settings={'enable_object_cache': True, 'enable_http_metadata_cache': True}, secrets=[], external_root='.', use_credential_provider=None, attach=None, filesystems=None, remote=None, plugins=None, disable_transactions=False, keep_open=False, module_paths=None, retries=None))
[0m02:47:56.030017 [debug] [MainThread]: DuckDB adapter: query cancelled on connection model.mta.weekly_riders_per_station
[0m02:47:56.030598 [error] [MainThread]: CANCEL query model.mta.expense_type_per_year ................................... [[31mCANCEL[0m]
[0m02:47:56.031235 [error] [MainThread]: CANCEL query model.mta.avg_riders_per_day ...................................... [[31mCANCEL[0m]
[0m02:47:56.031707 [error] [MainThread]: CANCEL query model.mta.bond_payment_info ....................................... [[31mCANCEL[0m]
[0m02:47:56.032100 [error] [MainThread]: CANCEL query model.mta.busiest_specific_times .................................. [[31mCANCEL[0m]
[0m02:47:56.032586 [error] [MainThread]: CANCEL query model.mta.daily_ridership ......................................... [[31mCANCEL[0m]
[0m02:47:56.033194 [error] [MainThread]: CANCEL query model.mta.fare_class_boro ......................................... [[31mCANCEL[0m]
[0m02:47:56.033675 [error] [MainThread]: CANCEL query model.mta.labor_expenses_per_agency ............................... [[31mCANCEL[0m]
[0m02:47:56.034702 [error] [MainThread]: CANCEL query model.mta.largest_expense_differences_2023 ........................ [[31mCANCEL[0m]
[0m02:47:56.035523 [error] [MainThread]: CANCEL query model.mta.omny_adoption_by_station ................................ [[31mCANCEL[0m]
[0m02:47:56.036560 [error] [MainThread]: CANCEL query model.mta.omny_adoption_increase .................................. [[31mCANCEL[0m]
[0m02:47:56.037435 [error] [MainThread]: CANCEL query model.mta.subway_station_stats .................................... [[31mCANCEL[0m]
[0m02:47:56.037971 [error] [MainThread]: CANCEL query model.mta.total_riders_per_station ................................ [[31mCANCEL[0m]
[0m02:47:56.038392 [error] [MainThread]: CANCEL query model.mta.weekly_riders_per_station ............................... [[31mCANCEL[0m]
[0m02:47:56.053059 [debug] [Thread-13 ]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      with weekly_ridership AS (
    SELECT 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_start,
        SUM(ridership) AS total_weekly_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp)
)
SELECT 
    station_complex, 
    week_start, 
    total_weekly_ridership
FROM 
    weekly_ridership
ORDER BY 
    station_complex, 
    week_start
    );
  
  
[0m02:47:56.055317 [debug] [Thread-10 ]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m02:47:56.057051 [debug] [Thread-12 ]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m02:47:56.060853 [debug] [Thread-6 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m02:47:56.064249 [debug] [Thread-9 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH yearly_data AS (
    SELECT 
        station_complex,
        YEAR(transit_timestamp) AS year,
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) * 1.0 / SUM(ridership) AS omny_percentage
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) IN (2022, 2023, 2024)
    GROUP BY 
        station_complex, 
        YEAR(transit_timestamp)
),
pivoted_data AS (
    SELECT 
        station_complex,
        MAX(CASE WHEN year = 2022 THEN omny_percentage ELSE NULL END) AS omny_2022,
        MAX(CASE WHEN year = 2023 THEN omny_percentage ELSE NULL END) AS omny_2023,
        MAX(CASE WHEN year = 2024 THEN omny_percentage ELSE NULL END) AS omny_2024
    FROM 
        yearly_data
    GROUP BY 
        station_complex
)
SELECT 
    station_complex,
    omny_2022,
    omny_2023,
    omny_2024,
    CASE 
        WHEN omny_2022 IS NOT NULL AND omny_2023 IS NOT NULL THEN 
            (omny_2023 - omny_2022) / omny_2022
        ELSE NULL
    END AS omny_2023_growth,
    CASE 
        WHEN omny_2023 IS NOT NULL AND omny_2024 IS NOT NULL THEN 
            (omny_2024 - omny_2023) / omny_2023
        ELSE NULL
    END AS omny_2024_growth
FROM 
    pivoted_data
ORDER BY 
    station_complex
    );
  
  
[0m02:47:56.066215 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m02:47:56.067479 [debug] [Thread-13 ]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.070219 [debug] [Thread-11 ]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */

  
    
    

    create  table
      "mtastats"."main"."subway_station_stats__dbt_tmp"
  
    as (
      WITH ridership_by_day AS (
    SELECT 
        station_complex,
        CAST(transit_timestamp AS DATE) AS day,
        DAYOFWEEK(transit_timestamp) AS weekday,
        SUM(ridership) AS daily_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) = 2024
    GROUP BY 
        station_complex, 
        CAST(transit_timestamp AS DATE), 
        DAYOFWEEK(transit_timestamp)
),
weekday_weekend AS (
    SELECT 
        station_complex,
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END AS day_type,
        AVG(daily_ridership) AS avg_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex, 
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END
),
single_day_stats AS (
    SELECT 
        station_complex,
        MAX(daily_ridership) AS highest_single_day_ridership,
        MIN(daily_ridership) AS lowest_single_day_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex
),
highest_single_day AS (
    SELECT 
        station_complex,
        day AS highest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MAX(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
),
lowest_single_day AS (
    SELECT 
        station_complex,
        day AS lowest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MIN(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
)
SELECT 
    rbd.station_complex,
    MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS avg_weekday_ridership,
    MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) AS avg_weekend_ridership,
    sds.highest_single_day_ridership,
    hsd.highest_single_day_ridership_day,
    sds.lowest_single_day_ridership,
    lsd.lowest_single_day_ridership_day,
    (MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) - MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END)) * 1.0 / MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS weekend_percentage_change
FROM 
    ridership_by_day rbd
JOIN 
    weekday_weekend wwd ON rbd.station_complex = wwd.station_complex
JOIN 
    single_day_stats sds ON rbd.station_complex = sds.station_complex
JOIN 
    highest_single_day hsd ON rbd.station_complex = hsd.station_complex
JOIN 
    lowest_single_day lsd ON rbd.station_complex = lsd.station_complex
GROUP BY 
    rbd.station_complex, 
    sds.highest_single_day_ridership, 
    sds.lowest_single_day_ridership, 
    hsd.highest_single_day_ridership_day, 
    lsd.lowest_single_day_ridership_day
ORDER BY 
    rbd.station_complex
    );
  
  
[0m02:47:56.072290 [debug] [Thread-10 ]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.073427 [debug] [Thread-12 ]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.074139 [debug] [Thread-6 (]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.074640 [debug] [Thread-9 (]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.075161 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.076492 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: ROLLBACK
[0m02:47:56.077092 [debug] [Thread-11 ]: DuckDB adapter: Rolling back transaction.
[0m02:47:56.077965 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: ROLLBACK
[0m02:47:56.078889 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: ROLLBACK
[0m02:47:56.079959 [debug] [Thread-6 (]: On model.mta.fare_class_boro: ROLLBACK
[0m02:47:56.080693 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: ROLLBACK
[0m02:47:56.081819 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: ROLLBACK
[0m02:47:56.083761 [debug] [Thread-11 ]: On model.mta.subway_station_stats: ROLLBACK
[0m02:47:56.119904 [debug] [Thread-11 ]: Failed to rollback 'model.mta.subway_station_stats'
[0m02:47:56.121240 [debug] [Thread-1 (]: Failed to rollback 'model.mta.avg_riders_per_day'
[0m02:47:56.121731 [debug] [Thread-11 ]: On model.mta.subway_station_stats: Close
[0m02:47:56.122380 [debug] [Thread-13 ]: Failed to rollback 'model.mta.weekly_riders_per_station'
[0m02:47:56.123041 [debug] [Thread-9 (]: Failed to rollback 'model.mta.omny_adoption_by_station'
[0m02:47:56.123597 [debug] [Thread-6 (]: Failed to rollback 'model.mta.fare_class_boro'
[0m02:47:56.124148 [debug] [Thread-10 ]: Failed to rollback 'model.mta.omny_adoption_increase'
[0m02:47:56.124627 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m02:47:56.125118 [debug] [Thread-12 ]: Failed to rollback 'model.mta.total_riders_per_station'
[0m02:47:56.126198 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: Close
[0m02:47:56.127012 [debug] [Thread-11 ]: Runtime Error in model subway_station_stats (models/subway_station_stats.sql)
  INTERRUPT Error: Interrupted!
[0m02:47:56.127418 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: Close
[0m02:47:56.127783 [debug] [Thread-6 (]: On model.mta.fare_class_boro: Close
[0m02:47:56.128172 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: Close
[0m02:47:56.129339 [debug] [Thread-1 (]: Runtime Error in model avg_riders_per_day (models/avg_riders_per_day.sql)
  INTERRUPT Error: Interrupted!
[0m02:47:56.129692 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: Close
[0m04:48:11.184871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1e2373a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1de09db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1c8e2a40>]}


============================== 04:48:11.189124 | c8b17d74-2f13-4fb9-8b94-67584b1fa7b4 ==============================
[0m04:48:11.189124 [info ] [MainThread]: Running with dbt=1.8.7
[0m04:48:11.189606 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:48:11.194760 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'LAKE_PATH'
[0m04:48:11.197082 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.058016445, "process_user_time": 1.078374, "process_kernel_time": 0.405542, "process_mem_max_rss": "90988", "process_out_blocks": "8", "command_success": false, "process_in_blocks": "0"}
[0m04:48:11.197761 [debug] [MainThread]: Command `dbt run` failed at 04:48:11.197640 after 0.06 seconds
[0m04:48:11.198163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1e2373a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1c97ae00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1c97b520>]}
[0m04:48:11.198603 [debug] [MainThread]: Flushing usage events
[0m04:49:24.174990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bda4e33d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bd8b8fa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bd8b8e230>]}


============================== 04:49:24.177331 | 797a8a5e-0376-4662-ae18-2a5d36c39116 ==============================
[0m04:49:24.177331 [info ] [MainThread]: Running with dbt=1.8.7
[0m04:49:24.177836 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:49:24.181466 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'LAKE_PATH'
[0m04:49:24.184154 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.053177968, "process_user_time": 0.872276, "process_kernel_time": 0.018363, "process_mem_max_rss": "91268", "process_out_blocks": "16", "command_success": false, "process_in_blocks": "0"}
[0m04:49:24.184904 [debug] [MainThread]: Command `dbt run` failed at 04:49:24.184736 after 0.05 seconds
[0m04:49:24.185991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bda4e33d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bd8c26dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bd8c274f0>]}
[0m04:49:24.186585 [debug] [MainThread]: Flushing usage events
[0m04:52:42.898642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19afdf430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd199689c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19968b5b0>]}


============================== 04:52:42.900671 | b76fbfd5-4ea6-493c-aedd-11146832e425 ==============================
[0m04:52:42.900671 [info ] [MainThread]: Running with dbt=1.8.7
[0m04:52:42.901269 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:52:43.173939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19b0a4a30>]}
[0m04:52:43.227653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd1995fcd60>]}
[0m04:52:43.232720 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m04:52:43.245746 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m04:52:43.385134 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:52:43.385554 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:52:43.420532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd199629720>]}
[0m04:52:43.498137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e10b6d0>]}
[0m04:52:43.498755 [info ] [MainThread]: Found 13 models, 9 sources, 416 macros
[0m04:52:43.499218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e10b790>]}
[0m04:52:43.500967 [info ] [MainThread]: 
[0m04:52:43.501589 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m04:52:43.505936 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_mtastats'
[0m04:52:43.593697 [debug] [ThreadPool]: Using duckdb connection "list_mtastats"
[0m04:52:43.594162 [debug] [ThreadPool]: On list_mtastats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"mtastats"'
    
  
  
[0m04:52:43.594508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:52:43.624413 [debug] [ThreadPool]: SQL status: OK in 0.030 seconds
[0m04:52:43.626335 [debug] [ThreadPool]: On list_mtastats: Close
[0m04:52:43.630284 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mtastats, now create_mtastats_main)
[0m04:52:43.630906 [debug] [ThreadPool]: Creating schema "database: "mtastats"
schema: "main"
"
[0m04:52:43.635567 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m04:52:43.635879 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
        select type from duckdb_databases()
        where database_name='mtastats'
        and type='sqlite'
    
  
[0m04:52:43.636160 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:52:43.646469 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m04:52:43.648298 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m04:52:43.648793 [debug] [ThreadPool]: On create_mtastats_main: BEGIN
[0m04:52:43.650521 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m04:52:43.650801 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m04:52:43.651105 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
    
        create schema if not exists "mtastats"."main"
    
[0m04:52:43.651749 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m04:52:43.652449 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m04:52:43.652709 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m04:52:43.652972 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m04:52:43.653437 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m04:52:43.653727 [debug] [ThreadPool]: On create_mtastats_main: Close
[0m04:52:43.657429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_mtastats_main, now list_mtastats_main)
[0m04:52:43.662767 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m04:52:43.663622 [debug] [ThreadPool]: On list_mtastats_main: BEGIN
[0m04:52:43.664081 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:52:43.670130 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m04:52:43.670611 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m04:52:43.671107 [debug] [ThreadPool]: On list_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats_main"} */
select
      'mtastats' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'mtastats'
  
[0m04:52:43.707374 [debug] [ThreadPool]: SQL status: OK in 0.036 seconds
[0m04:52:43.709346 [debug] [ThreadPool]: On list_mtastats_main: ROLLBACK
[0m04:52:43.711042 [debug] [ThreadPool]: Failed to rollback 'list_mtastats_main'
[0m04:52:43.711379 [debug] [ThreadPool]: On list_mtastats_main: Close
[0m04:52:43.715204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e167760>]}
[0m04:52:43.715771 [debug] [MainThread]: Using duckdb connection "master"
[0m04:52:43.716183 [debug] [MainThread]: On master: BEGIN
[0m04:52:43.716560 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:52:43.739442 [debug] [MainThread]: SQL status: OK in 0.023 seconds
[0m04:52:43.740206 [debug] [MainThread]: On master: COMMIT
[0m04:52:43.740566 [debug] [MainThread]: Using duckdb connection "master"
[0m04:52:43.740871 [debug] [MainThread]: On master: COMMIT
[0m04:52:43.741596 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m04:52:43.742052 [debug] [MainThread]: On master: Close
[0m04:52:43.744593 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m04:52:43.745220 [info ] [MainThread]: 
[0m04:52:43.756602 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m04:52:43.757334 [info ] [Thread-1 (]: 1 of 13 START sql table model main.avg_riders_per_day .......................... [RUN]
[0m04:52:43.758388 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m04:52:43.758791 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m04:52:43.765119 [debug] [Thread-2 (]: Began running node model.mta.bond_payment_info
[0m04:52:43.765868 [debug] [Thread-3 (]: Began running node model.mta.busiest_specific_times
[0m04:52:43.767315 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m04:52:43.767794 [info ] [Thread-2 (]: 2 of 13 START sql table model main.bond_payment_info ........................... [RUN]
[0m04:52:43.768629 [debug] [Thread-4 (]: Began running node model.mta.daily_ridership
[0m04:52:43.769359 [info ] [Thread-3 (]: 3 of 13 START sql table model main.busiest_specific_times ...................... [RUN]
[0m04:52:43.770289 [debug] [Thread-5 (]: Began running node model.mta.expense_type_per_year
[0m04:52:43.770966 [debug] [Thread-6 (]: Began running node model.mta.fare_class_boro
[0m04:52:43.771614 [debug] [Thread-7 (]: Began running node model.mta.labor_expenses_per_agency
[0m04:52:43.772350 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.bond_payment_info'
[0m04:52:43.772766 [debug] [Thread-8 (]: Began running node model.mta.largest_expense_differences_2023
[0m04:52:43.773935 [debug] [Thread-9 (]: Began running node model.mta.omny_adoption_by_station
[0m04:52:43.774405 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m04:52:43.775091 [debug] [Thread-10 ]: Began running node model.mta.omny_adoption_increase
[0m04:52:43.775739 [info ] [Thread-4 (]: 4 of 13 START sql table model main.daily_ridership ............................. [RUN]
[0m04:52:43.776594 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m04:52:43.777197 [debug] [Thread-11 ]: Began running node model.mta.subway_station_stats
[0m04:52:43.778147 [info ] [Thread-5 (]: 5 of 13 START sql table model main.expense_type_per_year ....................... [RUN]
[0m04:52:43.779025 [debug] [Thread-12 ]: Began running node model.mta.total_riders_per_station
[0m04:52:43.780114 [debug] [Thread-13 ]: Began running node model.mta.weekly_riders_per_station
[0m04:52:43.782434 [info ] [Thread-6 (]: 6 of 13 START sql table model main.fare_class_boro ............................. [RUN]
[0m04:52:43.783809 [info ] [Thread-7 (]: 7 of 13 START sql table model main.labor_expenses_per_agency ................... [RUN]
[0m04:52:43.784556 [debug] [Thread-2 (]: Began compiling node model.mta.bond_payment_info
[0m04:52:43.785338 [info ] [Thread-8 (]: 8 of 13 START sql table model main.largest_expense_differences_2023 ............ [RUN]
[0m04:52:43.786128 [info ] [Thread-9 (]: 9 of 13 START sql table model main.omny_adoption_by_station .................... [RUN]
[0m04:52:43.810043 [info ] [Thread-10 ]: 10 of 13 START sql table model main.omny_adoption_increase ..................... [RUN]
[0m04:52:43.823480 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.daily_ridership'
[0m04:52:43.827114 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m04:52:43.827904 [debug] [Thread-3 (]: Began compiling node model.mta.busiest_specific_times
[0m04:52:43.828590 [info ] [Thread-11 ]: 11 of 13 START sql table model main.subway_station_stats ....................... [RUN]
[0m04:52:43.829341 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_mtastats_main, now model.mta.expense_type_per_year)
[0m04:52:43.830061 [info ] [Thread-12 ]: 12 of 13 START sql table model main.total_riders_per_station ................... [RUN]
[0m04:52:43.830884 [info ] [Thread-13 ]: 13 of 13 START sql table model main.weekly_riders_per_station .................. [RUN]
[0m04:52:43.831872 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m04:52:43.832736 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.labor_expenses_per_agency'
[0m04:52:43.840463 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.bond_payment_info"
[0m04:52:43.841589 [debug] [Thread-8 (]: Acquiring new duckdb connection 'model.mta.largest_expense_differences_2023'
[0m04:52:43.842503 [debug] [Thread-9 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m04:52:43.843261 [debug] [Thread-10 ]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m04:52:43.844416 [debug] [Thread-4 (]: Began compiling node model.mta.daily_ridership
[0m04:52:43.909257 [debug] [Thread-11 ]: Acquiring new duckdb connection 'model.mta.subway_station_stats'
[0m04:52:43.911043 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m04:52:43.911799 [debug] [Thread-5 (]: Began compiling node model.mta.expense_type_per_year
[0m04:52:43.912637 [debug] [Thread-12 ]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m04:52:43.913366 [debug] [Thread-13 ]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m04:52:43.913964 [debug] [Thread-6 (]: Began compiling node model.mta.fare_class_boro
[0m04:52:43.914507 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m04:52:43.915038 [debug] [Thread-7 (]: Began compiling node model.mta.labor_expenses_per_agency
[0m04:52:43.916693 [debug] [Thread-8 (]: Began compiling node model.mta.largest_expense_differences_2023
[0m04:52:43.917209 [debug] [Thread-9 (]: Began compiling node model.mta.omny_adoption_by_station
[0m04:52:43.917794 [debug] [Thread-10 ]: Began compiling node model.mta.omny_adoption_increase
[0m04:52:43.924540 [debug] [Thread-2 (]: Began executing node model.mta.bond_payment_info
[0m04:52:43.925486 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.daily_ridership"
[0m04:52:43.925955 [debug] [Thread-11 ]: Began compiling node model.mta.subway_station_stats
[0m04:52:43.928269 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.expense_type_per_year"
[0m04:52:43.928881 [debug] [Thread-12 ]: Began compiling node model.mta.total_riders_per_station
[0m04:52:43.929349 [debug] [Thread-13 ]: Began compiling node model.mta.weekly_riders_per_station
[0m04:52:43.932645 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m04:52:43.933124 [debug] [Thread-3 (]: Began executing node model.mta.busiest_specific_times
[0m04:52:43.933708 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m04:52:43.936835 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.labor_expenses_per_agency"
[0m04:52:43.945279 [debug] [Thread-9 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m04:52:43.947123 [debug] [Thread-8 (]: Writing injected SQL for node "model.mta.largest_expense_differences_2023"
[0m04:52:43.959492 [debug] [Thread-10 ]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m04:52:43.963676 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.bond_payment_info"
[0m04:52:43.972170 [debug] [Thread-11 ]: Writing injected SQL for node "model.mta.subway_station_stats"
[0m04:52:43.972885 [debug] [Thread-4 (]: Began executing node model.mta.daily_ridership
[0m04:52:43.978410 [debug] [Thread-12 ]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m04:52:43.985612 [debug] [Thread-13 ]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m04:52:43.991323 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m04:52:43.991967 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m04:52:43.992562 [debug] [Thread-5 (]: Began executing node model.mta.expense_type_per_year
[0m04:52:43.994243 [debug] [Thread-7 (]: Began executing node model.mta.labor_expenses_per_agency
[0m04:52:43.996244 [debug] [Thread-8 (]: Began executing node model.mta.largest_expense_differences_2023
[0m04:52:43.997293 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m04:52:44.000916 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.daily_ridership"
[0m04:52:44.001985 [debug] [Thread-10 ]: Began executing node model.mta.omny_adoption_increase
[0m04:52:44.003043 [debug] [Thread-6 (]: Began executing node model.mta.fare_class_boro
[0m04:52:44.003481 [debug] [Thread-9 (]: Began executing node model.mta.omny_adoption_by_station
[0m04:52:44.003891 [debug] [Thread-11 ]: Began executing node model.mta.subway_station_stats
[0m04:52:44.012119 [debug] [Thread-13 ]: Began executing node model.mta.weekly_riders_per_station
[0m04:52:44.012576 [debug] [Thread-12 ]: Began executing node model.mta.total_riders_per_station
[0m04:52:44.016813 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.expense_type_per_year"
[0m04:52:44.017884 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m04:52:44.023003 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.labor_expenses_per_agency"
[0m04:52:44.025825 [debug] [Thread-8 (]: Writing runtime sql for node "model.mta.largest_expense_differences_2023"
[0m04:52:44.026629 [debug] [Thread-2 (]: On model.mta.bond_payment_info: BEGIN
[0m04:52:44.031081 [debug] [Thread-10 ]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m04:52:44.031755 [debug] [Thread-1 (]: SQL status: OK in 0.040 seconds
[0m04:52:44.037202 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m04:52:44.037721 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m04:52:44.044818 [debug] [Thread-9 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m04:52:44.048817 [debug] [Thread-11 ]: Writing runtime sql for node "model.mta.subway_station_stats"
[0m04:52:44.056223 [debug] [Thread-13 ]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m04:52:44.059563 [debug] [Thread-12 ]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m04:52:44.060333 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: BEGIN
[0m04:52:44.061442 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m04:52:44.062839 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m04:52:44.063755 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m04:52:44.064283 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m04:52:44.064938 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m04:52:44.065511 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m04:52:44.066012 [debug] [Thread-4 (]: On model.mta.daily_ridership: BEGIN
[0m04:52:44.066481 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m04:52:44.067500 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m04:52:44.068476 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m04:52:44.069991 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: BEGIN
[0m04:52:44.070554 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m04:52:44.071026 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m04:52:44.071747 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m04:52:44.072286 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: BEGIN
[0m04:52:44.072859 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m04:52:44.073838 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: BEGIN
[0m04:52:44.074590 [debug] [Thread-2 (]: SQL status: OK in 0.013 seconds
[0m04:52:44.075014 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: BEGIN
[0m04:52:44.075567 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m04:52:44.076069 [debug] [Thread-6 (]: On model.mta.fare_class_boro: BEGIN
[0m04:52:44.076575 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m04:52:44.077320 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m04:52:44.077798 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: BEGIN
[0m04:52:44.078250 [debug] [Thread-11 ]: On model.mta.subway_station_stats: BEGIN
[0m04:52:44.078678 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: BEGIN
[0m04:52:44.079172 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m04:52:44.080894 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m04:52:44.081745 [debug] [Thread-3 (]: SQL status: OK in 0.013 seconds
[0m04:52:44.082452 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m04:52:44.082949 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m04:52:44.083869 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m04:52:44.084575 [debug] [Thread-9 (]: Opening a new connection, currently in state init
[0m04:52:44.085309 [debug] [Thread-12 ]: Opening a new connection, currently in state init
[0m04:52:44.086014 [debug] [Thread-11 ]: Opening a new connection, currently in state init
[0m04:52:44.086859 [debug] [Thread-13 ]: Opening a new connection, currently in state init
[0m04:52:44.087959 [debug] [Thread-4 (]: SQL status: OK in 0.012 seconds
[0m04:52:44.088477 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m04:52:44.089078 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */

  
    
    

    create  table
      "mtastats"."main"."bond_payment_info__dbt_tmp"
  
    as (
      WITH payment_stats AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        MAX(timestamp) AS last_payment_date,
        AVG(amount) AS average_payment,
        COUNT(DISTINCT timestamp) AS total_payments,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) AS median_payment
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
first_payment AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = fp.general_ledger AND timestamp = MIN(fp.timestamp)) AS first_payment_amount
    FROM
        mta_operations_statement fp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
last_payment AS (
    SELECT
        general_ledger,
        MAX(timestamp) AS last_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = lp.general_ledger AND timestamp = MAX(lp.timestamp)) AS last_payment_amount
    FROM
        mta_operations_statement lp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
)
-- Wrapping everything inside another DISTINCT query
SELECT DISTINCT
    ps.general_ledger,
    fp.first_payment_date,
    fp.first_payment_amount,
    ps.last_payment_date,
    lp.last_payment_amount,
    ps.average_payment,
    ps.median_payment,
    ps.total_payments
FROM
    payment_stats ps
LEFT JOIN
    first_payment fp ON ps.general_ledger = fp.general_ledger
LEFT JOIN
    last_payment lp ON ps.general_ledger = lp.general_ledger
ORDER BY
    ps.general_ledger
    );
  
  
[0m04:52:44.090854 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m04:52:44.091408 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "mtastats"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m04:52:44.094364 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */

  
    
    

    create  table
      "mtastats"."main"."daily_ridership__dbt_tmp"
  
    as (
      SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(subways_total_ridership) AS ridership,
    'subway' AS transport_type,
    AVG(subways_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(buses_total_ridership) AS ridership,
    'buses' AS transport_type,
    AVG(buses_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(lirr_total_ridership) AS ridership,
    'lirr' AS transport_type,
    AVG(lirr_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(metro_north_total_ridership) AS ridership,
    'metro_north' AS transport_type,
    AVG(metro_north_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(access_a_ride_total_trips) AS ridership,
    'access_a_ride' AS transport_type,
    AVG(access_a_ride_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(bridges_tunnels_total_traffic) AS ridership,
    'bridges_tunnels' AS transport_type,
    AVG(bridges_tunnels_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(staten_island_railway_total_ridership) AS ridership,
    'staten_island_railway' AS transport_type,
    AVG(staten_island_railway_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type
    );
  
  
[0m04:52:44.095166 [debug] [Thread-5 (]: SQL status: OK in 0.018 seconds
[0m04:52:44.096229 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m04:52:44.096627 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */

  
    
    

    create  table
      "mtastats"."main"."expense_type_per_year__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    general_ledger,
    SUM(amount) AS total_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    scenario = 'Actual'
    AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
GROUP BY 
    agency,
    fiscal_year,
    general_ledger
ORDER BY 
    agency, fiscal_year, general_ledger
    );
  
  
[0m04:52:44.098092 [debug] [Thread-7 (]: SQL status: OK in 0.019 seconds
[0m04:52:44.098474 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m04:52:44.098902 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */

  
    
    

    create  table
      "mtastats"."main"."labor_expenses_per_agency__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    expense_type,
    general_ledger,
    SUM(amount) AS total_labor_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    subtype = 'Labor Expenses' AND 
    scenario = 'Actual'
GROUP BY 
    agency,
    fiscal_year,
    expense_type,
    general_ledger
ORDER BY 
    agency, fiscal_year, expense_type, general_ledger
    );
  
  
[0m04:52:44.114780 [debug] [Thread-8 (]: SQL status: OK in 0.034 seconds
[0m04:52:44.115455 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m04:52:44.116023 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */

  
    
    

    create  table
      "mtastats"."main"."largest_expense_differences_2023__dbt_tmp"
  
    as (
      WITH expense_differences AS (
    SELECT
        agency,
        general_ledger,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) AS actual_expenses,
        SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS adopted_plan_expenses,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) - SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS difference
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        fiscal_year = 2023
        AND scenario IN ('Actual', 'Adopted Budget')
        AND financial_plan_year = 2023  -- Ensure we use only the 2023 Adopted Budget
        AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
        AND general_ledger != 'Reimbursable Overhead'  -- Exclude Reimbursable Overhead
    GROUP BY
        agency, general_ledger
),
ranked_expenses AS (
    SELECT
        agency,
        general_ledger,
        actual_expenses,
        adopted_plan_expenses,
        difference,
        ROW_NUMBER() OVER (PARTITION BY agency ORDER BY difference DESC) AS rank
    FROM
        expense_differences
    WHERE
        difference > 0  -- Only include cases where actual expenses are larger than the adopted budget
)
SELECT
    agency,
    general_ledger,
    actual_expenses,
    adopted_plan_expenses,
    difference
FROM
    ranked_expenses
WHERE
    rank <= 5  -- Select the top 5 items per agency
ORDER BY
    difference, rank
    );
  
  
[0m04:52:44.131341 [debug] [Thread-10 ]: SQL status: OK in 0.048 seconds
[0m04:52:44.132064 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m04:52:44.133033 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m04:52:44.142772 [debug] [Thread-6 (]: SQL status: OK in 0.059 seconds
[0m04:52:44.143273 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m04:52:44.143936 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m04:52:44.158512 [debug] [Thread-9 (]: SQL status: OK in 0.074 seconds
[0m04:52:44.159083 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m04:52:44.159589 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH yearly_data AS (
    SELECT 
        station_complex,
        YEAR(transit_timestamp) AS year,
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) * 1.0 / SUM(ridership) AS omny_percentage
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) IN (2022, 2023, 2024)
    GROUP BY 
        station_complex, 
        YEAR(transit_timestamp)
),
pivoted_data AS (
    SELECT 
        station_complex,
        MAX(CASE WHEN year = 2022 THEN omny_percentage ELSE NULL END) AS omny_2022,
        MAX(CASE WHEN year = 2023 THEN omny_percentage ELSE NULL END) AS omny_2023,
        MAX(CASE WHEN year = 2024 THEN omny_percentage ELSE NULL END) AS omny_2024
    FROM 
        yearly_data
    GROUP BY 
        station_complex
)
SELECT 
    station_complex,
    omny_2022,
    omny_2023,
    omny_2024,
    CASE 
        WHEN omny_2022 IS NOT NULL AND omny_2023 IS NOT NULL THEN 
            (omny_2023 - omny_2022) / omny_2022
        ELSE NULL
    END AS omny_2023_growth,
    CASE 
        WHEN omny_2023 IS NOT NULL AND omny_2024 IS NOT NULL THEN 
            (omny_2024 - omny_2023) / omny_2023
        ELSE NULL
    END AS omny_2024_growth
FROM 
    pivoted_data
ORDER BY 
    station_complex
    );
  
  
[0m04:52:44.173111 [debug] [Thread-12 ]: SQL status: OK in 0.088 seconds
[0m04:52:44.173901 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m04:52:44.174382 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m04:52:44.185761 [debug] [Thread-11 ]: SQL status: OK in 0.100 seconds
[0m04:52:44.186719 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m04:52:44.187792 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */

  
    
    

    create  table
      "mtastats"."main"."subway_station_stats__dbt_tmp"
  
    as (
      WITH ridership_by_day AS (
    SELECT 
        station_complex,
        CAST(transit_timestamp AS DATE) AS day,
        DAYOFWEEK(transit_timestamp) AS weekday,
        SUM(ridership) AS daily_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) = 2024
    GROUP BY 
        station_complex, 
        CAST(transit_timestamp AS DATE), 
        DAYOFWEEK(transit_timestamp)
),
weekday_weekend AS (
    SELECT 
        station_complex,
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END AS day_type,
        AVG(daily_ridership) AS avg_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex, 
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END
),
single_day_stats AS (
    SELECT 
        station_complex,
        MAX(daily_ridership) AS highest_single_day_ridership,
        MIN(daily_ridership) AS lowest_single_day_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex
),
highest_single_day AS (
    SELECT 
        station_complex,
        day AS highest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MAX(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
),
lowest_single_day AS (
    SELECT 
        station_complex,
        day AS lowest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MIN(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
)
SELECT 
    rbd.station_complex,
    MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS avg_weekday_ridership,
    MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) AS avg_weekend_ridership,
    sds.highest_single_day_ridership,
    hsd.highest_single_day_ridership_day,
    sds.lowest_single_day_ridership,
    lsd.lowest_single_day_ridership_day,
    (MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) - MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END)) * 1.0 / MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS weekend_percentage_change
FROM 
    ridership_by_day rbd
JOIN 
    weekday_weekend wwd ON rbd.station_complex = wwd.station_complex
JOIN 
    single_day_stats sds ON rbd.station_complex = sds.station_complex
JOIN 
    highest_single_day hsd ON rbd.station_complex = hsd.station_complex
JOIN 
    lowest_single_day lsd ON rbd.station_complex = lsd.station_complex
GROUP BY 
    rbd.station_complex, 
    sds.highest_single_day_ridership, 
    sds.lowest_single_day_ridership, 
    hsd.highest_single_day_ridership_day, 
    lsd.lowest_single_day_ridership_day
ORDER BY 
    rbd.station_complex
    );
  
  
[0m04:52:44.208024 [debug] [Thread-13 ]: SQL status: OK in 0.121 seconds
[0m04:52:44.208739 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m04:52:44.209307 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      with weekly_ridership AS (
    SELECT 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_start,
        SUM(ridership) AS total_weekly_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp)
)
SELECT 
    station_complex, 
    week_start, 
    total_weekly_ridership
FROM 
    weekly_ridership
ORDER BY 
    station_complex, 
    week_start
    );
  
  
[0m04:52:44.734598 [debug] [Thread-5 (]: SQL status: OK in 0.637 seconds
[0m04:52:44.768007 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m04:52:44.768898 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
alter table "mtastats"."main"."expense_type_per_year__dbt_tmp" rename to "expense_type_per_year"
[0m04:52:44.773955 [debug] [Thread-5 (]: SQL status: OK in 0.004 seconds
[0m04:52:44.995252 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m04:52:44.996160 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m04:52:44.996928 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m04:52:44.998461 [debug] [Thread-7 (]: SQL status: OK in 0.899 seconds
[0m04:52:45.002522 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m04:52:45.003136 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
alter table "mtastats"."main"."labor_expenses_per_agency__dbt_tmp" rename to "labor_expenses_per_agency"
[0m04:52:45.004213 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m04:52:45.007974 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m04:52:45.009741 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m04:52:45.016492 [debug] [Thread-5 (]: SQL status: OK in 0.019 seconds
[0m04:52:45.017057 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m04:52:45.067925 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m04:52:45.068950 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
drop table if exists "mtastats"."main"."expense_type_per_year__dbt_backup" cascade
[0m04:52:45.075195 [debug] [Thread-7 (]: SQL status: OK in 0.032 seconds
[0m04:52:45.090172 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m04:52:45.092073 [debug] [Thread-5 (]: SQL status: OK in 0.019 seconds
[0m04:52:45.092981 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
drop table if exists "mtastats"."main"."labor_expenses_per_agency__dbt_backup" cascade
[0m04:52:45.190172 [debug] [Thread-4 (]: SQL status: OK in 1.094 seconds
[0m04:52:45.191471 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: Close
[0m04:52:45.199738 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19b06b550>]}
[0m04:52:45.200721 [info ] [Thread-5 (]: 5 of 13 OK created sql table model main.expense_type_per_year .................. [[32mOK[0m in 1.37s]
[0m04:52:45.202752 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m04:52:45.203378 [debug] [Thread-7 (]: SQL status: OK in 0.014 seconds
[0m04:52:45.204816 [debug] [Thread-5 (]: Finished running node model.mta.expense_type_per_year
[0m04:52:45.205555 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
alter table "mtastats"."main"."daily_ridership__dbt_tmp" rename to "daily_ridership"
[0m04:52:45.207326 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: Close
[0m04:52:45.209442 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d3b8b20>]}
[0m04:52:45.210803 [info ] [Thread-7 (]: 7 of 13 OK created sql table model main.labor_expenses_per_agency .............. [[32mOK[0m in 1.38s]
[0m04:52:45.212018 [debug] [Thread-7 (]: Finished running node model.mta.labor_expenses_per_agency
[0m04:52:45.212987 [debug] [Thread-4 (]: SQL status: OK in 0.004 seconds
[0m04:52:45.218334 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m04:52:45.219037 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m04:52:45.219461 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m04:52:45.240386 [debug] [Thread-4 (]: SQL status: OK in 0.019 seconds
[0m04:52:45.245097 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m04:52:45.245923 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
drop table if exists "mtastats"."main"."daily_ridership__dbt_backup" cascade
[0m04:52:45.248193 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m04:52:45.250286 [debug] [Thread-4 (]: On model.mta.daily_ridership: Close
[0m04:52:45.251118 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d5b4ac0>]}
[0m04:52:45.251866 [info ] [Thread-4 (]: 4 of 13 OK created sql table model main.daily_ridership ........................ [[32mOK[0m in 1.43s]
[0m04:52:45.252761 [debug] [Thread-4 (]: Finished running node model.mta.daily_ridership
[0m04:52:45.310290 [debug] [Thread-8 (]: SQL status: OK in 1.192 seconds
[0m04:52:45.318787 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m04:52:45.319928 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
alter table "mtastats"."main"."largest_expense_differences_2023__dbt_tmp" rename to "largest_expense_differences_2023"
[0m04:52:45.322497 [debug] [Thread-8 (]: SQL status: OK in 0.002 seconds
[0m04:52:45.329216 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m04:52:45.330794 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m04:52:45.331433 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m04:52:45.336364 [debug] [Thread-8 (]: SQL status: OK in 0.004 seconds
[0m04:52:45.342232 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m04:52:45.343413 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
drop table if exists "mtastats"."main"."largest_expense_differences_2023__dbt_backup" cascade
[0m04:52:45.347935 [debug] [Thread-8 (]: SQL status: OK in 0.004 seconds
[0m04:52:45.351418 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: Close
[0m04:52:45.352935 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d462f20>]}
[0m04:52:45.354424 [info ] [Thread-8 (]: 8 of 13 OK created sql table model main.largest_expense_differences_2023 ....... [[32mOK[0m in 1.51s]
[0m04:52:45.355158 [debug] [Thread-8 (]: Finished running node model.mta.largest_expense_differences_2023
[0m04:52:45.868373 [debug] [Thread-2 (]: SQL status: OK in 1.776 seconds
[0m04:52:45.912886 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m04:52:45.913944 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
alter table "mtastats"."main"."bond_payment_info__dbt_tmp" rename to "bond_payment_info"
[0m04:52:45.915168 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m04:52:45.918892 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m04:52:45.919888 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m04:52:45.920511 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m04:52:45.927012 [debug] [Thread-2 (]: SQL status: OK in 0.006 seconds
[0m04:52:45.964485 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m04:52:45.966123 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
drop table if exists "mtastats"."main"."bond_payment_info__dbt_backup" cascade
[0m04:52:45.968003 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m04:52:45.971932 [debug] [Thread-2 (]: On model.mta.bond_payment_info: Close
[0m04:52:45.973992 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d463f10>]}
[0m04:52:45.980716 [info ] [Thread-2 (]: 2 of 13 OK created sql table model main.bond_payment_info ...................... [[32mOK[0m in 2.20s]
[0m04:52:45.985552 [debug] [Thread-2 (]: Finished running node model.mta.bond_payment_info
[0m04:52:50.069046 [debug] [Thread-1 (]: SQL status: OK in 5.979 seconds
[0m04:52:50.228307 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m04:52:50.240776 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "mtastats"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m04:52:50.256652 [debug] [Thread-1 (]: SQL status: OK in 0.012 seconds
[0m04:52:50.283742 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m04:52:50.284785 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m04:52:50.285538 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m04:52:50.334279 [debug] [Thread-1 (]: SQL status: OK in 0.048 seconds
[0m04:52:50.339850 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m04:52:50.340780 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "mtastats"."main"."avg_riders_per_day__dbt_backup" cascade
[0m04:52:50.342312 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m04:52:50.347169 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m04:52:50.368932 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e14ebc0>]}
[0m04:52:50.399869 [info ] [Thread-1 (]: 1 of 13 OK created sql table model main.avg_riders_per_day ..................... [[32mOK[0m in 6.61s]
[0m04:52:50.431793 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m04:52:51.328598 [debug] [Thread-3 (]: SQL status: OK in 7.232 seconds
[0m04:52:51.371586 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m04:52:51.372763 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "mtastats"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m04:52:51.390786 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m04:52:51.394264 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m04:52:51.395239 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m04:52:51.396064 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m04:52:51.407243 [debug] [Thread-3 (]: SQL status: OK in 0.006 seconds
[0m04:52:51.414537 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m04:52:51.415682 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "mtastats"."main"."busiest_specific_times__dbt_backup" cascade
[0m04:52:51.417245 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m04:52:51.443568 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: Close
[0m04:52:51.460574 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e174f10>]}
[0m04:52:51.462422 [info ] [Thread-3 (]: 3 of 13 OK created sql table model main.busiest_specific_times ................. [[32mOK[0m in 7.68s]
[0m04:52:51.464574 [debug] [Thread-3 (]: Finished running node model.mta.busiest_specific_times
[0m04:52:53.410021 [debug] [Thread-13 ]: SQL status: OK in 9.200 seconds
[0m04:52:53.424260 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m04:52:53.425225 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "mtastats"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m04:52:53.428177 [debug] [Thread-13 ]: SQL status: OK in 0.001 seconds
[0m04:52:53.431736 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m04:52:53.444890 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m04:52:53.452447 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m04:52:53.474991 [debug] [Thread-6 (]: SQL status: OK in 9.330 seconds
[0m04:52:53.485907 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m04:52:53.494678 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "mtastats"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m04:52:53.496280 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m04:52:53.499293 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m04:52:53.500389 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m04:52:53.502786 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m04:52:53.501184 [debug] [Thread-13 ]: SQL status: OK in 0.047 seconds
[0m04:52:53.508964 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m04:52:53.520440 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "mtastats"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m04:52:53.521828 [debug] [Thread-13 ]: SQL status: OK in 0.000 seconds
[0m04:52:53.524782 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: Close
[0m04:52:53.526713 [debug] [Thread-13 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d46cee0>]}
[0m04:52:53.528422 [info ] [Thread-13 ]: 13 of 13 OK created sql table model main.weekly_riders_per_station ............. [[32mOK[0m in 9.61s]
[0m04:52:53.529815 [debug] [Thread-13 ]: Finished running node model.mta.weekly_riders_per_station
[0m04:52:53.550574 [debug] [Thread-6 (]: SQL status: OK in 0.046 seconds
[0m04:52:53.557028 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m04:52:53.558033 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "mtastats"."main"."fare_class_boro__dbt_backup" cascade
[0m04:52:53.559403 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m04:52:53.562462 [debug] [Thread-6 (]: On model.mta.fare_class_boro: Close
[0m04:52:53.569853 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d463670>]}
[0m04:52:53.571377 [info ] [Thread-6 (]: 6 of 13 OK created sql table model main.fare_class_boro ........................ [[32mOK[0m in 9.74s]
[0m04:52:53.572949 [debug] [Thread-6 (]: Finished running node model.mta.fare_class_boro
[0m04:52:54.570705 [debug] [Thread-10 ]: SQL status: OK in 10.437 seconds
[0m04:52:54.581235 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m04:52:54.582511 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "mtastats"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m04:52:54.595639 [debug] [Thread-10 ]: SQL status: OK in 0.001 seconds
[0m04:52:54.602697 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: COMMIT
[0m04:52:54.603555 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m04:52:54.604171 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: COMMIT
[0m04:52:54.632859 [debug] [Thread-10 ]: SQL status: OK in 0.028 seconds
[0m04:52:54.643208 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m04:52:54.644123 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "mtastats"."main"."omny_adoption_increase__dbt_backup" cascade
[0m04:52:54.645406 [debug] [Thread-10 ]: SQL status: OK in 0.000 seconds
[0m04:52:54.647838 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: Close
[0m04:52:54.648814 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d46c370>]}
[0m04:52:54.649945 [info ] [Thread-10 ]: 10 of 13 OK created sql table model main.omny_adoption_increase ................ [[32mOK[0m in 10.81s]
[0m04:52:54.652881 [debug] [Thread-10 ]: Finished running node model.mta.omny_adoption_increase
[0m04:52:54.722182 [debug] [Thread-9 (]: SQL status: OK in 10.562 seconds
[0m04:52:54.741061 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m04:52:54.741984 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "mtastats"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m04:52:54.743383 [debug] [Thread-9 (]: SQL status: OK in 0.001 seconds
[0m04:52:54.746450 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m04:52:54.747266 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m04:52:54.747906 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m04:52:54.779558 [debug] [Thread-9 (]: SQL status: OK in 0.031 seconds
[0m04:52:54.786351 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m04:52:54.787345 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "mtastats"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m04:52:54.788621 [debug] [Thread-9 (]: SQL status: OK in 0.001 seconds
[0m04:52:54.792908 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: Close
[0m04:52:54.794464 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd131902770>]}
[0m04:52:54.795706 [info ] [Thread-9 (]: 9 of 13 OK created sql table model main.omny_adoption_by_station ............... [[32mOK[0m in 10.95s]
[0m04:52:54.796989 [debug] [Thread-9 (]: Finished running node model.mta.omny_adoption_by_station
[0m04:52:55.224802 [debug] [Thread-12 ]: SQL status: OK in 11.050 seconds
[0m04:52:55.231001 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m04:52:55.231972 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "mtastats"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m04:52:55.233442 [debug] [Thread-12 ]: SQL status: OK in 0.001 seconds
[0m04:52:55.236624 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: COMMIT
[0m04:52:55.237373 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m04:52:55.238195 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: COMMIT
[0m04:52:55.244275 [debug] [Thread-12 ]: SQL status: OK in 0.005 seconds
[0m04:52:55.249245 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m04:52:55.250373 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "mtastats"."main"."total_riders_per_station__dbt_backup" cascade
[0m04:52:55.251864 [debug] [Thread-12 ]: SQL status: OK in 0.000 seconds
[0m04:52:55.255679 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: Close
[0m04:52:55.257243 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d46cdf0>]}
[0m04:52:55.260277 [info ] [Thread-12 ]: 12 of 13 OK created sql table model main.total_riders_per_station .............. [[32mOK[0m in 11.34s]
[0m04:52:55.262618 [debug] [Thread-12 ]: Finished running node model.mta.total_riders_per_station
[0m04:52:57.795180 [debug] [Thread-11 ]: SQL status: OK in 13.606 seconds
[0m04:52:57.798521 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m04:52:57.798937 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
alter table "mtastats"."main"."subway_station_stats__dbt_tmp" rename to "subway_station_stats"
[0m04:52:57.799992 [debug] [Thread-11 ]: SQL status: OK in 0.001 seconds
[0m04:52:57.801558 [debug] [Thread-11 ]: On model.mta.subway_station_stats: COMMIT
[0m04:52:57.801917 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m04:52:57.802247 [debug] [Thread-11 ]: On model.mta.subway_station_stats: COMMIT
[0m04:52:57.807876 [debug] [Thread-11 ]: SQL status: OK in 0.005 seconds
[0m04:52:57.810263 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m04:52:57.810668 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
drop table if exists "mtastats"."main"."subway_station_stats__dbt_backup" cascade
[0m04:52:57.811450 [debug] [Thread-11 ]: SQL status: OK in 0.000 seconds
[0m04:52:57.812914 [debug] [Thread-11 ]: On model.mta.subway_station_stats: Close
[0m04:52:57.928091 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b76fbfd5-4ea6-493c-aedd-11146832e425', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18d46cb80>]}
[0m04:52:57.929022 [info ] [Thread-11 ]: 11 of 13 OK created sql table model main.subway_station_stats .................. [[32mOK[0m in 14.02s]
[0m04:52:57.929686 [debug] [Thread-11 ]: Finished running node model.mta.subway_station_stats
[0m04:52:57.941238 [debug] [MainThread]: Using duckdb connection "master"
[0m04:52:57.941854 [debug] [MainThread]: On master: BEGIN
[0m04:52:57.942349 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:52:57.967797 [debug] [MainThread]: SQL status: OK in 0.025 seconds
[0m04:52:57.968817 [debug] [MainThread]: On master: COMMIT
[0m04:52:57.969175 [debug] [MainThread]: Using duckdb connection "master"
[0m04:52:57.969420 [debug] [MainThread]: On master: COMMIT
[0m04:52:57.970255 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m04:52:57.970564 [debug] [MainThread]: On master: Close
[0m04:52:57.973232 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:52:57.973522 [debug] [MainThread]: Connection 'model.mta.expense_type_per_year' was properly closed.
[0m04:52:57.973780 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m04:52:57.974003 [debug] [MainThread]: Connection 'model.mta.bond_payment_info' was properly closed.
[0m04:52:57.974276 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m04:52:57.974495 [debug] [MainThread]: Connection 'model.mta.daily_ridership' was properly closed.
[0m04:52:57.974698 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m04:52:57.974983 [debug] [MainThread]: Connection 'model.mta.labor_expenses_per_agency' was properly closed.
[0m04:52:57.975181 [debug] [MainThread]: Connection 'model.mta.largest_expense_differences_2023' was properly closed.
[0m04:52:57.975379 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m04:52:57.975576 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m04:52:57.975761 [debug] [MainThread]: Connection 'model.mta.subway_station_stats' was properly closed.
[0m04:52:57.975946 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m04:52:57.976132 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m04:52:57.977361 [info ] [MainThread]: 
[0m04:52:57.978062 [info ] [MainThread]: Finished running 13 table models in 0 hours 0 minutes and 14.48 seconds (14.48s).
[0m04:52:57.980673 [debug] [MainThread]: Command end result
[0m04:52:58.052593 [info ] [MainThread]: 
[0m04:52:58.054286 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:52:58.054795 [info ] [MainThread]: 
[0m04:52:58.055592 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 TOTAL=13
[0m04:52:58.062967 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.208805, "process_user_time": 141.3524, "process_kernel_time": 30.339373, "process_mem_max_rss": "678484", "process_in_blocks": "59120", "process_out_blocks": "15456"}
[0m04:52:58.065413 [debug] [MainThread]: Command `dbt run` succeeded at 04:52:58.065215 after 15.21 seconds
[0m04:52:58.066815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd19afdf430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e167760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd18e35ecb0>]}
[0m04:52:58.067344 [debug] [MainThread]: Flushing usage events
[0m05:04:24.178463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc44a434c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc430ee5c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc430ee6e0>]}


============================== 05:04:24.181989 | f38d9ea3-389d-4346-8e92-11abcec2b402 ==============================
[0m05:04:24.181989 [info ] [MainThread]: Running with dbt=1.8.7
[0m05:04:24.182524 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:04:24.393875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc4303fc40>]}
[0m05:04:24.448819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc430226b0>]}
[0m05:04:24.451849 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m05:04:24.459951 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m05:04:24.546360 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:04:24.546866 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:04:24.577368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc43094970>]}
[0m05:04:24.663573 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc431f1b40>]}
[0m05:04:24.664142 [info ] [MainThread]: Found 13 models, 9 sources, 416 macros
[0m05:04:24.664532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc431f3820>]}
[0m05:04:24.666170 [info ] [MainThread]: 
[0m05:04:24.666767 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m05:04:24.671176 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_mtastats'
[0m05:04:24.737632 [debug] [ThreadPool]: Using duckdb connection "list_mtastats"
[0m05:04:24.738548 [debug] [ThreadPool]: On list_mtastats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"mtastats"'
    
  
  
[0m05:04:24.738942 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:04:24.763394 [debug] [ThreadPool]: SQL status: OK in 0.024 seconds
[0m05:04:24.764629 [debug] [ThreadPool]: On list_mtastats: Close
[0m05:04:24.767587 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mtastats, now create_mtastats_main)
[0m05:04:24.768298 [debug] [ThreadPool]: Creating schema "database: "mtastats"
schema: "main"
"
[0m05:04:24.773551 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:04:24.773870 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
        select type from duckdb_databases()
        where database_name='mtastats'
        and type='sqlite'
    
  
[0m05:04:24.774148 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:04:24.781704 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m05:04:24.782866 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:04:24.783166 [debug] [ThreadPool]: On create_mtastats_main: BEGIN
[0m05:04:24.783635 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:04:24.783902 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:04:24.784125 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
    
        create schema if not exists "mtastats"."main"
    
[0m05:04:24.784832 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:04:24.785495 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m05:04:24.785745 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:04:24.785996 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m05:04:24.786439 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:04:24.786727 [debug] [ThreadPool]: On create_mtastats_main: Close
[0m05:04:24.792764 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_mtastats_main, now list_mtastats_main)
[0m05:04:24.798184 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m05:04:24.798871 [debug] [ThreadPool]: On list_mtastats_main: BEGIN
[0m05:04:24.799267 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:04:24.807445 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m05:04:24.808022 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m05:04:24.808375 [debug] [ThreadPool]: On list_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats_main"} */
select
      'mtastats' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'mtastats'
  
[0m05:04:24.827072 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m05:04:24.828951 [debug] [ThreadPool]: On list_mtastats_main: ROLLBACK
[0m05:04:24.831590 [debug] [ThreadPool]: Failed to rollback 'list_mtastats_main'
[0m05:04:24.831974 [debug] [ThreadPool]: On list_mtastats_main: Close
[0m05:04:24.838338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc43138f10>]}
[0m05:04:24.838893 [debug] [MainThread]: Using duckdb connection "master"
[0m05:04:24.839207 [debug] [MainThread]: On master: BEGIN
[0m05:04:24.839465 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:04:24.855890 [debug] [MainThread]: SQL status: OK in 0.016 seconds
[0m05:04:24.856366 [debug] [MainThread]: On master: COMMIT
[0m05:04:24.856650 [debug] [MainThread]: Using duckdb connection "master"
[0m05:04:24.856883 [debug] [MainThread]: On master: COMMIT
[0m05:04:24.857330 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m05:04:24.857626 [debug] [MainThread]: On master: Close
[0m05:04:24.859423 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m05:04:24.859833 [info ] [MainThread]: 
[0m05:04:24.868405 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m05:04:24.869102 [debug] [Thread-2 (]: Began running node model.mta.bond_payment_info
[0m05:04:24.869988 [info ] [Thread-1 (]: 1 of 13 START sql table model main.avg_riders_per_day .......................... [RUN]
[0m05:04:24.870756 [info ] [Thread-2 (]: 2 of 13 START sql table model main.bond_payment_info ........................... [RUN]
[0m05:04:24.871925 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m05:04:24.872504 [debug] [Thread-3 (]: Began running node model.mta.busiest_specific_times
[0m05:04:24.873118 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.bond_payment_info'
[0m05:04:24.873631 [debug] [Thread-4 (]: Began running node model.mta.daily_ridership
[0m05:04:24.874207 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m05:04:24.874692 [debug] [Thread-5 (]: Began running node model.mta.expense_type_per_year
[0m05:04:24.875250 [debug] [Thread-6 (]: Began running node model.mta.fare_class_boro
[0m05:04:24.876192 [debug] [Thread-7 (]: Began running node model.mta.labor_expenses_per_agency
[0m05:04:24.877045 [debug] [Thread-8 (]: Began running node model.mta.largest_expense_differences_2023
[0m05:04:24.877498 [debug] [Thread-2 (]: Began compiling node model.mta.bond_payment_info
[0m05:04:24.875814 [info ] [Thread-3 (]: 3 of 13 START sql table model main.busiest_specific_times ...................... [RUN]
[0m05:04:24.878079 [debug] [Thread-9 (]: Began running node model.mta.omny_adoption_by_station
[0m05:04:24.878701 [debug] [Thread-10 ]: Began running node model.mta.omny_adoption_increase
[0m05:04:24.879929 [debug] [Thread-11 ]: Began running node model.mta.subway_station_stats
[0m05:04:24.881182 [debug] [Thread-12 ]: Began running node model.mta.total_riders_per_station
[0m05:04:24.888999 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m05:04:24.890085 [debug] [Thread-13 ]: Began running node model.mta.weekly_riders_per_station
[0m05:04:24.879407 [info ] [Thread-4 (]: 4 of 13 START sql table model main.daily_ridership ............................. [RUN]
[0m05:04:24.893748 [info ] [Thread-5 (]: 5 of 13 START sql table model main.expense_type_per_year ....................... [RUN]
[0m05:04:24.895312 [info ] [Thread-6 (]: 6 of 13 START sql table model main.fare_class_boro ............................. [RUN]
[0m05:04:24.896171 [info ] [Thread-7 (]: 7 of 13 START sql table model main.labor_expenses_per_agency ................... [RUN]
[0m05:04:24.896984 [info ] [Thread-8 (]: 8 of 13 START sql table model main.largest_expense_differences_2023 ............ [RUN]
[0m05:04:24.901283 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.bond_payment_info"
[0m05:04:24.902486 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m05:04:24.903664 [info ] [Thread-9 (]: 9 of 13 START sql table model main.omny_adoption_by_station .................... [RUN]
[0m05:04:24.905118 [info ] [Thread-10 ]: 10 of 13 START sql table model main.omny_adoption_increase ..................... [RUN]
[0m05:04:24.906514 [info ] [Thread-11 ]: 11 of 13 START sql table model main.subway_station_stats ....................... [RUN]
[0m05:04:24.907386 [info ] [Thread-12 ]: 12 of 13 START sql table model main.total_riders_per_station ................... [RUN]
[0m05:04:24.908467 [info ] [Thread-13 ]: 13 of 13 START sql table model main.weekly_riders_per_station .................. [RUN]
[0m05:04:24.909501 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.daily_ridership'
[0m05:04:24.910335 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_mtastats_main, now model.mta.expense_type_per_year)
[0m05:04:24.910875 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m05:04:24.911713 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m05:04:24.912371 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.labor_expenses_per_agency'
[0m05:04:24.912891 [debug] [Thread-8 (]: Acquiring new duckdb connection 'model.mta.largest_expense_differences_2023'
[0m05:04:24.913886 [debug] [Thread-3 (]: Began compiling node model.mta.busiest_specific_times
[0m05:04:24.914552 [debug] [Thread-9 (]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m05:04:24.915324 [debug] [Thread-10 ]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m05:04:24.915984 [debug] [Thread-11 ]: Acquiring new duckdb connection 'model.mta.subway_station_stats'
[0m05:04:24.916574 [debug] [Thread-2 (]: Began executing node model.mta.bond_payment_info
[0m05:04:24.917275 [debug] [Thread-12 ]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m05:04:24.918086 [debug] [Thread-13 ]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m05:04:24.918725 [debug] [Thread-4 (]: Began compiling node model.mta.daily_ridership
[0m05:04:24.919424 [debug] [Thread-5 (]: Began compiling node model.mta.expense_type_per_year
[0m05:04:24.932402 [debug] [Thread-6 (]: Began compiling node model.mta.fare_class_boro
[0m05:04:24.950152 [debug] [Thread-7 (]: Began compiling node model.mta.labor_expenses_per_agency
[0m05:04:24.951495 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m05:04:24.952359 [debug] [Thread-8 (]: Began compiling node model.mta.largest_expense_differences_2023
[0m05:04:25.013490 [debug] [Thread-9 (]: Began compiling node model.mta.omny_adoption_by_station
[0m05:04:25.015859 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m05:04:25.016458 [debug] [Thread-10 ]: Began compiling node model.mta.omny_adoption_increase
[0m05:04:25.016963 [debug] [Thread-11 ]: Began compiling node model.mta.subway_station_stats
[0m05:04:25.019794 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.bond_payment_info"
[0m05:04:25.020321 [debug] [Thread-12 ]: Began compiling node model.mta.total_riders_per_station
[0m05:04:25.020815 [debug] [Thread-13 ]: Began compiling node model.mta.weekly_riders_per_station
[0m05:04:25.024780 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.daily_ridership"
[0m05:04:25.028277 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.expense_type_per_year"
[0m05:04:25.033229 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m05:04:25.035788 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.labor_expenses_per_agency"
[0m05:04:25.038917 [debug] [Thread-8 (]: Writing injected SQL for node "model.mta.largest_expense_differences_2023"
[0m05:04:25.041961 [debug] [Thread-9 (]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m05:04:25.042519 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:04:25.046859 [debug] [Thread-10 ]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m05:04:25.047377 [debug] [Thread-3 (]: Began executing node model.mta.busiest_specific_times
[0m05:04:25.050119 [debug] [Thread-11 ]: Writing injected SQL for node "model.mta.subway_station_stats"
[0m05:04:25.052788 [debug] [Thread-12 ]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m05:04:25.055394 [debug] [Thread-13 ]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m05:04:25.055969 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:04:25.058140 [debug] [Thread-6 (]: Began executing node model.mta.fare_class_boro
[0m05:04:25.058673 [debug] [Thread-4 (]: Began executing node model.mta.daily_ridership
[0m05:04:25.059483 [debug] [Thread-5 (]: Began executing node model.mta.expense_type_per_year
[0m05:04:25.060001 [debug] [Thread-7 (]: Began executing node model.mta.labor_expenses_per_agency
[0m05:04:25.060793 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m05:04:25.062282 [debug] [Thread-8 (]: Began executing node model.mta.largest_expense_differences_2023
[0m05:04:25.063097 [debug] [Thread-9 (]: Began executing node model.mta.omny_adoption_by_station
[0m05:04:25.066738 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m05:04:25.067283 [debug] [Thread-10 ]: Began executing node model.mta.omny_adoption_increase
[0m05:04:25.068219 [debug] [Thread-11 ]: Began executing node model.mta.subway_station_stats
[0m05:04:25.069462 [debug] [Thread-2 (]: On model.mta.bond_payment_info: BEGIN
[0m05:04:25.070035 [debug] [Thread-12 ]: Began executing node model.mta.total_riders_per_station
[0m05:04:25.073522 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m05:04:25.074074 [debug] [Thread-13 ]: Began executing node model.mta.weekly_riders_per_station
[0m05:04:25.077756 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.daily_ridership"
[0m05:04:25.083724 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.expense_type_per_year"
[0m05:04:25.087570 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.labor_expenses_per_agency"
[0m05:04:25.088287 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m05:04:25.091555 [debug] [Thread-8 (]: Writing runtime sql for node "model.mta.largest_expense_differences_2023"
[0m05:04:25.095790 [debug] [Thread-9 (]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m05:04:25.096937 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:04:25.100296 [debug] [Thread-10 ]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m05:04:25.103664 [debug] [Thread-11 ]: Writing runtime sql for node "model.mta.subway_station_stats"
[0m05:04:25.104275 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m05:04:25.108319 [debug] [Thread-12 ]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m05:04:25.111976 [debug] [Thread-13 ]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m05:04:25.112811 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:04:25.113496 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:04:25.113981 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:04:25.123810 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:04:25.124552 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:04:25.125403 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: BEGIN
[0m05:04:25.126094 [debug] [Thread-1 (]: SQL status: OK in 0.038 seconds
[0m05:04:25.126738 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:04:25.127771 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:04:25.128910 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:04:25.130237 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:04:25.130857 [debug] [Thread-4 (]: On model.mta.daily_ridership: BEGIN
[0m05:04:25.131393 [debug] [Thread-6 (]: On model.mta.fare_class_boro: BEGIN
[0m05:04:25.132159 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: BEGIN
[0m05:04:25.132694 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:04:25.133413 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: BEGIN
[0m05:04:25.134013 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: BEGIN
[0m05:04:25.134452 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m05:04:25.135117 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:04:25.135778 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: BEGIN
[0m05:04:25.136540 [debug] [Thread-11 ]: On model.mta.subway_station_stats: BEGIN
[0m05:04:25.137320 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: BEGIN
[0m05:04:25.138051 [debug] [Thread-2 (]: SQL status: OK in 0.034 seconds
[0m05:04:25.138922 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: BEGIN
[0m05:04:25.139405 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m05:04:25.140111 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m05:04:25.140798 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m05:04:25.141471 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: BEGIN
[0m05:04:25.141957 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m05:04:25.142584 [debug] [Thread-9 (]: Opening a new connection, currently in state init
[0m05:04:25.143743 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m05:04:25.144323 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m05:04:25.144798 [debug] [Thread-11 ]: Opening a new connection, currently in state init
[0m05:04:25.145403 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m05:04:25.146053 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:04:25.146653 [debug] [Thread-12 ]: Opening a new connection, currently in state init
[0m05:04:25.148592 [debug] [Thread-13 ]: Opening a new connection, currently in state init
[0m05:04:25.149064 [debug] [Thread-3 (]: SQL status: OK in 0.015 seconds
[0m05:04:25.150807 [debug] [Thread-4 (]: SQL status: OK in 0.011 seconds
[0m05:04:25.155076 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */

  
    
    

    create  table
      "mtastats"."main"."bond_payment_info__dbt_tmp"
  
    as (
      WITH payment_stats AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        MAX(timestamp) AS last_payment_date,
        AVG(amount) AS average_payment,
        COUNT(DISTINCT timestamp) AS total_payments,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) AS median_payment
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
first_payment AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = fp.general_ledger AND timestamp = MIN(fp.timestamp)) AS first_payment_amount
    FROM
        mta_operations_statement fp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
last_payment AS (
    SELECT
        general_ledger,
        MAX(timestamp) AS last_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = lp.general_ledger AND timestamp = MAX(lp.timestamp)) AS last_payment_amount
    FROM
        mta_operations_statement lp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
)
-- Wrapping everything inside another DISTINCT query
SELECT DISTINCT
    ps.general_ledger,
    fp.first_payment_date,
    fp.first_payment_amount,
    ps.last_payment_date,
    lp.last_payment_amount,
    ps.average_payment,
    ps.median_payment,
    ps.total_payments
FROM
    payment_stats ps
LEFT JOIN
    first_payment fp ON ps.general_ledger = fp.general_ledger
LEFT JOIN
    last_payment lp ON ps.general_ledger = lp.general_ledger
ORDER BY
    ps.general_ledger
    );
  
  
[0m05:04:25.155655 [debug] [Thread-6 (]: SQL status: OK in 0.015 seconds
[0m05:04:25.156798 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:04:25.157317 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:04:25.161558 [debug] [Thread-5 (]: SQL status: OK in 0.021 seconds
[0m05:04:25.162372 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:04:25.163368 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "mtastats"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m05:04:25.164217 [debug] [Thread-7 (]: SQL status: OK in 0.022 seconds
[0m05:04:25.164870 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */

  
    
    

    create  table
      "mtastats"."main"."daily_ridership__dbt_tmp"
  
    as (
      SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(subways_total_ridership) AS ridership,
    'subway' AS transport_type,
    AVG(subways_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(buses_total_ridership) AS ridership,
    'buses' AS transport_type,
    AVG(buses_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(lirr_total_ridership) AS ridership,
    'lirr' AS transport_type,
    AVG(lirr_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(metro_north_total_ridership) AS ridership,
    'metro_north' AS transport_type,
    AVG(metro_north_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(access_a_ride_total_trips) AS ridership,
    'access_a_ride' AS transport_type,
    AVG(access_a_ride_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(bridges_tunnels_total_traffic) AS ridership,
    'bridges_tunnels' AS transport_type,
    AVG(bridges_tunnels_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(staten_island_railway_total_ridership) AS ridership,
    'staten_island_railway' AS transport_type,
    AVG(staten_island_railway_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type
    );
  
  
[0m05:04:25.165497 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:04:25.166137 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m05:04:25.168233 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:04:25.169282 [debug] [Thread-9 (]: SQL status: OK in 0.027 seconds
[0m05:04:25.174134 [debug] [Thread-8 (]: SQL status: OK in 0.030 seconds
[0m05:04:25.174806 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */

  
    
    

    create  table
      "mtastats"."main"."expense_type_per_year__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    general_ledger,
    SUM(amount) AS total_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    scenario = 'Actual'
    AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
GROUP BY 
    agency,
    fiscal_year,
    general_ledger
ORDER BY 
    agency, fiscal_year, general_ledger
    );
  
  
[0m05:04:25.176806 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */

  
    
    

    create  table
      "mtastats"."main"."labor_expenses_per_agency__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    expense_type,
    general_ledger,
    SUM(amount) AS total_labor_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    subtype = 'Labor Expenses' AND 
    scenario = 'Actual'
GROUP BY 
    agency,
    fiscal_year,
    expense_type,
    general_ledger
ORDER BY 
    agency, fiscal_year, expense_type, general_ledger
    );
  
  
[0m05:04:25.177438 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:04:25.178398 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:04:25.179965 [debug] [Thread-11 ]: SQL status: OK in 0.035 seconds
[0m05:04:25.181740 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH yearly_data AS (
    SELECT 
        station_complex,
        YEAR(transit_timestamp) AS year,
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) * 1.0 / SUM(ridership) AS omny_percentage
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) IN (2022, 2023, 2024)
    GROUP BY 
        station_complex, 
        YEAR(transit_timestamp)
),
pivoted_data AS (
    SELECT 
        station_complex,
        MAX(CASE WHEN year = 2022 THEN omny_percentage ELSE NULL END) AS omny_2022,
        MAX(CASE WHEN year = 2023 THEN omny_percentage ELSE NULL END) AS omny_2023,
        MAX(CASE WHEN year = 2024 THEN omny_percentage ELSE NULL END) AS omny_2024
    FROM 
        yearly_data
    GROUP BY 
        station_complex
)
SELECT 
    station_complex,
    omny_2022,
    omny_2023,
    omny_2024,
    CASE 
        WHEN omny_2022 IS NOT NULL AND omny_2023 IS NOT NULL THEN 
            (omny_2023 - omny_2022) / omny_2022
        ELSE NULL
    END AS omny_2023_growth,
    CASE 
        WHEN omny_2023 IS NOT NULL AND omny_2024 IS NOT NULL THEN 
            (omny_2024 - omny_2023) / omny_2023
        ELSE NULL
    END AS omny_2024_growth
FROM 
    pivoted_data
ORDER BY 
    station_complex
    );
  
  
[0m05:04:25.183058 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */

  
    
    

    create  table
      "mtastats"."main"."largest_expense_differences_2023__dbt_tmp"
  
    as (
      WITH expense_differences AS (
    SELECT
        agency,
        general_ledger,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) AS actual_expenses,
        SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS adopted_plan_expenses,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) - SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS difference
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        fiscal_year = 2023
        AND scenario IN ('Actual', 'Adopted Budget')
        AND financial_plan_year = 2023  -- Ensure we use only the 2023 Adopted Budget
        AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
        AND general_ledger != 'Reimbursable Overhead'  -- Exclude Reimbursable Overhead
    GROUP BY
        agency, general_ledger
),
ranked_expenses AS (
    SELECT
        agency,
        general_ledger,
        actual_expenses,
        adopted_plan_expenses,
        difference,
        ROW_NUMBER() OVER (PARTITION BY agency ORDER BY difference DESC) AS rank
    FROM
        expense_differences
    WHERE
        difference > 0  -- Only include cases where actual expenses are larger than the adopted budget
)
SELECT
    agency,
    general_ledger,
    actual_expenses,
    adopted_plan_expenses,
    difference
FROM
    ranked_expenses
WHERE
    rank <= 5  -- Select the top 5 items per agency
ORDER BY
    difference, rank
    );
  
  
[0m05:04:25.184198 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:04:25.190535 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */

  
    
    

    create  table
      "mtastats"."main"."subway_station_stats__dbt_tmp"
  
    as (
      WITH ridership_by_day AS (
    SELECT 
        station_complex,
        CAST(transit_timestamp AS DATE) AS day,
        DAYOFWEEK(transit_timestamp) AS weekday,
        SUM(ridership) AS daily_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) = 2024
    GROUP BY 
        station_complex, 
        CAST(transit_timestamp AS DATE), 
        DAYOFWEEK(transit_timestamp)
),
weekday_weekend AS (
    SELECT 
        station_complex,
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END AS day_type,
        AVG(daily_ridership) AS avg_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex, 
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END
),
single_day_stats AS (
    SELECT 
        station_complex,
        MAX(daily_ridership) AS highest_single_day_ridership,
        MIN(daily_ridership) AS lowest_single_day_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex
),
highest_single_day AS (
    SELECT 
        station_complex,
        day AS highest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MAX(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
),
lowest_single_day AS (
    SELECT 
        station_complex,
        day AS lowest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MIN(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
)
SELECT 
    rbd.station_complex,
    MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS avg_weekday_ridership,
    MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) AS avg_weekend_ridership,
    sds.highest_single_day_ridership,
    hsd.highest_single_day_ridership_day,
    sds.lowest_single_day_ridership,
    lsd.lowest_single_day_ridership_day,
    (MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) - MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END)) * 1.0 / MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS weekend_percentage_change
FROM 
    ridership_by_day rbd
JOIN 
    weekday_weekend wwd ON rbd.station_complex = wwd.station_complex
JOIN 
    single_day_stats sds ON rbd.station_complex = sds.station_complex
JOIN 
    highest_single_day hsd ON rbd.station_complex = hsd.station_complex
JOIN 
    lowest_single_day lsd ON rbd.station_complex = lsd.station_complex
GROUP BY 
    rbd.station_complex, 
    sds.highest_single_day_ridership, 
    sds.lowest_single_day_ridership, 
    hsd.highest_single_day_ridership_day, 
    lsd.lowest_single_day_ridership_day
ORDER BY 
    rbd.station_complex
    );
  
  
[0m05:04:25.191903 [debug] [Thread-10 ]: SQL status: OK in 0.046 seconds
[0m05:04:25.193642 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:04:25.194520 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m05:04:25.197503 [debug] [Thread-12 ]: SQL status: OK in 0.050 seconds
[0m05:04:25.198539 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:04:25.198999 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m05:04:25.214417 [debug] [Thread-13 ]: SQL status: OK in 0.066 seconds
[0m05:04:25.215105 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:04:25.215573 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      with weekly_ridership AS (
    SELECT 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_start,
        SUM(ridership) AS total_weekly_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp)
)
SELECT 
    station_complex, 
    week_start, 
    total_weekly_ridership
FROM 
    weekly_ridership
ORDER BY 
    station_complex, 
    week_start
    );
  
  
[0m05:04:25.537362 [debug] [Thread-4 (]: SQL status: OK in 0.366 seconds
[0m05:04:25.555200 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:04:25.556172 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
alter table "mtastats"."main"."daily_ridership__dbt_tmp" rename to "daily_ridership"
[0m05:04:25.559568 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m05:04:25.586543 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m05:04:25.587670 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:04:25.588143 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m05:04:25.593256 [debug] [Thread-7 (]: SQL status: OK in 0.412 seconds
[0m05:04:25.597361 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:04:25.598620 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
alter table "mtastats"."main"."labor_expenses_per_agency__dbt_tmp" rename to "labor_expenses_per_agency"
[0m05:04:25.600945 [debug] [Thread-7 (]: SQL status: OK in 0.002 seconds
[0m05:04:25.603178 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m05:04:25.604237 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:04:25.604750 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m05:04:25.605479 [debug] [Thread-4 (]: SQL status: OK in 0.017 seconds
[0m05:04:25.623540 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:04:25.624633 [debug] [Thread-7 (]: SQL status: OK in 0.019 seconds
[0m05:04:25.625555 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
drop table if exists "mtastats"."main"."daily_ridership__dbt_backup" cascade
[0m05:04:25.633444 [debug] [Thread-7 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:04:25.634760 [debug] [Thread-5 (]: SQL status: OK in 0.455 seconds
[0m05:04:25.635794 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
drop table if exists "mtastats"."main"."labor_expenses_per_agency__dbt_backup" cascade
[0m05:04:25.642439 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:04:25.645253 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m05:04:25.643975 [debug] [Thread-4 (]: SQL status: OK in 0.009 seconds
[0m05:04:25.646214 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
alter table "mtastats"."main"."expense_type_per_year__dbt_tmp" rename to "expense_type_per_year"
[0m05:04:25.650230 [debug] [Thread-7 (]: On model.mta.labor_expenses_per_agency: Close
[0m05:04:25.652982 [debug] [Thread-4 (]: On model.mta.daily_ridership: Close
[0m05:04:25.658104 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc44acf5e0>]}
[0m05:04:25.659588 [debug] [Thread-5 (]: SQL status: OK in 0.005 seconds
[0m05:04:25.661031 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc37c52f50>]}
[0m05:04:25.662244 [info ] [Thread-7 (]: 7 of 13 OK created sql table model main.labor_expenses_per_agency .............. [[32mOK[0m in 0.74s]
[0m05:04:25.666231 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m05:04:25.667523 [info ] [Thread-4 (]: 4 of 13 OK created sql table model main.daily_ridership ........................ [[32mOK[0m in 0.75s]
[0m05:04:25.669917 [debug] [Thread-7 (]: Finished running node model.mta.labor_expenses_per_agency
[0m05:04:25.670939 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:04:25.672119 [debug] [Thread-4 (]: Finished running node model.mta.daily_ridership
[0m05:04:25.673945 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m05:04:25.680972 [debug] [Thread-5 (]: SQL status: OK in 0.005 seconds
[0m05:04:25.685671 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:04:25.686783 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
drop table if exists "mtastats"."main"."expense_type_per_year__dbt_backup" cascade
[0m05:04:25.694126 [debug] [Thread-5 (]: SQL status: OK in 0.005 seconds
[0m05:04:25.697347 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: Close
[0m05:04:25.698617 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc37c51c00>]}
[0m05:04:25.700346 [info ] [Thread-5 (]: 5 of 13 OK created sql table model main.expense_type_per_year .................. [[32mOK[0m in 0.79s]
[0m05:04:25.702652 [debug] [Thread-5 (]: Finished running node model.mta.expense_type_per_year
[0m05:04:25.704153 [debug] [Thread-8 (]: SQL status: OK in 0.515 seconds
[0m05:04:25.709592 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:04:25.712783 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
alter table "mtastats"."main"."largest_expense_differences_2023__dbt_tmp" rename to "largest_expense_differences_2023"
[0m05:04:25.715435 [debug] [Thread-8 (]: SQL status: OK in 0.001 seconds
[0m05:04:25.718594 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m05:04:25.719449 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:04:25.721940 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m05:04:25.731278 [debug] [Thread-8 (]: SQL status: OK in 0.007 seconds
[0m05:04:25.736739 [debug] [Thread-8 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:04:25.737885 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
drop table if exists "mtastats"."main"."largest_expense_differences_2023__dbt_backup" cascade
[0m05:04:25.739181 [debug] [Thread-8 (]: SQL status: OK in 0.000 seconds
[0m05:04:25.741576 [debug] [Thread-8 (]: On model.mta.largest_expense_differences_2023: Close
[0m05:04:25.743514 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc370b6200>]}
[0m05:04:25.745183 [info ] [Thread-8 (]: 8 of 13 OK created sql table model main.largest_expense_differences_2023 ....... [[32mOK[0m in 0.83s]
[0m05:04:25.748382 [debug] [Thread-8 (]: Finished running node model.mta.largest_expense_differences_2023
[0m05:04:26.137994 [debug] [Thread-2 (]: SQL status: OK in 0.979 seconds
[0m05:04:26.144137 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:04:26.146724 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
alter table "mtastats"."main"."bond_payment_info__dbt_tmp" rename to "bond_payment_info"
[0m05:04:26.169729 [debug] [Thread-2 (]: SQL status: OK in 0.022 seconds
[0m05:04:26.212140 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m05:04:26.213210 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:04:26.220679 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m05:04:26.246454 [debug] [Thread-2 (]: SQL status: OK in 0.025 seconds
[0m05:04:26.251969 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:04:26.254357 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
drop table if exists "mtastats"."main"."bond_payment_info__dbt_backup" cascade
[0m05:04:26.256685 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m05:04:26.260092 [debug] [Thread-2 (]: On model.mta.bond_payment_info: Close
[0m05:04:26.280911 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc37c505b0>]}
[0m05:04:26.283527 [info ] [Thread-2 (]: 2 of 13 OK created sql table model main.bond_payment_info ...................... [[32mOK[0m in 1.41s]
[0m05:04:26.286659 [debug] [Thread-2 (]: Finished running node model.mta.bond_payment_info
[0m05:04:27.933781 [debug] [Thread-1 (]: SQL status: OK in 2.782 seconds
[0m05:04:27.939995 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:04:27.940995 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "mtastats"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m05:04:27.942745 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m05:04:27.946686 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m05:04:27.953954 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:04:27.956794 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m05:04:27.990387 [debug] [Thread-1 (]: SQL status: OK in 0.033 seconds
[0m05:04:27.995176 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:04:27.996433 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "mtastats"."main"."avg_riders_per_day__dbt_backup" cascade
[0m05:04:27.997568 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m05:04:28.001605 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m05:04:28.022230 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc37c517b0>]}
[0m05:04:28.024039 [info ] [Thread-1 (]: 1 of 13 OK created sql table model main.avg_riders_per_day ..................... [[32mOK[0m in 3.15s]
[0m05:04:28.025089 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m05:04:29.626936 [debug] [Thread-3 (]: SQL status: OK in 4.459 seconds
[0m05:04:29.633951 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:04:29.635500 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "mtastats"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m05:04:29.637886 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m05:04:29.641121 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m05:04:29.642069 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:04:29.642718 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m05:04:29.651466 [debug] [Thread-3 (]: SQL status: OK in 0.008 seconds
[0m05:04:29.656966 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:04:29.657778 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "mtastats"."main"."busiest_specific_times__dbt_backup" cascade
[0m05:04:29.658943 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m05:04:29.661368 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: Close
[0m05:04:29.662562 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc36f84850>]}
[0m05:04:29.664439 [info ] [Thread-3 (]: 3 of 13 OK created sql table model main.busiest_specific_times ................. [[32mOK[0m in 4.76s]
[0m05:04:29.666823 [debug] [Thread-3 (]: Finished running node model.mta.busiest_specific_times
[0m05:04:34.219368 [debug] [Thread-13 ]: SQL status: OK in 9.002 seconds
[0m05:04:34.227636 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:04:34.270512 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "mtastats"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m05:04:34.272266 [debug] [Thread-13 ]: SQL status: OK in 0.001 seconds
[0m05:04:34.275562 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m05:04:34.276535 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:04:34.277404 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m05:04:34.316061 [debug] [Thread-13 ]: SQL status: OK in 0.022 seconds
[0m05:04:34.326110 [debug] [Thread-13 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:04:34.327525 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "mtastats"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m05:04:34.329124 [debug] [Thread-13 ]: SQL status: OK in 0.001 seconds
[0m05:04:34.332335 [debug] [Thread-13 ]: On model.mta.weekly_riders_per_station: Close
[0m05:04:34.333575 [debug] [Thread-13 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc36f74e50>]}
[0m05:04:34.335563 [info ] [Thread-13 ]: 13 of 13 OK created sql table model main.weekly_riders_per_station ............. [[32mOK[0m in 9.42s]
[0m05:04:34.337448 [debug] [Thread-13 ]: Finished running node model.mta.weekly_riders_per_station
[0m05:04:34.564470 [debug] [Thread-10 ]: SQL status: OK in 9.369 seconds
[0m05:04:34.570172 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:04:34.571080 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "mtastats"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m05:04:34.573239 [debug] [Thread-10 ]: SQL status: OK in 0.001 seconds
[0m05:04:34.577925 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: COMMIT
[0m05:04:34.578798 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:04:34.579484 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: COMMIT
[0m05:04:34.586095 [debug] [Thread-10 ]: SQL status: OK in 0.006 seconds
[0m05:04:34.590624 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:04:34.591427 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "mtastats"."main"."omny_adoption_increase__dbt_backup" cascade
[0m05:04:34.592603 [debug] [Thread-10 ]: SQL status: OK in 0.000 seconds
[0m05:04:34.597895 [debug] [Thread-10 ]: On model.mta.omny_adoption_increase: Close
[0m05:04:34.610892 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc370b6740>]}
[0m05:04:34.612364 [info ] [Thread-10 ]: 10 of 13 OK created sql table model main.omny_adoption_increase ................ [[32mOK[0m in 9.70s]
[0m05:04:34.613606 [debug] [Thread-10 ]: Finished running node model.mta.omny_adoption_increase
[0m05:04:34.951975 [debug] [Thread-11 ]: SQL status: OK in 9.759 seconds
[0m05:04:34.957782 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:04:34.958618 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
alter table "mtastats"."main"."subway_station_stats__dbt_tmp" rename to "subway_station_stats"
[0m05:04:34.959941 [debug] [Thread-11 ]: SQL status: OK in 0.001 seconds
[0m05:04:34.962895 [debug] [Thread-11 ]: On model.mta.subway_station_stats: COMMIT
[0m05:04:34.963681 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:04:34.964373 [debug] [Thread-11 ]: On model.mta.subway_station_stats: COMMIT
[0m05:04:34.990183 [debug] [Thread-11 ]: SQL status: OK in 0.025 seconds
[0m05:04:34.995998 [debug] [Thread-11 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:04:34.998463 [debug] [Thread-11 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
drop table if exists "mtastats"."main"."subway_station_stats__dbt_backup" cascade
[0m05:04:35.003174 [debug] [Thread-11 ]: SQL status: OK in 0.002 seconds
[0m05:04:35.006320 [debug] [Thread-11 ]: On model.mta.subway_station_stats: Close
[0m05:04:35.030620 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc370b5990>]}
[0m05:04:35.032089 [info ] [Thread-11 ]: 11 of 13 OK created sql table model main.subway_station_stats .................. [[32mOK[0m in 10.11s]
[0m05:04:35.033261 [debug] [Thread-11 ]: Finished running node model.mta.subway_station_stats
[0m05:04:35.466726 [debug] [Thread-12 ]: SQL status: OK in 10.266 seconds
[0m05:04:35.474841 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:04:35.475812 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "mtastats"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m05:04:35.477173 [debug] [Thread-12 ]: SQL status: OK in 0.001 seconds
[0m05:04:35.480683 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: COMMIT
[0m05:04:35.481602 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:04:35.482288 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: COMMIT
[0m05:04:35.504901 [debug] [Thread-12 ]: SQL status: OK in 0.022 seconds
[0m05:04:35.509349 [debug] [Thread-12 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:04:35.510133 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "mtastats"."main"."total_riders_per_station__dbt_backup" cascade
[0m05:04:35.511176 [debug] [Thread-12 ]: SQL status: OK in 0.000 seconds
[0m05:04:35.513309 [debug] [Thread-12 ]: On model.mta.total_riders_per_station: Close
[0m05:04:35.514310 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb8aaa9d50>]}
[0m05:04:35.515527 [info ] [Thread-12 ]: 12 of 13 OK created sql table model main.total_riders_per_station .............. [[32mOK[0m in 10.60s]
[0m05:04:35.516529 [debug] [Thread-12 ]: Finished running node model.mta.total_riders_per_station
[0m05:04:35.828772 [debug] [Thread-9 (]: SQL status: OK in 10.643 seconds
[0m05:04:35.833928 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:04:35.834790 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "mtastats"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m05:04:35.836102 [debug] [Thread-9 (]: SQL status: OK in 0.001 seconds
[0m05:04:35.838867 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m05:04:35.839666 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:04:35.840453 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: COMMIT
[0m05:04:35.864998 [debug] [Thread-9 (]: SQL status: OK in 0.024 seconds
[0m05:04:35.869838 [debug] [Thread-9 (]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:04:35.870535 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "mtastats"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m05:04:35.871566 [debug] [Thread-9 (]: SQL status: OK in 0.000 seconds
[0m05:04:35.873797 [debug] [Thread-9 (]: On model.mta.omny_adoption_by_station: Close
[0m05:04:35.874822 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc370b66b0>]}
[0m05:04:35.875972 [info ] [Thread-9 (]: 9 of 13 OK created sql table model main.omny_adoption_by_station ............... [[32mOK[0m in 10.96s]
[0m05:04:35.876964 [debug] [Thread-9 (]: Finished running node model.mta.omny_adoption_by_station
[0m05:04:36.218819 [debug] [Thread-6 (]: SQL status: OK in 11.043 seconds
[0m05:04:36.222930 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:04:36.223616 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "mtastats"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m05:04:36.225194 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m05:04:36.227539 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m05:04:36.228113 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:04:36.228587 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m05:04:36.232127 [debug] [Thread-6 (]: SQL status: OK in 0.003 seconds
[0m05:04:36.234269 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:04:36.234639 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "mtastats"."main"."fare_class_boro__dbt_backup" cascade
[0m05:04:36.235240 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m05:04:36.236515 [debug] [Thread-6 (]: On model.mta.fare_class_boro: Close
[0m05:04:36.313418 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f38d9ea3-389d-4346-8e92-11abcec2b402', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc370b5d80>]}
[0m05:04:36.314224 [info ] [Thread-6 (]: 6 of 13 OK created sql table model main.fare_class_boro ........................ [[32mOK[0m in 11.40s]
[0m05:04:36.314841 [debug] [Thread-6 (]: Finished running node model.mta.fare_class_boro
[0m05:04:36.318575 [debug] [MainThread]: Using duckdb connection "master"
[0m05:04:36.318960 [debug] [MainThread]: On master: BEGIN
[0m05:04:36.319282 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m05:04:36.325326 [debug] [MainThread]: SQL status: OK in 0.006 seconds
[0m05:04:36.325773 [debug] [MainThread]: On master: COMMIT
[0m05:04:36.326075 [debug] [MainThread]: Using duckdb connection "master"
[0m05:04:36.326342 [debug] [MainThread]: On master: COMMIT
[0m05:04:36.327000 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m05:04:36.327310 [debug] [MainThread]: On master: Close
[0m05:04:36.329344 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:04:36.329631 [debug] [MainThread]: Connection 'model.mta.expense_type_per_year' was properly closed.
[0m05:04:36.329960 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m05:04:36.330243 [debug] [MainThread]: Connection 'model.mta.bond_payment_info' was properly closed.
[0m05:04:36.330501 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m05:04:36.330752 [debug] [MainThread]: Connection 'model.mta.daily_ridership' was properly closed.
[0m05:04:36.330987 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m05:04:36.331204 [debug] [MainThread]: Connection 'model.mta.labor_expenses_per_agency' was properly closed.
[0m05:04:36.331404 [debug] [MainThread]: Connection 'model.mta.largest_expense_differences_2023' was properly closed.
[0m05:04:36.331592 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m05:04:36.331782 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m05:04:36.331968 [debug] [MainThread]: Connection 'model.mta.subway_station_stats' was properly closed.
[0m05:04:36.332157 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m05:04:36.332344 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m05:04:36.332748 [info ] [MainThread]: 
[0m05:04:36.333100 [info ] [MainThread]: Finished running 13 table models in 0 hours 0 minutes and 11.67 seconds (11.67s).
[0m05:04:36.334696 [debug] [MainThread]: Command end result
[0m05:04:36.360755 [info ] [MainThread]: 
[0m05:04:36.361448 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:04:36.361876 [info ] [MainThread]: 
[0m05:04:36.362264 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 TOTAL=13
[0m05:04:36.363253 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 12.235546, "process_user_time": 145.34872, "process_kernel_time": 8.473576, "process_mem_max_rss": "818404", "process_in_blocks": "119424", "process_out_blocks": "15464"}
[0m05:04:36.363842 [debug] [MainThread]: Command `dbt run` succeeded at 05:04:36.363734 after 12.24 seconds
[0m05:04:36.364234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc44a434c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc3451fb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc430228c0>]}
[0m05:04:36.364634 [debug] [MainThread]: Flushing usage events
[0m05:24:14.539658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e304f370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e2bd2bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e16fab00>]}


============================== 05:24:14.547133 | dc7bda9b-b77f-4f7c-a03e-d5ea0120e8ec ==============================
[0m05:24:14.547133 [info ] [MainThread]: Running with dbt=1.8.7
[0m05:24:14.547632 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:24:14.552563 [error] [MainThread]: Encountered an error:
Parsing Error
  Env var required but not provided: 'LAKE_PATH'
[0m05:24:14.553762 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 0.06644556, "process_user_time": 0.873807, "process_kernel_time": 0.524284, "process_mem_max_rss": "91268", "process_in_blocks": "8", "process_out_blocks": "16", "command_success": false}
[0m05:24:14.554254 [debug] [MainThread]: Command `dbt run` failed at 05:24:14.554143 after 0.07 seconds
[0m05:24:14.554604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e304f370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e1792dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e17934f0>]}
[0m05:24:14.554966 [debug] [MainThread]: Flushing usage events
[0m05:25:04.967902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3c323400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3bd003a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3a9d5ea0>]}


============================== 05:25:04.970266 | 35beca91-1b5b-4899-aa82-f6b59aabe584 ==============================
[0m05:25:04.970266 [info ] [MainThread]: Running with dbt=1.8.7
[0m05:25:04.970780 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/christianocean/mta/mta/transformations/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/home/christianocean/mta/mta/transformations/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:25:05.198785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3a97a0e0>]}
[0m05:25:05.258995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3b62e800>]}
[0m05:25:05.264108 [info ] [MainThread]: Registered adapter: duckdb=1.8.3
[0m05:25:05.273051 [debug] [MainThread]: checksum: 4af21dafb485259c48497ac86b711ddb1982f3d0f1c0ca4e09356de488b753c0, vars: {}, profile: , target: , version: 1.8.7
[0m05:25:05.413705 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m05:25:05.414326 [debug] [MainThread]: Partial parsing: added file: mta://models/forecast_accuracy_2023.sql
[0m05:25:05.668572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f4d4100>]}
[0m05:25:05.742423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f5016f0>]}
[0m05:25:05.743194 [info ] [MainThread]: Found 14 models, 9 sources, 416 macros
[0m05:25:05.743898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f501b10>]}
[0m05:25:05.745871 [info ] [MainThread]: 
[0m05:25:05.746516 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m05:25:05.752207 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_mtastats'
[0m05:25:05.873150 [debug] [ThreadPool]: Using duckdb connection "list_mtastats"
[0m05:25:05.873790 [debug] [ThreadPool]: On list_mtastats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where catalog_name = '"mtastats"'
    
  
  
[0m05:25:05.874232 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:05.894658 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m05:25:05.896389 [debug] [ThreadPool]: On list_mtastats: Close
[0m05:25:05.898703 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_mtastats, now create_mtastats_main)
[0m05:25:05.899360 [debug] [ThreadPool]: Creating schema "database: "mtastats"
schema: "main"
"
[0m05:25:05.903871 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:25:05.904177 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
        select type from duckdb_databases()
        where database_name='mtastats'
        and type='sqlite'
    
  
[0m05:25:05.904430 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:25:05.910454 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m05:25:05.911656 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:25:05.911932 [debug] [ThreadPool]: On create_mtastats_main: BEGIN
[0m05:25:05.912417 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:25:05.912653 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:25:05.912889 [debug] [ThreadPool]: On create_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "create_mtastats_main"} */

    
    
        create schema if not exists "mtastats"."main"
    
[0m05:25:05.913375 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:25:05.913947 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m05:25:05.914178 [debug] [ThreadPool]: Using duckdb connection "create_mtastats_main"
[0m05:25:05.914412 [debug] [ThreadPool]: On create_mtastats_main: COMMIT
[0m05:25:05.914811 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m05:25:05.915058 [debug] [ThreadPool]: On create_mtastats_main: Close
[0m05:25:05.917818 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_mtastats_main, now list_mtastats_main)
[0m05:25:05.922365 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m05:25:05.922660 [debug] [ThreadPool]: On list_mtastats_main: BEGIN
[0m05:25:05.922958 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:25:05.929438 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m05:25:05.929979 [debug] [ThreadPool]: Using duckdb connection "list_mtastats_main"
[0m05:25:05.930332 [debug] [ThreadPool]: On list_mtastats_main: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "connection_name": "list_mtastats_main"} */
select
      'mtastats' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where table_schema = 'main'
    and table_catalog = 'mtastats'
  
[0m05:25:05.950701 [debug] [ThreadPool]: SQL status: OK in 0.020 seconds
[0m05:25:05.952099 [debug] [ThreadPool]: On list_mtastats_main: ROLLBACK
[0m05:25:05.952772 [debug] [ThreadPool]: Failed to rollback 'list_mtastats_main'
[0m05:25:05.953027 [debug] [ThreadPool]: On list_mtastats_main: Close
[0m05:25:05.956369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3c60ecb0>]}
[0m05:25:05.956744 [debug] [MainThread]: Using duckdb connection "master"
[0m05:25:05.956995 [debug] [MainThread]: On master: BEGIN
[0m05:25:05.957216 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:25:05.964713 [debug] [MainThread]: SQL status: OK in 0.007 seconds
[0m05:25:05.965130 [debug] [MainThread]: On master: COMMIT
[0m05:25:05.965446 [debug] [MainThread]: Using duckdb connection "master"
[0m05:25:05.965671 [debug] [MainThread]: On master: COMMIT
[0m05:25:05.966048 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m05:25:05.966296 [debug] [MainThread]: On master: Close
[0m05:25:05.968011 [info ] [MainThread]: Concurrency: 16 threads (target='dev')
[0m05:25:05.968361 [info ] [MainThread]: 
[0m05:25:05.977721 [debug] [Thread-1 (]: Began running node model.mta.avg_riders_per_day
[0m05:25:05.978371 [debug] [Thread-2 (]: Began running node model.mta.bond_payment_info
[0m05:25:05.978874 [debug] [Thread-3 (]: Began running node model.mta.busiest_specific_times
[0m05:25:05.979502 [info ] [Thread-1 (]: 1 of 14 START sql table model main.avg_riders_per_day .......................... [RUN]
[0m05:25:05.980205 [debug] [Thread-4 (]: Began running node model.mta.daily_ridership
[0m05:25:05.980723 [info ] [Thread-2 (]: 2 of 14 START sql table model main.bond_payment_info ........................... [RUN]
[0m05:25:05.981442 [info ] [Thread-3 (]: 3 of 14 START sql table model main.busiest_specific_times ...................... [RUN]
[0m05:25:05.982002 [debug] [Thread-5 (]: Began running node model.mta.expense_type_per_year
[0m05:25:05.982573 [debug] [Thread-6 (]: Began running node model.mta.fare_class_boro
[0m05:25:05.983284 [debug] [Thread-1 (]: Acquiring new duckdb connection 'model.mta.avg_riders_per_day'
[0m05:25:05.983775 [debug] [Thread-7 (]: Began running node model.mta.forecast_accuracy_2023
[0m05:25:05.984328 [debug] [Thread-8 (]: Began running node model.mta.labor_expenses_per_agency
[0m05:25:05.984974 [info ] [Thread-4 (]: 4 of 14 START sql table model main.daily_ridership ............................. [RUN]
[0m05:25:05.986010 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.mta.bond_payment_info'
[0m05:25:05.987302 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.mta.busiest_specific_times'
[0m05:25:05.988914 [debug] [Thread-9 (]: Began running node model.mta.largest_expense_differences_2023
[0m05:25:05.991196 [debug] [Thread-10 ]: Began running node model.mta.omny_adoption_by_station
[0m05:25:05.992074 [debug] [Thread-11 ]: Began running node model.mta.omny_adoption_increase
[0m05:25:05.992710 [info ] [Thread-5 (]: 5 of 14 START sql table model main.expense_type_per_year ....................... [RUN]
[0m05:25:05.993577 [info ] [Thread-6 (]: 6 of 14 START sql table model main.fare_class_boro ............................. [RUN]
[0m05:25:05.994287 [debug] [Thread-1 (]: Began compiling node model.mta.avg_riders_per_day
[0m05:25:05.994830 [debug] [Thread-12 ]: Began running node model.mta.subway_station_stats
[0m05:25:05.995470 [info ] [Thread-7 (]: 7 of 14 START sql table model main.forecast_accuracy_2023 ...................... [RUN]
[0m05:25:05.995939 [debug] [Thread-13 ]: Began running node model.mta.total_riders_per_station
[0m05:25:05.996580 [debug] [Thread-14 ]: Began running node model.mta.weekly_riders_per_station
[0m05:25:05.997060 [info ] [Thread-8 (]: 8 of 14 START sql table model main.labor_expenses_per_agency ................... [RUN]
[0m05:25:05.997867 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.mta.daily_ridership'
[0m05:25:05.998460 [debug] [Thread-2 (]: Began compiling node model.mta.bond_payment_info
[0m05:25:05.999054 [debug] [Thread-3 (]: Began compiling node model.mta.busiest_specific_times
[0m05:25:05.999683 [info ] [Thread-9 (]: 9 of 14 START sql table model main.largest_expense_differences_2023 ............ [RUN]
[0m05:25:06.000453 [info ] [Thread-10 ]: 10 of 14 START sql table model main.omny_adoption_by_station ................... [RUN]
[0m05:25:06.001253 [info ] [Thread-11 ]: 11 of 14 START sql table model main.omny_adoption_increase ..................... [RUN]
[0m05:25:06.002270 [debug] [Thread-5 (]: Re-using an available connection from the pool (formerly list_mtastats_main, now model.mta.expense_type_per_year)
[0m05:25:06.004529 [debug] [Thread-6 (]: Acquiring new duckdb connection 'model.mta.fare_class_boro'
[0m05:25:06.014976 [debug] [Thread-1 (]: Writing injected SQL for node "model.mta.avg_riders_per_day"
[0m05:25:06.015672 [info ] [Thread-12 ]: 12 of 14 START sql table model main.subway_station_stats ....................... [RUN]
[0m05:25:06.016448 [debug] [Thread-7 (]: Acquiring new duckdb connection 'model.mta.forecast_accuracy_2023'
[0m05:25:06.017009 [info ] [Thread-13 ]: 13 of 14 START sql table model main.total_riders_per_station ................... [RUN]
[0m05:25:06.017592 [info ] [Thread-14 ]: 14 of 14 START sql table model main.weekly_riders_per_station .................. [RUN]
[0m05:25:06.018297 [debug] [Thread-8 (]: Acquiring new duckdb connection 'model.mta.labor_expenses_per_agency'
[0m05:25:06.018898 [debug] [Thread-4 (]: Began compiling node model.mta.daily_ridership
[0m05:25:06.026211 [debug] [Thread-2 (]: Writing injected SQL for node "model.mta.bond_payment_info"
[0m05:25:06.029634 [debug] [Thread-3 (]: Writing injected SQL for node "model.mta.busiest_specific_times"
[0m05:25:06.030838 [debug] [Thread-9 (]: Acquiring new duckdb connection 'model.mta.largest_expense_differences_2023'
[0m05:25:06.031637 [debug] [Thread-10 ]: Acquiring new duckdb connection 'model.mta.omny_adoption_by_station'
[0m05:25:06.032192 [debug] [Thread-11 ]: Acquiring new duckdb connection 'model.mta.omny_adoption_increase'
[0m05:25:06.032687 [debug] [Thread-5 (]: Began compiling node model.mta.expense_type_per_year
[0m05:25:06.033285 [debug] [Thread-6 (]: Began compiling node model.mta.fare_class_boro
[0m05:25:06.034117 [debug] [Thread-12 ]: Acquiring new duckdb connection 'model.mta.subway_station_stats'
[0m05:25:06.034678 [debug] [Thread-7 (]: Began compiling node model.mta.forecast_accuracy_2023
[0m05:25:06.035346 [debug] [Thread-13 ]: Acquiring new duckdb connection 'model.mta.total_riders_per_station'
[0m05:25:06.035878 [debug] [Thread-14 ]: Acquiring new duckdb connection 'model.mta.weekly_riders_per_station'
[0m05:25:06.036490 [debug] [Thread-8 (]: Began compiling node model.mta.labor_expenses_per_agency
[0m05:25:06.037045 [debug] [Thread-1 (]: Began executing node model.mta.avg_riders_per_day
[0m05:25:06.048117 [debug] [Thread-4 (]: Writing injected SQL for node "model.mta.daily_ridership"
[0m05:25:06.049288 [debug] [Thread-9 (]: Began compiling node model.mta.largest_expense_differences_2023
[0m05:25:06.050097 [debug] [Thread-3 (]: Began executing node model.mta.busiest_specific_times
[0m05:25:06.050636 [debug] [Thread-10 ]: Began compiling node model.mta.omny_adoption_by_station
[0m05:25:06.051132 [debug] [Thread-2 (]: Began executing node model.mta.bond_payment_info
[0m05:25:06.051584 [debug] [Thread-11 ]: Began compiling node model.mta.omny_adoption_increase
[0m05:25:06.055610 [debug] [Thread-5 (]: Writing injected SQL for node "model.mta.expense_type_per_year"
[0m05:25:06.063287 [debug] [Thread-6 (]: Writing injected SQL for node "model.mta.fare_class_boro"
[0m05:25:06.063952 [debug] [Thread-12 ]: Began compiling node model.mta.subway_station_stats
[0m05:25:06.066725 [debug] [Thread-7 (]: Writing injected SQL for node "model.mta.forecast_accuracy_2023"
[0m05:25:06.067250 [debug] [Thread-13 ]: Began compiling node model.mta.total_riders_per_station
[0m05:25:06.067763 [debug] [Thread-14 ]: Began compiling node model.mta.weekly_riders_per_station
[0m05:25:06.070029 [debug] [Thread-8 (]: Writing injected SQL for node "model.mta.labor_expenses_per_agency"
[0m05:25:06.091558 [debug] [Thread-9 (]: Writing injected SQL for node "model.mta.largest_expense_differences_2023"
[0m05:25:06.107536 [debug] [Thread-4 (]: Began executing node model.mta.daily_ridership
[0m05:25:06.112826 [debug] [Thread-1 (]: Writing runtime sql for node "model.mta.avg_riders_per_day"
[0m05:25:06.113552 [debug] [Thread-3 (]: Writing runtime sql for node "model.mta.busiest_specific_times"
[0m05:25:06.117368 [debug] [Thread-10 ]: Writing injected SQL for node "model.mta.omny_adoption_by_station"
[0m05:25:06.120681 [debug] [Thread-2 (]: Writing runtime sql for node "model.mta.bond_payment_info"
[0m05:25:06.123494 [debug] [Thread-11 ]: Writing injected SQL for node "model.mta.omny_adoption_increase"
[0m05:25:06.127799 [debug] [Thread-12 ]: Writing injected SQL for node "model.mta.subway_station_stats"
[0m05:25:06.129044 [debug] [Thread-5 (]: Began executing node model.mta.expense_type_per_year
[0m05:25:06.129791 [debug] [Thread-6 (]: Began executing node model.mta.fare_class_boro
[0m05:25:06.132207 [debug] [Thread-13 ]: Writing injected SQL for node "model.mta.total_riders_per_station"
[0m05:25:06.132728 [debug] [Thread-7 (]: Began executing node model.mta.forecast_accuracy_2023
[0m05:25:06.134707 [debug] [Thread-14 ]: Writing injected SQL for node "model.mta.weekly_riders_per_station"
[0m05:25:06.135567 [debug] [Thread-8 (]: Began executing node model.mta.labor_expenses_per_agency
[0m05:25:06.138704 [debug] [Thread-4 (]: Writing runtime sql for node "model.mta.daily_ridership"
[0m05:25:06.139627 [debug] [Thread-9 (]: Began executing node model.mta.largest_expense_differences_2023
[0m05:25:06.141947 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:25:06.142565 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:25:06.143572 [debug] [Thread-10 ]: Began executing node model.mta.omny_adoption_by_station
[0m05:25:06.150673 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:25:06.151234 [debug] [Thread-5 (]: Writing runtime sql for node "model.mta.expense_type_per_year"
[0m05:25:06.152143 [debug] [Thread-12 ]: Began executing node model.mta.subway_station_stats
[0m05:25:06.154518 [debug] [Thread-6 (]: Writing runtime sql for node "model.mta.fare_class_boro"
[0m05:25:06.155030 [debug] [Thread-11 ]: Began executing node model.mta.omny_adoption_increase
[0m05:25:06.158110 [debug] [Thread-7 (]: Writing runtime sql for node "model.mta.forecast_accuracy_2023"
[0m05:25:06.161613 [debug] [Thread-8 (]: Writing runtime sql for node "model.mta.labor_expenses_per_agency"
[0m05:25:06.162474 [debug] [Thread-13 ]: Began executing node model.mta.total_riders_per_station
[0m05:25:06.166159 [debug] [Thread-9 (]: Writing runtime sql for node "model.mta.largest_expense_differences_2023"
[0m05:25:06.166799 [debug] [Thread-14 ]: Began executing node model.mta.weekly_riders_per_station
[0m05:25:06.167237 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: BEGIN
[0m05:25:06.167809 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: BEGIN
[0m05:25:06.170510 [debug] [Thread-10 ]: Writing runtime sql for node "model.mta.omny_adoption_by_station"
[0m05:25:06.171091 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:25:06.171625 [debug] [Thread-2 (]: On model.mta.bond_payment_info: BEGIN
[0m05:25:06.175029 [debug] [Thread-12 ]: Writing runtime sql for node "model.mta.subway_station_stats"
[0m05:25:06.176011 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:25:06.178490 [debug] [Thread-11 ]: Writing runtime sql for node "model.mta.omny_adoption_increase"
[0m05:25:06.179440 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:25:06.183459 [debug] [Thread-13 ]: Writing runtime sql for node "model.mta.total_riders_per_station"
[0m05:25:06.185551 [debug] [Thread-7 (]: Using duckdb connection "model.mta.forecast_accuracy_2023"
[0m05:25:06.186019 [debug] [Thread-9 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:25:06.186539 [debug] [Thread-8 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:25:06.188897 [debug] [Thread-14 ]: Writing runtime sql for node "model.mta.weekly_riders_per_station"
[0m05:25:06.189536 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m05:25:06.190122 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m05:25:06.190875 [debug] [Thread-4 (]: On model.mta.daily_ridership: BEGIN
[0m05:25:06.191428 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m05:25:06.192253 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: BEGIN
[0m05:25:06.192861 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:25:06.193975 [debug] [Thread-12 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:25:06.194627 [debug] [Thread-6 (]: On model.mta.fare_class_boro: BEGIN
[0m05:25:06.195369 [debug] [Thread-11 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:25:06.195802 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: BEGIN
[0m05:25:06.196480 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: BEGIN
[0m05:25:06.196900 [debug] [Thread-13 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:25:06.197430 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: BEGIN
[0m05:25:06.206341 [debug] [Thread-14 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:25:06.206910 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m05:25:06.207793 [debug] [Thread-5 (]: Opening a new connection, currently in state closed
[0m05:25:06.209005 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: BEGIN
[0m05:25:06.209927 [debug] [Thread-12 ]: On model.mta.subway_station_stats: BEGIN
[0m05:25:06.210541 [debug] [Thread-1 (]: SQL status: OK in 0.021 seconds
[0m05:25:06.211052 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m05:25:06.211534 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: BEGIN
[0m05:25:06.212011 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m05:25:06.212525 [debug] [Thread-9 (]: Opening a new connection, currently in state init
[0m05:25:06.213164 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: BEGIN
[0m05:25:06.214655 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m05:25:06.215666 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: BEGIN
[0m05:25:06.216050 [debug] [Thread-3 (]: SQL status: OK in 0.026 seconds
[0m05:25:06.216853 [debug] [Thread-10 ]: Opening a new connection, currently in state init
[0m05:25:06.217425 [debug] [Thread-12 ]: Opening a new connection, currently in state init
[0m05:25:06.217934 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:25:06.218834 [debug] [Thread-11 ]: Opening a new connection, currently in state init
[0m05:25:06.220434 [debug] [Thread-2 (]: SQL status: OK in 0.029 seconds
[0m05:25:06.221250 [debug] [Thread-13 ]: Opening a new connection, currently in state init
[0m05:25:06.222162 [debug] [Thread-14 ]: Opening a new connection, currently in state init
[0m05:25:06.222796 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:25:06.223857 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */

  
    
    

    create  table
      "mtastats"."main"."avg_riders_per_day__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    EXTRACT(DAYOFWEEK FROM transit_timestamp) AS day_of_week, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    day_of_week
ORDER BY 
    average_ridership DESC
    );
  
  
[0m05:25:06.225127 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:25:06.225615 [debug] [Thread-4 (]: SQL status: OK in 0.019 seconds
[0m05:25:06.226615 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */

  
    
    

    create  table
      "mtastats"."main"."busiest_specific_times__dbt_tmp"
  
    as (
      SELECT 
    EXTRACT(HOUR FROM transit_timestamp) AS transit_hour, 
    AVG(ridership) AS average_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    transit_hour
ORDER BY 
    average_ridership DESC
    );
  
  
[0m05:25:06.227730 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */

  
    
    

    create  table
      "mtastats"."main"."bond_payment_info__dbt_tmp"
  
    as (
      WITH payment_stats AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        MAX(timestamp) AS last_payment_date,
        AVG(amount) AS average_payment,
        COUNT(DISTINCT timestamp) AS total_payments,
        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY amount) AS median_payment
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
first_payment AS (
    SELECT
        general_ledger,
        MIN(timestamp) AS first_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = fp.general_ledger AND timestamp = MIN(fp.timestamp)) AS first_payment_amount
    FROM
        mta_operations_statement fp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
),
last_payment AS (
    SELECT
        general_ledger,
        MAX(timestamp) AS last_payment_date,
        (SELECT amount FROM mta_operations_statement WHERE general_ledger = lp.general_ledger AND timestamp = MAX(lp.timestamp)) AS last_payment_amount
    FROM
        mta_operations_statement lp
    WHERE
        scenario = 'Actual'
        AND type = 'Debt Service Expenses'
    GROUP BY
        general_ledger
)
-- Wrapping everything inside another DISTINCT query
SELECT DISTINCT
    ps.general_ledger,
    fp.first_payment_date,
    fp.first_payment_amount,
    ps.last_payment_date,
    lp.last_payment_amount,
    ps.average_payment,
    ps.median_payment,
    ps.total_payments
FROM
    payment_stats ps
LEFT JOIN
    first_payment fp ON ps.general_ledger = fp.general_ledger
LEFT JOIN
    last_payment lp ON ps.general_ledger = lp.general_ledger
ORDER BY
    ps.general_ledger
    );
  
  
[0m05:25:06.228678 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:25:06.229253 [debug] [Thread-5 (]: SQL status: OK in 0.021 seconds
[0m05:25:06.231692 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */

  
    
    

    create  table
      "mtastats"."main"."daily_ridership__dbt_tmp"
  
    as (
      SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(subways_total_ridership) AS ridership,
    'subway' AS transport_type,
    AVG(subways_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(buses_total_ridership) AS ridership,
    'buses' AS transport_type,
    AVG(buses_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(lirr_total_ridership) AS ridership,
    'lirr' AS transport_type,
    AVG(lirr_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(metro_north_total_ridership) AS ridership,
    'metro_north' AS transport_type,
    AVG(metro_north_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(access_a_ride_total_trips) AS ridership,
    'access_a_ride' AS transport_type,
    AVG(access_a_ride_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(bridges_tunnels_total_traffic) AS ridership,
    'bridges_tunnels' AS transport_type,
    AVG(bridges_tunnels_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type

UNION ALL

SELECT 
    DATE_TRUNC('week', date) AS week_start,
    SUM(staten_island_railway_total_ridership) AS ridership,
    'staten_island_railway' AS transport_type,
    AVG(staten_island_railway_pct_pre_pandemic) AS avg_pct_pre_pandemic
FROM "mtastats"."main"."mta_daily_ridership"
GROUP BY week_start, transport_type
    );
  
  
[0m05:25:06.232771 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:25:06.234179 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */

  
    
    

    create  table
      "mtastats"."main"."expense_type_per_year__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    general_ledger,
    SUM(amount) AS total_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    scenario = 'Actual'
    AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
GROUP BY 
    agency,
    fiscal_year,
    general_ledger
ORDER BY 
    agency, fiscal_year, general_ledger
    );
  
  
[0m05:25:06.234897 [debug] [Thread-6 (]: SQL status: OK in 0.024 seconds
[0m05:25:06.235672 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:25:06.236244 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */

  
    
    

    create  table
      "mtastats"."main"."fare_class_boro__dbt_tmp"
  
    as (
      WITH total_ridership_per_borough_daytype AS (
    -- Calculate total ridership for each borough and day type (Weekday or Weekend)
    SELECT 
        borough, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership_borough_daytype
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, day_type
),
ridership_by_fare_class AS (
    -- Calculate total ridership by fare class category, borough, and day type (Weekday/Weekend)
    SELECT 
        borough, 
        fare_class_category, 
        CASE 
            WHEN EXTRACT(DAYOFWEEK FROM transit_timestamp) IN (1, 7) THEN 'Weekend'
            ELSE 'Weekday'
        END AS day_type,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        borough, fare_class_category, day_type
)
SELECT 
    r.borough, 
    r.fare_class_category, 
    r.day_type,
    r.total_ridership, 
    ROUND(r.total_ridership / t.total_ridership_borough_daytype, 4) AS ridership_percentage
FROM 
    ridership_by_fare_class r
JOIN 
    total_ridership_per_borough_daytype t
    ON r.borough = t.borough 
    AND r.day_type = t.day_type
ORDER BY 
    total_ridership DESC
    );
  
  
[0m05:25:06.238111 [debug] [Thread-7 (]: SQL status: OK in 0.026 seconds
[0m05:25:06.238843 [debug] [Thread-7 (]: Using duckdb connection "model.mta.forecast_accuracy_2023"
[0m05:25:06.239895 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.forecast_accuracy_2023"} */

  
    
    

    create  table
      "mtastats"."main"."forecast_accuracy_2023__dbt_tmp"
  
    as (
      SELECT 
    agency_full_name,
    general_ledger,
    expense_type,

    -- Total amounts for Adopted Budget by Financial Plan Year
    SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2019 
        THEN amount 
        ELSE 0 
    END) AS total_adopted_budget_2019,

    SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2020 
        THEN amount 
        ELSE 0 
    END) AS total_adopted_budget_2020,

    SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2021 
        THEN amount 
        ELSE 0 
    END) AS total_adopted_budget_2021,

    SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2022 
        THEN amount 
        ELSE 0 
    END) AS total_adopted_budget_2022,

    -- Total amount for Actual 2023
    SUM(CASE 
        WHEN scenario = 'Actual' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2023 
        THEN amount 
        ELSE 0 
    END) AS total_actual_2023,

    -- Differences between Actual and Adopted Budget for each year
    SUM(CASE 
        WHEN scenario = 'Actual' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2023 
        THEN amount 
        ELSE 0 
    END) - SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2019 
        THEN amount 
        ELSE 0 
    END) AS difference_2019_vs_actual,

    SUM(CASE 
        WHEN scenario = 'Actual' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2023 
        THEN amount 
        ELSE 0 
    END) - SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2020 
        THEN amount 
        ELSE 0 
    END) AS difference_2020_vs_actual,

    SUM(CASE 
        WHEN scenario = 'Actual' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2023 
        THEN amount 
        ELSE 0 
    END) - SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2021 
        THEN amount 
        ELSE 0 
    END) AS difference_2021_vs_actual,

    SUM(CASE 
        WHEN scenario = 'Actual' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2023 
        THEN amount 
        ELSE 0 
    END) - SUM(CASE 
        WHEN scenario = 'Adopted Budget' 
            AND fiscal_year = 2023 
            AND financial_plan_year = 2022 
        THEN amount 
        ELSE 0 
    END) AS difference_2022_vs_actual,

    -- Percentage differences for each year
    CASE 
        WHEN SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2019 
            THEN amount 
            ELSE 0 
        END) <> 0 
        THEN (SUM(CASE 
            WHEN scenario = 'Actual' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2023 
            THEN amount 
            ELSE 0 
        END) - SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2019 
            THEN amount 
            ELSE 0 
        END)) / SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2019 
            THEN amount 
            ELSE 0 
        END)
        ELSE NULL 
    END AS percentage_diff_2019_vs_actual,

    CASE 
        WHEN SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2020 
            THEN amount 
            ELSE 0 
        END) <> 0 
        THEN (SUM(CASE 
            WHEN scenario = 'Actual' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2023 
            THEN amount 
            ELSE 0 
        END) - SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2020 
            THEN amount 
            ELSE 0 
        END)) / SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2020 
            THEN amount 
            ELSE 0 
        END)
        ELSE NULL 
    END AS percentage_diff_2020_vs_actual,

    CASE 
        WHEN SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2021 
            THEN amount 
            ELSE 0 
        END) <> 0 
        THEN (SUM(CASE 
            WHEN scenario = 'Actual' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2023 
            THEN amount 
            ELSE 0 
        END) - SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2021 
            THEN amount 
            ELSE 0 
        END)) / SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2021 
            THEN amount 
            ELSE 0 
        END)
        ELSE NULL 
    END AS percentage_diff_2021_vs_actual,

    CASE 
        WHEN SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2022 
            THEN amount 
            ELSE 0 
        END) <> 0 
        THEN (SUM(CASE 
            WHEN scenario = 'Actual' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2023 
            THEN amount 
            ELSE 0 
        END) - SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2022 
            THEN amount 
            ELSE 0 
        END)) / SUM(CASE 
            WHEN scenario = 'Adopted Budget' 
                AND fiscal_year = 2023 
                AND financial_plan_year = 2022 
            THEN amount 
            ELSE 0 
        END)
        ELSE NULL 
    END AS percentage_diff_2022_vs_actual

FROM "mtastats"."main"."mta_operations_statement"
WHERE type = 'Total Expenses Before Non-Cash Liability Adjs.'
GROUP BY agency_full_name, general_ledger, expense_type
    );
  
  
[0m05:25:06.244622 [debug] [Thread-9 (]: SQL status: OK in 0.032 seconds
[0m05:25:06.245356 [debug] [Thread-9 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:25:06.246043 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */

  
    
    

    create  table
      "mtastats"."main"."largest_expense_differences_2023__dbt_tmp"
  
    as (
      WITH expense_differences AS (
    SELECT
        agency,
        general_ledger,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) AS actual_expenses,
        SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS adopted_plan_expenses,
        SUM(CASE WHEN scenario = 'Actual' THEN amount ELSE 0 END) - SUM(CASE WHEN scenario = 'Adopted Budget' AND financial_plan_year = 2023 THEN amount ELSE 0 END) AS difference
    FROM
        "mtastats"."main"."mta_operations_statement"
    WHERE
        fiscal_year = 2023
        AND scenario IN ('Actual', 'Adopted Budget')
        AND financial_plan_year = 2023  -- Ensure we use only the 2023 Adopted Budget
        AND type = 'Total Expenses Before Non-Cash Liability Adjs.'
        AND general_ledger != 'Reimbursable Overhead'  -- Exclude Reimbursable Overhead
    GROUP BY
        agency, general_ledger
),
ranked_expenses AS (
    SELECT
        agency,
        general_ledger,
        actual_expenses,
        adopted_plan_expenses,
        difference,
        ROW_NUMBER() OVER (PARTITION BY agency ORDER BY difference DESC) AS rank
    FROM
        expense_differences
    WHERE
        difference > 0  -- Only include cases where actual expenses are larger than the adopted budget
)
SELECT
    agency,
    general_ledger,
    actual_expenses,
    adopted_plan_expenses,
    difference
FROM
    ranked_expenses
WHERE
    rank <= 5  -- Select the top 5 items per agency
ORDER BY
    difference, rank
    );
  
  
[0m05:25:06.251731 [debug] [Thread-8 (]: SQL status: OK in 0.037 seconds
[0m05:25:06.252570 [debug] [Thread-8 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:25:06.253289 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */

  
    
    

    create  table
      "mtastats"."main"."labor_expenses_per_agency__dbt_tmp"
  
    as (
      SELECT 
    agency,
    fiscal_year,
    expense_type,
    general_ledger,
    SUM(amount) AS total_labor_expenses
FROM 
    "mtastats"."main"."mta_operations_statement"
WHERE 
    subtype = 'Labor Expenses' AND 
    scenario = 'Actual'
GROUP BY 
    agency,
    fiscal_year,
    expense_type,
    general_ledger
ORDER BY 
    agency, fiscal_year, expense_type, general_ledger
    );
  
  
[0m05:25:06.254390 [debug] [Thread-10 ]: SQL status: OK in 0.038 seconds
[0m05:25:06.255386 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:25:06.256010 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_by_station__dbt_tmp"
  
    as (
      WITH yearly_data AS (
    SELECT 
        station_complex,
        YEAR(transit_timestamp) AS year,
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) * 1.0 / SUM(ridership) AS omny_percentage
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) IN (2022, 2023, 2024)
    GROUP BY 
        station_complex, 
        YEAR(transit_timestamp)
),
pivoted_data AS (
    SELECT 
        station_complex,
        MAX(CASE WHEN year = 2022 THEN omny_percentage ELSE NULL END) AS omny_2022,
        MAX(CASE WHEN year = 2023 THEN omny_percentage ELSE NULL END) AS omny_2023,
        MAX(CASE WHEN year = 2024 THEN omny_percentage ELSE NULL END) AS omny_2024
    FROM 
        yearly_data
    GROUP BY 
        station_complex
)
SELECT 
    station_complex,
    omny_2022,
    omny_2023,
    omny_2024,
    CASE 
        WHEN omny_2022 IS NOT NULL AND omny_2023 IS NOT NULL THEN 
            (omny_2023 - omny_2022) / omny_2022
        ELSE NULL
    END AS omny_2023_growth,
    CASE 
        WHEN omny_2023 IS NOT NULL AND omny_2024 IS NOT NULL THEN 
            (omny_2024 - omny_2023) / omny_2023
        ELSE NULL
    END AS omny_2024_growth
FROM 
    pivoted_data
ORDER BY 
    station_complex
    );
  
  
[0m05:25:06.261680 [debug] [Thread-12 ]: SQL status: OK in 0.044 seconds
[0m05:25:06.263038 [debug] [Thread-12 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:25:06.264461 [debug] [Thread-12 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */

  
    
    

    create  table
      "mtastats"."main"."subway_station_stats__dbt_tmp"
  
    as (
      WITH ridership_by_day AS (
    SELECT 
        station_complex,
        CAST(transit_timestamp AS DATE) AS day,
        DAYOFWEEK(transit_timestamp) AS weekday,
        SUM(ridership) AS daily_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        YEAR(transit_timestamp) = 2024
    GROUP BY 
        station_complex, 
        CAST(transit_timestamp AS DATE), 
        DAYOFWEEK(transit_timestamp)
),
weekday_weekend AS (
    SELECT 
        station_complex,
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END AS day_type,
        AVG(daily_ridership) AS avg_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex, 
        CASE 
            WHEN weekday IN (2, 3, 4, 5, 6) THEN 'weekday'
            ELSE 'weekend'
        END
),
single_day_stats AS (
    SELECT 
        station_complex,
        MAX(daily_ridership) AS highest_single_day_ridership,
        MIN(daily_ridership) AS lowest_single_day_ridership
    FROM 
        ridership_by_day
    GROUP BY 
        station_complex
),
highest_single_day AS (
    SELECT 
        station_complex,
        day AS highest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MAX(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
),
lowest_single_day AS (
    SELECT 
        station_complex,
        day AS lowest_single_day_ridership_day
    FROM 
        ridership_by_day rbd
    WHERE 
        rbd.daily_ridership = (
            SELECT 
                MIN(daily_ridership)
            FROM 
                ridership_by_day
            WHERE 
                station_complex = rbd.station_complex
        )
)
SELECT 
    rbd.station_complex,
    MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS avg_weekday_ridership,
    MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) AS avg_weekend_ridership,
    sds.highest_single_day_ridership,
    hsd.highest_single_day_ridership_day,
    sds.lowest_single_day_ridership,
    lsd.lowest_single_day_ridership_day,
    (MAX(CASE WHEN wwd.day_type = 'weekend' THEN wwd.avg_ridership END) - MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END)) * 1.0 / MAX(CASE WHEN wwd.day_type = 'weekday' THEN wwd.avg_ridership END) AS weekend_percentage_change
FROM 
    ridership_by_day rbd
JOIN 
    weekday_weekend wwd ON rbd.station_complex = wwd.station_complex
JOIN 
    single_day_stats sds ON rbd.station_complex = sds.station_complex
JOIN 
    highest_single_day hsd ON rbd.station_complex = hsd.station_complex
JOIN 
    lowest_single_day lsd ON rbd.station_complex = lsd.station_complex
GROUP BY 
    rbd.station_complex, 
    sds.highest_single_day_ridership, 
    sds.lowest_single_day_ridership, 
    hsd.highest_single_day_ridership_day, 
    lsd.lowest_single_day_ridership_day
ORDER BY 
    rbd.station_complex
    );
  
  
[0m05:25:06.267710 [debug] [Thread-11 ]: SQL status: OK in 0.049 seconds
[0m05:25:06.268275 [debug] [Thread-11 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:25:06.268870 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */

  
    
    

    create  table
      "mtastats"."main"."omny_adoption_increase__dbt_tmp"
  
    as (
      WITH omny_ridership_by_station_year AS (
    -- Calculate the OMNY ridership and total ridership for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        EXTRACT(YEAR FROM transit_timestamp) AS year, 
        SUM(CASE WHEN payment_method = 'omny' THEN ridership ELSE 0 END) AS omny_ridership,
        SUM(ridership) AS total_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    WHERE 
        EXTRACT(YEAR FROM transit_timestamp) IN (2023, 2024)
    GROUP BY 
        station_complex_id, station_complex, latitude, longitude, year
),
omny_percentage_by_station AS (
    -- Calculate the OMNY percentage for each station in 2023 and 2024, including latitude and longitude
    SELECT 
        station_complex_id, 
        station_complex, 
        latitude, 
        longitude, 
        year, 
        (omny_ridership / total_ridership) AS omny_percentage
    FROM 
        omny_ridership_by_station_year
)
SELECT 
    s2023.station_complex_id AS station_id, 
    s2023.station_complex AS station_name,
    s2023.latitude,
    s2023.longitude,
    s2023.omny_percentage AS omny_percentage_2023,
    s2024.omny_percentage AS omny_percentage_2024,
    (s2024.omny_percentage - s2023.omny_percentage) AS omny_percentage_increase
FROM 
    omny_percentage_by_station s2023
JOIN 
    omny_percentage_by_station s2024 
    ON s2023.station_complex_id = s2024.station_complex_id
    AND s2023.latitude = s2024.latitude
    AND s2023.longitude = s2024.longitude
    AND s2023.year = 2023
    AND s2024.year = 2024
WHERE 
    s2024.omny_percentage > s2023.omny_percentage
ORDER BY 
    omny_percentage_increase DESC
    );
  
  
[0m05:25:06.277764 [debug] [Thread-13 ]: SQL status: OK in 0.056 seconds
[0m05:25:06.278485 [debug] [Thread-13 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:25:06.279223 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."total_riders_per_station__dbt_tmp"
  
    as (
      SELECT 
    station_complex_id, 
    station_complex, 
    latitude, 
    longitude, 
    SUM(ridership) AS total_ridership
FROM 
    "mtastats"."main"."mta_hourly_subway_socrata"
GROUP BY 
    station_complex_id, station_complex, latitude, longitude
ORDER BY 
    total_ridership DESC
    );
  
  
[0m05:25:06.283852 [debug] [Thread-14 ]: SQL status: OK in 0.062 seconds
[0m05:25:06.284449 [debug] [Thread-14 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:25:06.284946 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */

  
    
    

    create  table
      "mtastats"."main"."weekly_riders_per_station__dbt_tmp"
  
    as (
      with weekly_ridership AS (
    SELECT 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp) AS week_start,
        SUM(ridership) AS total_weekly_ridership
    FROM 
        "mtastats"."main"."mta_hourly_subway_socrata"
    GROUP BY 
        station_complex, 
        DATE_TRUNC('week', transit_timestamp)
)
SELECT 
    station_complex, 
    week_start, 
    total_weekly_ridership
FROM 
    weekly_ridership
ORDER BY 
    station_complex, 
    week_start
    );
  
  
[0m05:25:06.326294 [debug] [Thread-4 (]: SQL status: OK in 0.092 seconds
[0m05:25:06.340873 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:25:06.341754 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
alter table "mtastats"."main"."daily_ridership__dbt_tmp" rename to "daily_ridership"
[0m05:25:06.343348 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m05:25:06.367365 [debug] [Thread-5 (]: SQL status: OK in 0.133 seconds
[0m05:25:06.384720 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:25:06.396461 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m05:25:06.397989 [debug] [Thread-8 (]: SQL status: OK in 0.144 seconds
[0m05:25:06.398790 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
alter table "mtastats"."main"."expense_type_per_year__dbt_tmp" rename to "expense_type_per_year"
[0m05:25:06.399354 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:25:06.404237 [debug] [Thread-8 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:25:06.405672 [debug] [Thread-4 (]: On model.mta.daily_ridership: COMMIT
[0m05:25:06.406321 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
alter table "mtastats"."main"."labor_expenses_per_agency__dbt_tmp" rename to "labor_expenses_per_agency"
[0m05:25:06.407775 [debug] [Thread-5 (]: SQL status: OK in 0.003 seconds
[0m05:25:06.409903 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m05:25:06.410508 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:25:06.411068 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: COMMIT
[0m05:25:06.411801 [debug] [Thread-8 (]: SQL status: OK in 0.005 seconds
[0m05:25:06.413669 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m05:25:06.414079 [debug] [Thread-8 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:25:06.414425 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: COMMIT
[0m05:25:06.435456 [debug] [Thread-4 (]: SQL status: OK in 0.028 seconds
[0m05:25:06.448077 [debug] [Thread-4 (]: Using duckdb connection "model.mta.daily_ridership"
[0m05:25:06.448871 [debug] [Thread-4 (]: On model.mta.daily_ridership: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.daily_ridership"} */
drop table if exists "mtastats"."main"."daily_ridership__dbt_backup" cascade
[0m05:25:06.451239 [debug] [Thread-5 (]: SQL status: OK in 0.040 seconds
[0m05:25:06.465809 [debug] [Thread-5 (]: Using duckdb connection "model.mta.expense_type_per_year"
[0m05:25:06.466882 [debug] [Thread-8 (]: SQL status: OK in 0.052 seconds
[0m05:25:06.467554 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.expense_type_per_year"} */
drop table if exists "mtastats"."main"."expense_type_per_year__dbt_backup" cascade
[0m05:25:06.468309 [debug] [Thread-9 (]: SQL status: OK in 0.222 seconds
[0m05:25:06.485424 [debug] [Thread-8 (]: Using duckdb connection "model.mta.labor_expenses_per_agency"
[0m05:25:06.487341 [debug] [Thread-4 (]: SQL status: OK in 0.037 seconds
[0m05:25:06.502943 [debug] [Thread-9 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:25:06.503639 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.labor_expenses_per_agency"} */
drop table if exists "mtastats"."main"."labor_expenses_per_agency__dbt_backup" cascade
[0m05:25:06.511819 [debug] [Thread-4 (]: On model.mta.daily_ridership: Close
[0m05:25:06.512579 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
alter table "mtastats"."main"."largest_expense_differences_2023__dbt_tmp" rename to "largest_expense_differences_2023"
[0m05:25:06.514489 [debug] [Thread-5 (]: SQL status: OK in 0.027 seconds
[0m05:25:06.517592 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56df90>]}
[0m05:25:06.521624 [debug] [Thread-5 (]: On model.mta.expense_type_per_year: Close
[0m05:25:06.522131 [debug] [Thread-8 (]: SQL status: OK in 0.007 seconds
[0m05:25:06.524037 [debug] [Thread-9 (]: SQL status: OK in 0.006 seconds
[0m05:25:06.523165 [info ] [Thread-4 (]: 4 of 14 OK created sql table model main.daily_ridership ........................ [[32mOK[0m in 0.52s]
[0m05:25:06.525199 [debug] [Thread-5 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56c9a0>]}
[0m05:25:06.526851 [debug] [Thread-8 (]: On model.mta.labor_expenses_per_agency: Close
[0m05:25:06.528767 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m05:25:06.529640 [debug] [Thread-4 (]: Finished running node model.mta.daily_ridership
[0m05:25:06.530621 [info ] [Thread-5 (]: 5 of 14 OK created sql table model main.expense_type_per_year .................. [[32mOK[0m in 0.52s]
[0m05:25:06.531912 [debug] [Thread-8 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56d270>]}
[0m05:25:06.532678 [debug] [Thread-9 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:25:06.534034 [debug] [Thread-5 (]: Finished running node model.mta.expense_type_per_year
[0m05:25:06.534879 [info ] [Thread-8 (]: 8 of 14 OK created sql table model main.labor_expenses_per_agency .............. [[32mOK[0m in 0.51s]
[0m05:25:06.535581 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: COMMIT
[0m05:25:06.537130 [debug] [Thread-8 (]: Finished running node model.mta.labor_expenses_per_agency
[0m05:25:06.543595 [debug] [Thread-9 (]: SQL status: OK in 0.005 seconds
[0m05:25:06.555886 [debug] [Thread-9 (]: Using duckdb connection "model.mta.largest_expense_differences_2023"
[0m05:25:06.557664 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.largest_expense_differences_2023"} */
drop table if exists "mtastats"."main"."largest_expense_differences_2023__dbt_backup" cascade
[0m05:25:06.562935 [debug] [Thread-9 (]: SQL status: OK in 0.003 seconds
[0m05:25:06.569612 [debug] [Thread-9 (]: On model.mta.largest_expense_differences_2023: Close
[0m05:25:06.570633 [debug] [Thread-9 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f579ff0>]}
[0m05:25:06.571564 [info ] [Thread-9 (]: 9 of 14 OK created sql table model main.largest_expense_differences_2023 ....... [[32mOK[0m in 0.54s]
[0m05:25:06.572356 [debug] [Thread-9 (]: Finished running node model.mta.largest_expense_differences_2023
[0m05:25:06.810417 [debug] [Thread-7 (]: SQL status: OK in 0.568 seconds
[0m05:25:06.836719 [debug] [Thread-7 (]: Using duckdb connection "model.mta.forecast_accuracy_2023"
[0m05:25:06.837604 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.forecast_accuracy_2023"} */
alter table "mtastats"."main"."forecast_accuracy_2023__dbt_tmp" rename to "forecast_accuracy_2023"
[0m05:25:06.838912 [debug] [Thread-7 (]: SQL status: OK in 0.001 seconds
[0m05:25:06.849690 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: COMMIT
[0m05:25:06.850348 [debug] [Thread-7 (]: Using duckdb connection "model.mta.forecast_accuracy_2023"
[0m05:25:06.850810 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: COMMIT
[0m05:25:06.856929 [debug] [Thread-7 (]: SQL status: OK in 0.006 seconds
[0m05:25:06.864821 [debug] [Thread-2 (]: SQL status: OK in 0.634 seconds
[0m05:25:06.871239 [debug] [Thread-7 (]: Using duckdb connection "model.mta.forecast_accuracy_2023"
[0m05:25:06.883029 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:25:06.883701 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.forecast_accuracy_2023"} */
drop table if exists "mtastats"."main"."forecast_accuracy_2023__dbt_backup" cascade
[0m05:25:06.884427 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
alter table "mtastats"."main"."bond_payment_info__dbt_tmp" rename to "bond_payment_info"
[0m05:25:06.887264 [debug] [Thread-7 (]: SQL status: OK in 0.002 seconds
[0m05:25:06.889247 [debug] [Thread-7 (]: On model.mta.forecast_accuracy_2023: Close
[0m05:25:06.890067 [debug] [Thread-2 (]: SQL status: OK in 0.004 seconds
[0m05:25:06.890896 [debug] [Thread-7 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f3fd780>]}
[0m05:25:06.892921 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m05:25:06.894020 [info ] [Thread-7 (]: 7 of 14 OK created sql table model main.forecast_accuracy_2023 ................. [[32mOK[0m in 0.87s]
[0m05:25:06.894689 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:25:06.895476 [debug] [Thread-7 (]: Finished running node model.mta.forecast_accuracy_2023
[0m05:25:06.896167 [debug] [Thread-2 (]: On model.mta.bond_payment_info: COMMIT
[0m05:25:06.902529 [debug] [Thread-2 (]: SQL status: OK in 0.005 seconds
[0m05:25:06.906763 [debug] [Thread-2 (]: Using duckdb connection "model.mta.bond_payment_info"
[0m05:25:06.907394 [debug] [Thread-2 (]: On model.mta.bond_payment_info: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.bond_payment_info"} */
drop table if exists "mtastats"."main"."bond_payment_info__dbt_backup" cascade
[0m05:25:06.909618 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m05:25:06.911545 [debug] [Thread-2 (]: On model.mta.bond_payment_info: Close
[0m05:25:06.912513 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3a92ace0>]}
[0m05:25:06.913595 [info ] [Thread-2 (]: 2 of 14 OK created sql table model main.bond_payment_info ...................... [[32mOK[0m in 0.93s]
[0m05:25:06.914992 [debug] [Thread-2 (]: Finished running node model.mta.bond_payment_info
[0m05:25:10.921067 [debug] [Thread-1 (]: SQL status: OK in 4.674 seconds
[0m05:25:10.953096 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:25:10.954219 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
alter table "mtastats"."main"."avg_riders_per_day__dbt_tmp" rename to "avg_riders_per_day"
[0m05:25:10.973118 [debug] [Thread-1 (]: SQL status: OK in 0.017 seconds
[0m05:25:10.976885 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m05:25:10.977643 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:25:10.978202 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: COMMIT
[0m05:25:10.994148 [debug] [Thread-1 (]: SQL status: OK in 0.014 seconds
[0m05:25:10.998518 [debug] [Thread-1 (]: Using duckdb connection "model.mta.avg_riders_per_day"
[0m05:25:10.999388 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.avg_riders_per_day"} */
drop table if exists "mtastats"."main"."avg_riders_per_day__dbt_backup" cascade
[0m05:25:11.000778 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m05:25:11.004419 [debug] [Thread-1 (]: On model.mta.avg_riders_per_day: Close
[0m05:25:11.006354 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56c1f0>]}
[0m05:25:11.021820 [info ] [Thread-1 (]: 1 of 14 OK created sql table model main.avg_riders_per_day ..................... [[32mOK[0m in 5.02s]
[0m05:25:11.027379 [debug] [Thread-1 (]: Finished running node model.mta.avg_riders_per_day
[0m05:25:11.878341 [debug] [Thread-3 (]: SQL status: OK in 5.648 seconds
[0m05:25:11.884622 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:25:11.886277 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
alter table "mtastats"."main"."busiest_specific_times__dbt_tmp" rename to "busiest_specific_times"
[0m05:25:11.904010 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m05:25:11.907850 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m05:25:11.908871 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:25:11.909685 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: COMMIT
[0m05:25:11.915245 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m05:25:11.923758 [debug] [Thread-3 (]: Using duckdb connection "model.mta.busiest_specific_times"
[0m05:25:11.925872 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.busiest_specific_times"} */
drop table if exists "mtastats"."main"."busiest_specific_times__dbt_backup" cascade
[0m05:25:11.927530 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m05:25:11.930958 [debug] [Thread-3 (]: On model.mta.busiest_specific_times: Close
[0m05:25:11.932395 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56e530>]}
[0m05:25:11.933899 [info ] [Thread-3 (]: 3 of 14 OK created sql table model main.busiest_specific_times ................. [[32mOK[0m in 5.95s]
[0m05:25:11.935500 [debug] [Thread-3 (]: Finished running node model.mta.busiest_specific_times
[0m05:25:17.084499 [debug] [Thread-14 ]: SQL status: OK in 10.799 seconds
[0m05:25:17.112943 [debug] [Thread-14 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:25:17.120415 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
alter table "mtastats"."main"."weekly_riders_per_station__dbt_tmp" rename to "weekly_riders_per_station"
[0m05:25:17.122064 [debug] [Thread-14 ]: SQL status: OK in 0.001 seconds
[0m05:25:17.125232 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m05:25:17.126120 [debug] [Thread-14 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:25:17.126763 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: COMMIT
[0m05:25:17.273643 [debug] [Thread-14 ]: SQL status: OK in 0.146 seconds
[0m05:25:17.280968 [debug] [Thread-14 ]: Using duckdb connection "model.mta.weekly_riders_per_station"
[0m05:25:17.281819 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.weekly_riders_per_station"} */
drop table if exists "mtastats"."main"."weekly_riders_per_station__dbt_backup" cascade
[0m05:25:17.282920 [debug] [Thread-14 ]: SQL status: OK in 0.000 seconds
[0m05:25:17.286983 [debug] [Thread-14 ]: On model.mta.weekly_riders_per_station: Close
[0m05:25:17.310781 [debug] [Thread-14 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f579ba0>]}
[0m05:25:17.312497 [info ] [Thread-14 ]: 14 of 14 OK created sql table model main.weekly_riders_per_station ............. [[32mOK[0m in 11.27s]
[0m05:25:17.313945 [debug] [Thread-14 ]: Finished running node model.mta.weekly_riders_per_station
[0m05:25:17.895249 [debug] [Thread-11 ]: SQL status: OK in 11.625 seconds
[0m05:25:17.922727 [debug] [Thread-11 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:25:17.923535 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
alter table "mtastats"."main"."omny_adoption_increase__dbt_tmp" rename to "omny_adoption_increase"
[0m05:25:17.924774 [debug] [Thread-11 ]: SQL status: OK in 0.001 seconds
[0m05:25:17.927470 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: COMMIT
[0m05:25:17.928128 [debug] [Thread-11 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:25:17.928770 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: COMMIT
[0m05:25:17.935531 [debug] [Thread-11 ]: SQL status: OK in 0.006 seconds
[0m05:25:17.941889 [debug] [Thread-11 ]: Using duckdb connection "model.mta.omny_adoption_increase"
[0m05:25:17.942939 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_increase"} */
drop table if exists "mtastats"."main"."omny_adoption_increase__dbt_backup" cascade
[0m05:25:17.944393 [debug] [Thread-11 ]: SQL status: OK in 0.001 seconds
[0m05:25:17.947247 [debug] [Thread-11 ]: On model.mta.omny_adoption_increase: Close
[0m05:25:17.948499 [debug] [Thread-11 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb4b755990>]}
[0m05:25:17.970418 [info ] [Thread-11 ]: 11 of 14 OK created sql table model main.omny_adoption_increase ................ [[32mOK[0m in 11.92s]
[0m05:25:17.971704 [debug] [Thread-11 ]: Finished running node model.mta.omny_adoption_increase
[0m05:25:17.979375 [debug] [Thread-10 ]: SQL status: OK in 11.722 seconds
[0m05:25:17.987217 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:25:17.988169 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
alter table "mtastats"."main"."omny_adoption_by_station__dbt_tmp" rename to "omny_adoption_by_station"
[0m05:25:18.001990 [debug] [Thread-10 ]: SQL status: OK in 0.001 seconds
[0m05:25:18.022389 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: COMMIT
[0m05:25:18.024084 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:25:18.025713 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: COMMIT
[0m05:25:18.039647 [debug] [Thread-10 ]: SQL status: OK in 0.013 seconds
[0m05:25:18.044217 [debug] [Thread-10 ]: Using duckdb connection "model.mta.omny_adoption_by_station"
[0m05:25:18.060296 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.omny_adoption_by_station"} */
drop table if exists "mtastats"."main"."omny_adoption_by_station__dbt_backup" cascade
[0m05:25:18.061761 [debug] [Thread-10 ]: SQL status: OK in 0.000 seconds
[0m05:25:18.064035 [debug] [Thread-10 ]: On model.mta.omny_adoption_by_station: Close
[0m05:25:18.065029 [debug] [Thread-10 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f57a1d0>]}
[0m05:25:18.066013 [info ] [Thread-10 ]: 10 of 14 OK created sql table model main.omny_adoption_by_station .............. [[32mOK[0m in 12.03s]
[0m05:25:18.066929 [debug] [Thread-10 ]: Finished running node model.mta.omny_adoption_by_station
[0m05:25:18.173511 [debug] [Thread-12 ]: SQL status: OK in 11.907 seconds
[0m05:25:18.179530 [debug] [Thread-12 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:25:18.180667 [debug] [Thread-12 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
alter table "mtastats"."main"."subway_station_stats__dbt_tmp" rename to "subway_station_stats"
[0m05:25:18.182229 [debug] [Thread-12 ]: SQL status: OK in 0.001 seconds
[0m05:25:18.186444 [debug] [Thread-12 ]: On model.mta.subway_station_stats: COMMIT
[0m05:25:18.187485 [debug] [Thread-12 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:25:18.188421 [debug] [Thread-12 ]: On model.mta.subway_station_stats: COMMIT
[0m05:25:18.235878 [debug] [Thread-12 ]: SQL status: OK in 0.028 seconds
[0m05:25:18.240889 [debug] [Thread-12 ]: Using duckdb connection "model.mta.subway_station_stats"
[0m05:25:18.241696 [debug] [Thread-12 ]: On model.mta.subway_station_stats: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.subway_station_stats"} */
drop table if exists "mtastats"."main"."subway_station_stats__dbt_backup" cascade
[0m05:25:18.242925 [debug] [Thread-12 ]: SQL status: OK in 0.000 seconds
[0m05:25:18.245192 [debug] [Thread-12 ]: On model.mta.subway_station_stats: Close
[0m05:25:18.246101 [debug] [Thread-12 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56cb50>]}
[0m05:25:18.247085 [info ] [Thread-12 ]: 12 of 14 OK created sql table model main.subway_station_stats .................. [[32mOK[0m in 12.21s]
[0m05:25:18.247995 [debug] [Thread-12 ]: Finished running node model.mta.subway_station_stats
[0m05:25:19.114724 [debug] [Thread-13 ]: SQL status: OK in 12.835 seconds
[0m05:25:19.121144 [debug] [Thread-13 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:25:19.122138 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
alter table "mtastats"."main"."total_riders_per_station__dbt_tmp" rename to "total_riders_per_station"
[0m05:25:19.123435 [debug] [Thread-13 ]: SQL status: OK in 0.001 seconds
[0m05:25:19.127783 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: COMMIT
[0m05:25:19.129038 [debug] [Thread-13 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:25:19.130505 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: COMMIT
[0m05:25:19.150237 [debug] [Thread-13 ]: SQL status: OK in 0.019 seconds
[0m05:25:19.154906 [debug] [Thread-13 ]: Using duckdb connection "model.mta.total_riders_per_station"
[0m05:25:19.155747 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.total_riders_per_station"} */
drop table if exists "mtastats"."main"."total_riders_per_station__dbt_backup" cascade
[0m05:25:19.158921 [debug] [Thread-13 ]: SQL status: OK in 0.002 seconds
[0m05:25:19.162021 [debug] [Thread-13 ]: On model.mta.total_riders_per_station: Close
[0m05:25:19.163458 [debug] [Thread-13 ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc2f56ce20>]}
[0m05:25:19.166429 [info ] [Thread-13 ]: 13 of 14 OK created sql table model main.total_riders_per_station .............. [[32mOK[0m in 13.13s]
[0m05:25:19.167843 [debug] [Thread-13 ]: Finished running node model.mta.total_riders_per_station
[0m05:25:19.240229 [debug] [Thread-6 (]: SQL status: OK in 13.003 seconds
[0m05:25:19.245286 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:25:19.245782 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
alter table "mtastats"."main"."fare_class_boro__dbt_tmp" rename to "fare_class_boro"
[0m05:25:19.246816 [debug] [Thread-6 (]: SQL status: OK in 0.001 seconds
[0m05:25:19.248307 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m05:25:19.248678 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:25:19.249021 [debug] [Thread-6 (]: On model.mta.fare_class_boro: COMMIT
[0m05:25:19.256151 [debug] [Thread-6 (]: SQL status: OK in 0.007 seconds
[0m05:25:19.258646 [debug] [Thread-6 (]: Using duckdb connection "model.mta.fare_class_boro"
[0m05:25:19.259070 [debug] [Thread-6 (]: On model.mta.fare_class_boro: /* {"app": "dbt", "dbt_version": "1.8.7", "profile_name": "default", "target_name": "dev", "node_id": "model.mta.fare_class_boro"} */
drop table if exists "mtastats"."main"."fare_class_boro__dbt_backup" cascade
[0m05:25:19.259892 [debug] [Thread-6 (]: SQL status: OK in 0.000 seconds
[0m05:25:19.261120 [debug] [Thread-6 (]: On model.mta.fare_class_boro: Close
[0m05:25:19.383608 [debug] [Thread-6 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35beca91-1b5b-4899-aa82-f6b59aabe584', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb4b769210>]}
[0m05:25:19.384488 [info ] [Thread-6 (]: 6 of 14 OK created sql table model main.fare_class_boro ........................ [[32mOK[0m in 13.38s]
[0m05:25:19.385089 [debug] [Thread-6 (]: Finished running node model.mta.fare_class_boro
[0m05:25:19.390657 [debug] [MainThread]: Using duckdb connection "master"
[0m05:25:19.391037 [debug] [MainThread]: On master: BEGIN
[0m05:25:19.391287 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m05:25:19.406588 [debug] [MainThread]: SQL status: OK in 0.015 seconds
[0m05:25:19.407096 [debug] [MainThread]: On master: COMMIT
[0m05:25:19.407437 [debug] [MainThread]: Using duckdb connection "master"
[0m05:25:19.407705 [debug] [MainThread]: On master: COMMIT
[0m05:25:19.408286 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m05:25:19.408589 [debug] [MainThread]: On master: Close
[0m05:25:19.410928 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:19.411265 [debug] [MainThread]: Connection 'model.mta.expense_type_per_year' was properly closed.
[0m05:25:19.411578 [debug] [MainThread]: Connection 'model.mta.avg_riders_per_day' was properly closed.
[0m05:25:19.411817 [debug] [MainThread]: Connection 'model.mta.bond_payment_info' was properly closed.
[0m05:25:19.412049 [debug] [MainThread]: Connection 'model.mta.busiest_specific_times' was properly closed.
[0m05:25:19.412265 [debug] [MainThread]: Connection 'model.mta.daily_ridership' was properly closed.
[0m05:25:19.412472 [debug] [MainThread]: Connection 'model.mta.fare_class_boro' was properly closed.
[0m05:25:19.412687 [debug] [MainThread]: Connection 'model.mta.forecast_accuracy_2023' was properly closed.
[0m05:25:19.412881 [debug] [MainThread]: Connection 'model.mta.labor_expenses_per_agency' was properly closed.
[0m05:25:19.413095 [debug] [MainThread]: Connection 'model.mta.largest_expense_differences_2023' was properly closed.
[0m05:25:19.413298 [debug] [MainThread]: Connection 'model.mta.omny_adoption_by_station' was properly closed.
[0m05:25:19.413489 [debug] [MainThread]: Connection 'model.mta.omny_adoption_increase' was properly closed.
[0m05:25:19.413697 [debug] [MainThread]: Connection 'model.mta.subway_station_stats' was properly closed.
[0m05:25:19.413915 [debug] [MainThread]: Connection 'model.mta.total_riders_per_station' was properly closed.
[0m05:25:19.414111 [debug] [MainThread]: Connection 'model.mta.weekly_riders_per_station' was properly closed.
[0m05:25:19.414680 [info ] [MainThread]: 
[0m05:25:19.415039 [info ] [MainThread]: Finished running 14 table models in 0 hours 0 minutes and 13.67 seconds (13.67s).
[0m05:25:19.417014 [debug] [MainThread]: Command end result
[0m05:25:19.453994 [info ] [MainThread]: 
[0m05:25:19.455306 [info ] [MainThread]: [32mCompleted successfully[0m
[0m05:25:19.456222 [info ] [MainThread]: 
[0m05:25:19.458321 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m05:25:19.462109 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.547945, "process_user_time": 144.40848, "process_kernel_time": 29.051752, "process_mem_max_rss": "798136", "process_in_blocks": "288", "process_out_blocks": "17608"}
[0m05:25:19.462824 [debug] [MainThread]: Command `dbt run` succeeded at 05:25:19.462698 after 14.55 seconds
[0m05:25:19.463260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3c323400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcb4b7230d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3b62e800>]}
[0m05:25:19.463669 [debug] [MainThread]: Flushing usage events
