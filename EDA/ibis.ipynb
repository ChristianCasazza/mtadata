{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import duckdb\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, PartialCredentialsError\n",
    "from dotenv import load_dotenv\n",
    "import urllib.parse\n",
    "\n",
    "class DataSharingClient:\n",
    "    def __init__(self, duckdb_region=None, username=None, password=None, use_auth=False, debug=False, duckdb_path=None):\n",
    "        self.debug = debug  # Set the debug flag\n",
    "        self.use_auth = use_auth  # Control whether authentication is needed\n",
    "\n",
    "        # Load environment variables from the .env file\n",
    "        load_dotenv()\n",
    "\n",
    "        # Retrieve credentials from environment variables if not provided\n",
    "        self.username = username or os.getenv(\"OCEAN_USERNAME\")\n",
    "        self.password = password or os.getenv(\"OCEAN_PASSWORD\")\n",
    "\n",
    "        if self.use_auth and (not self.username or not self.password):\n",
    "            raise ValueError(\"Username and password must be provided either as arguments or in the .env file if use_auth is True\")\n",
    "\n",
    "        self.config = {\n",
    "            \"region\": \"us-east-1\",  # Default region for Cognito\n",
    "            \"duckdb_region\": duckdb_region or \"us-east-1\",  # Default to us-east-1 if not specified\n",
    "            \"userPoolId\": \"your_user_pool_id\",  # Placeholder: Replace with your Cognito User Pool ID\n",
    "            \"clientId\": \"your_client_id\",       # Placeholder: Replace with your Cognito App Client ID\n",
    "            \"identityPoolId\": \"your_identity_pool_id\",  # Placeholder: Replace with your Cognito Identity Pool ID\n",
    "            \"bucketName\": \"your_bucket_name\"    # Placeholder: Replace with your S3 bucket name\n",
    "        }\n",
    "        self.id_token = None\n",
    "        self.access_token = None\n",
    "        self.refresh_token = None\n",
    "        self.temporary_credentials = None\n",
    "        self.conn = None\n",
    "        self.s3_client = None\n",
    "        self.cognito_identity_client = None\n",
    "        self.duckdb_path = duckdb_path  # Path for persistent DuckDB database\n",
    "\n",
    "        # Only authenticate if use_auth is True\n",
    "        if self.use_auth:\n",
    "            self.authenticate_user()\n",
    "            self.obtain_temporary_credentials()\n",
    "\n",
    "        self.setup_duckdb()\n",
    "\n",
    "        if not self.debug:\n",
    "            print(\"It's data time!\")\n",
    "            print(f'You can query datasets in the \"{self.config[\"duckdb_region\"]}\" region')\n",
    "\n",
    "    def authenticate_user(self):\n",
    "        auth_url = f\"https://cognito-idp.{self.config['region']}.amazonaws.com/\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/x-amz-json-1.1\",\n",
    "            \"X-Amz-Target\": \"AWSCognitoIdentityProviderService.InitiateAuth\"\n",
    "        }\n",
    "        auth_data = {\n",
    "            \"AuthParameters\": {\n",
    "                \"USERNAME\": self.username,\n",
    "                \"PASSWORD\": self.password\n",
    "            },\n",
    "            \"AuthFlow\": \"USER_PASSWORD_AUTH\",\n",
    "            \"ClientId\": self.config[\"clientId\"]\n",
    "        }\n",
    "\n",
    "        response = requests.post(auth_url, headers=headers, json=auth_data)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if 'ChallengeName' in response_data and response_data['ChallengeName'] == 'SOFTWARE_TOKEN_MFA':\n",
    "                mfa_code = input(\"Enter the MFA code from your authenticator app: \")\n",
    "                self.respond_to_auth_challenge(response_data['Session'], mfa_code)\n",
    "            else:\n",
    "                self.id_token = response_data[\"AuthenticationResult\"][\"IdToken\"]\n",
    "                self.access_token = response_data[\"AuthenticationResult\"][\"AccessToken\"]\n",
    "                self.refresh_token = response_data[\"AuthenticationResult\"][\"RefreshToken\"]\n",
    "                if self.debug:\n",
    "                    print(\"Authentication successful.\")\n",
    "        else:\n",
    "            print(\"Authentication failed:\", response_data)\n",
    "\n",
    "    def respond_to_auth_challenge(self, session, mfa_code):\n",
    "        auth_url = f\"https://cognito-idp.{self.config['region']}.amazonaws.com/\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/x-amz-json-1.1\",\n",
    "            \"X-Amz-Target\": \"AWSCognitoIdentityProviderService.RespondToAuthChallenge\"\n",
    "        }\n",
    "        challenge_data = {\n",
    "            \"ChallengeName\": \"SOFTWARE_TOKEN_MFA\",\n",
    "            \"ClientId\": self.config[\"clientId\"],\n",
    "            \"Session\": session,\n",
    "            \"ChallengeResponses\": {\n",
    "                \"USERNAME\": self.username,\n",
    "                \"SOFTWARE_TOKEN_MFA_CODE\": mfa_code\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(auth_url, headers=headers, json=challenge_data)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            self.id_token = response_data[\"AuthenticationResult\"][\"IdToken\"]\n",
    "            self.access_token = response_data[\"AuthenticationResult\"][\"AccessToken\"]\n",
    "            self.refresh_token = response_data[\"AuthenticationResult\"][\"RefreshToken\"]\n",
    "            if self.debug:\n",
    "                print(\"MFA authentication successful.\")\n",
    "        else:\n",
    "            print(\"MFA authentication failed:\", response_data)\n",
    "\n",
    "    def obtain_temporary_credentials(self):\n",
    "        if not self.cognito_identity_client:\n",
    "            self.cognito_identity_client = boto3.client('cognito-identity', region_name=self.config[\"region\"])\n",
    "\n",
    "        logins = {\n",
    "            f'cognito-idp.{self.config[\"region\"]}.amazonaws.com/{self.config[\"userPoolId\"]}': self.id_token\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            if self.debug:\n",
    "                print(\"Getting identity ID...\")\n",
    "            response = self.cognito_identity_client.get_id(\n",
    "                IdentityPoolId=self.config[\"identityPoolId\"],\n",
    "                Logins=logins\n",
    "            )\n",
    "            identity_id = response['IdentityId']\n",
    "            if self.debug:\n",
    "                print(f\"Identity ID obtained: {identity_id}\")\n",
    "\n",
    "            if self.debug:\n",
    "                print(\"Getting OpenID token...\")\n",
    "            open_id_response = self.cognito_identity_client.get_open_id_token(\n",
    "                IdentityId=identity_id,\n",
    "                Logins=logins\n",
    "            )\n",
    "            open_id_token = open_id_response['Token']\n",
    "            if self.debug:\n",
    "                print(\"OpenID token obtained.\")\n",
    "\n",
    "            if self.debug:\n",
    "                print(\"Getting credentials for identity...\")\n",
    "            credentials_response = self.cognito_identity_client.get_credentials_for_identity(\n",
    "                IdentityId=identity_id,\n",
    "                Logins=logins\n",
    "            )\n",
    "\n",
    "            self.temporary_credentials = credentials_response['Credentials']\n",
    "            if self.debug:\n",
    "                print(\"Temporary credentials obtained.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error obtaining temporary credentials: {e}\")\n",
    "\n",
    "        self.s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=self.temporary_credentials['AccessKeyId'],\n",
    "            aws_secret_access_key=self.temporary_credentials['SecretKey'],\n",
    "            aws_session_token=self.temporary_credentials['SessionToken'],\n",
    "            region_name=self.config[\"duckdb_region\"]\n",
    "        )\n",
    "\n",
    "    def setup_duckdb(self):\n",
    "        if self.duckdb_path:\n",
    "            # Use an existing DuckDB file or create a new one at the specified path\n",
    "            self.conn = duckdb.connect(database=self.duckdb_path, read_only=False)\n",
    "        else:\n",
    "            # Use an in-memory DuckDB instance\n",
    "            self.conn = duckdb.connect(database=':memory:', read_only=False)\n",
    "\n",
    "        self.conn.execute(\"INSTALL httpfs;\")\n",
    "        self.conn.execute(\"LOAD httpfs;\")\n",
    "        self.conn.execute(f\"SET s3_region='{self.config['duckdb_region']}';\")\n",
    "\n",
    "        if self.use_auth:\n",
    "            self.conn.execute(f\"SET s3_access_key_id='{self.temporary_credentials['AccessKeyId']}';\")\n",
    "            self.conn.execute(f\"SET s3_secret_access_key='{self.temporary_credentials['SecretKey']}';\")\n",
    "            self.conn.execute(f\"SET s3_session_token='{self.temporary_credentials['SessionToken']}';\")\n",
    "        else:\n",
    "            # If not using auth, clear any existing AWS credentials in DuckDB settings\n",
    "            self.conn.execute(\"SET s3_access_key_id='';\")\n",
    "            self.conn.execute(\"SET s3_secret_access_key='';\")\n",
    "            self.conn.execute(\"SET s3_session_token='';\")\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"DuckDB setup complete.\")\n",
    "\n",
    "    def create_views(self, paths, table_names):\n",
    "        # Ensure paths and table_names are lists of the same length\n",
    "        if len(paths) != len(table_names):\n",
    "            raise ValueError(\"The number of paths and table names must be the same.\")\n",
    "        \n",
    "        # Loop through each path and create a corresponding view\n",
    "        for path, table_name in zip(paths, table_names):\n",
    "            if path.startswith(\"s3://\"):\n",
    "                if not self.use_auth:\n",
    "                    raise ValueError(\"Authentication required for S3 access. Initialize with use_auth=True.\")\n",
    "                self._create_view_from_s3(path, table_name)\n",
    "            else:\n",
    "                self._create_view_from_local(path, table_name)\n",
    "            print(f\"View {table_name} created from {path}.\")\n",
    "\n",
    "\n",
    "    def _create_view_from_s3(self, s3_path, view_name):\n",
    "        file_extension = s3_path.split('.')[-1].lower()\n",
    "\n",
    "        if file_extension == \"csv\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_csv_auto('{s3_path}')\"\n",
    "        elif file_extension == \"parquet\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_parquet('{s3_path}')\"\n",
    "        elif file_extension == \"json\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_json_auto('{s3_path}')\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "        self.conn.execute(query)\n",
    "\n",
    "    def _create_view_from_local(self, file_path, view_name):\n",
    "        file_extension = file_path.split('.')[-1].lower()\n",
    "\n",
    "        if file_extension == \"csv\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_csv_auto('{file_path}')\"\n",
    "        elif file_extension == \"parquet\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_parquet('{file_path}')\"\n",
    "        elif file_extension == \"json\":\n",
    "            query = f\"CREATE VIEW {view_name} AS SELECT * FROM read_json_auto('{file_path}')\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
    "\n",
    "        self.conn.execute(query)\n",
    "\n",
    "    def query(self, query, new_table_name=None):\n",
    "        if new_table_name:\n",
    "            self.conn.execute(f\"CREATE TABLE {new_table_name} AS {query}\")\n",
    "            print(f\"Table {new_table_name} created from query.\")\n",
    "        else:\n",
    "            result_df = self.conn.execute(query).fetchdf()\n",
    "            if self.debug:\n",
    "                print(f\"Query executed: {query}\")\n",
    "            return result_df\n",
    "\n",
    "    def list_tables(self):\n",
    "        query = \"\"\"\n",
    "        SELECT table_name, table_type \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema='main'\n",
    "        \"\"\"\n",
    "        tables = self.conn.execute(query).fetchall()\n",
    "        return tables\n",
    "\n",
    "    def export_tables(self, table_names, output_dir, file_format):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        if file_format in [\"parquet\", \"csv\"]:\n",
    "            for table_name in table_names:\n",
    "                file_name = f\"{table_name}.{file_format}\"\n",
    "                file_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "                if file_format == \"parquet\":\n",
    "                    self.conn.execute(\n",
    "                        f\"COPY (SELECT * FROM {table_name}) TO '{file_path}' (FORMAT 'parquet')\"\n",
    "                    )\n",
    "                elif file_format == \"csv\":\n",
    "                    self.conn.execute(\n",
    "                        f\"COPY (SELECT * FROM {table_name}) TO '{file_path}' (HEADER, DELIMITER ',')\"\n",
    "                    )\n",
    "                print(f\"Table {table_name} exported to {file_path}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {file_format}\")\n",
    "\n",
    "    def download_dataset(self, s3_uri, local_path):\n",
    "        if not self.use_auth:\n",
    "            raise ValueError(\"Authentication required for S3 access. Initialize with use_auth=True.\")\n",
    "\n",
    "        parsed_url = urllib.parse.urlparse(s3_uri)\n",
    "        bucket_name = parsed_url.netloc\n",
    "        object_key = parsed_url.path.lstrip('/')\n",
    "\n",
    "        try:\n",
    "            self.s3_client.download_file(bucket_name, object_key, local_path)\n",
    "            print(f\"Downloaded {s3_uri} to {local_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB setup complete.\n"
     ]
    }
   ],
   "source": [
    "client = DataSharingClient(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View nfl created from /home/christianocean/quiv/nfl.parquet.\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "  \n",
    "    \"/home/christianocean/quiv/nfl.parquet\",\n",
    "    #\"/home/christianocean/oceandatachallengesdemo/data/samples/normalized_taxi_trips.json\"\n",
    "]\n",
    "\n",
    "# Generate the corresponding table names\n",
    "table_names = [\n",
    "    \"nfl\",\n",
    "]\n",
    "\n",
    "client.create_views(paths, table_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed: \n",
      "\n",
      "SELECT count(*) from nfl\n",
      "\n",
      "\n",
      "   count_star()\n",
      "0          8193\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "\n",
    "SELECT count(*) from nfl\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "result = client.query(query)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'ibis' has no attribute 'duckdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError querying S3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43msetup_ibis_duckdb\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m test_connection(conn, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Close the connection\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[25], line 14\u001b[0m, in \u001b[0;36msetup_ibis_duckdb\u001b[0;34m(duckdb_path, debug)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected to DuckDB file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduckdb_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Use an in-memory DuckDB instance\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mibis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mduckdb\u001b[49m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnected to in-memory DuckDB instance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'ibis' has no attribute 'duckdb'"
     ]
    }
   ],
   "source": [
    "import ibis\n",
    "import s3fs\n",
    "import os\n",
    "\n",
    "def setup_ibis_duckdb(duckdb_path=None, debug=False):\n",
    "    # Use DuckDB as the Ibis backend\n",
    "    if duckdb_path:\n",
    "        # Use an existing DuckDB file or create a new one at the specified path\n",
    "        conn = ibis.duckdb.connect(duckdb_path)\n",
    "        if debug:\n",
    "            print(f\"Connected to DuckDB file: {duckdb_path}\")\n",
    "    else:\n",
    "        # Use an in-memory DuckDB instance\n",
    "        conn = ibis.duckdb.connect()\n",
    "        if debug:\n",
    "            print(\"Connected to in-memory DuckDB instance\")\n",
    "\n",
    "    # Install and load the httpfs extension\n",
    "    conn.raw_sql(\"INSTALL httpfs;\")\n",
    "    conn.raw_sql(\"LOAD httpfs;\")\n",
    "\n",
    "    # Set up anonymous S3 access\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "    # Register the S3 filesystem with DuckDB\n",
    "    conn.register_filesystem(fs)\n",
    "\n",
    "    if debug:\n",
    "        print(\"DuckDB setup complete with Ibis and S3FS.\")\n",
    "\n",
    "    return conn\n",
    "\n",
    "def test_connection(conn, debug=False):\n",
    "    # Create a simple table\n",
    "    conn.raw_sql(\"CREATE TABLE test (id INTEGER, name VARCHAR)\")\n",
    "    conn.raw_sql(\"INSERT INTO test VALUES (1, 'Alice'), (2, 'Bob')\")\n",
    "\n",
    "    # Query the table using Ibis\n",
    "    table = conn.table(\"test\")\n",
    "    result = table.execute()\n",
    "\n",
    "    if debug:\n",
    "        print(\"Test table contents:\")\n",
    "        print(result)\n",
    "\n",
    "    # Try reading from a public S3 bucket\n",
    "    try:\n",
    "        # This is an example. Replace with a real public S3 path if you want to test S3 access\n",
    "        s3_path = 's3://aws-roda-hcls-datalake/gnomad/chrm/run-DataDistiller-2-5C34C2E_F3-job1-of-1-attempt-2023-02-09-00-39-47-ffd3dbaf/part-00000-tid-6010929057455058388-8b99362c-3972-4445-8296-27a7c52f0098-542-1-c000.json'\n",
    "        s3_query = f\"SELECT * FROM read_json_auto('{s3_path}') LIMIT 5\"\n",
    "        s3_result = conn.raw_sql(s3_query).df()\n",
    "        \n",
    "        if debug:\n",
    "            print(\"\\nS3 query result:\")\n",
    "            print(s3_result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying S3: {e}\")\n",
    "\n",
    "\n",
    "conn = setup_ibis_duckdb( debug=True)\n",
    "test_connection(conn, debug=True)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Clean up the test database file\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "    print(f\"Removed test database file: {db_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
